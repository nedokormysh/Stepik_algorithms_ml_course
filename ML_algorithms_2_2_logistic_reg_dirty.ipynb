{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNl6g1W7G50FUxwKbC1TBTu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nedokormysh/Stepik_algorithms_ml_course/blob/logistic_regression/ML_algorithms_2_2_logistic_reg_dirty.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nXbYShLddNfs"
      },
      "outputs": [],
      "source": [
        "from typing import Union"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "Bjw00C0UdkEZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.datasets import make_regression\n",
        "\n",
        "# X_mk, y_mk = make_regression(n_samples=5, n_features=3, n_informative=10, noise=15, random_state=42)"
      ],
      "metadata": {
        "id": "wFmJ6P66dlV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_classification\n",
        "\n",
        "# X_mk, y_mk = make_classification(n_samples=5, n_features=3)\n",
        "X_mk, y_mk = make_classification(n_samples=10, n_features=5, n_informative=2, random_state=42)\n",
        "X_mk = pd.DataFrame(X_mk)\n",
        "y_ml = pd.Series(y_mk)\n",
        "X_mk.columns = [f'col_{col}' for col in X_mk.columns]"
      ],
      "metadata": {
        "id": "RivqkBoTdz1x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2_2_4\n",
        "\n",
        "**Инициализация класса**\n",
        "\n",
        "Создайте класс с именем MyLogReg. Данный класс при инициализации должен принимать на вход два параметра:\n",
        "\n",
        "n_iter – количество шагов градиентного спуска.\n",
        "\n",
        "По-умолчанию: 10\n",
        "\n",
        "learning_rate – коэффициент скорости обучения градиентного спуска.\n",
        "\n",
        "По-умолчанию: 0.1\n",
        "\n",
        "Все переданные (или дефолтные) параметры должны быть сохранены внутри класса.\n",
        "\n",
        "При обращении к экземпляру класса (или при передачи его в функцию print) необходимо распечатать строку по следующему шаблону:\n",
        "\n",
        "MyLogReg class: n_iter=<n_iter>, learning_rate=<learning_rate>\n",
        "\n",
        "Проверка\n",
        "\n",
        "Входные данные: различные исходные параметры логистической регрессии\n",
        "Выходные данные: строка с распечатанным инстансом класса\n",
        "\n",
        "**Sample Input:**\n",
        "\n",
        "{\"n_iter\": 100, \"learning_rate\": 0.1}\n",
        "\n",
        "**Sample Output:**\n",
        "\n",
        "MyLogReg class: n_iter=100, learning_rate=0.1"
      ],
      "metadata": {
        "id": "aI3J4C3pel09"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyLogReg():\n",
        "    def __init__(self,\n",
        "               n_iter: int = 10,\n",
        "               learning_rate: float = 0.1) -> None:\n",
        "\n",
        "        self.n_iter = n_iter\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"MyLogReg class: n_iter={self.n_iter}, learning_rate={self.learning_rate}\""
      ],
      "metadata": {
        "id": "UliEuvEzf9tQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = MyLogReg()\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SEWD1oT7fp60",
        "outputId": "ae0f4867-7720-4609-f6ad-3fef03545a75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MyLogReg class: n_iter=10, learning_rate=0.1"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2_2_5\n",
        "\n",
        "Обучение\n",
        "Реализуем обучение нашей модели:\n",
        "\n",
        "В инициализатор класса добавить новый параметр – weights – который будет хранить веса модели. По умолчанию он ничего не содержит.\n",
        "Вам необходимо реализовать метод fit в Вашем классе. Данный метод должен делать следующее:\n",
        "На вход принимать три атрибута:\n",
        "- X – все фичи в виде датафрейма пандаса.\n",
        "  Примечание: даже если фича будет всего одна, это все равно будет датафрейм, а не серия.\n",
        "- y – целевая переменная в виде пандасовской серии.\n",
        "- verbose – указывает, на какой итерации выводить лог. Например, значение 10 означает, что на каждой 10 итерации градиентного спуска будет печататься лог. Значение по умолчанию = False (т.е. ничего не выводится).\n",
        "Дополнить переданную матрицу фичей единичным столбцом слева.\n",
        "Определить, сколько фичей передано и создать вектор весов, состоящий из одних единиц соответствующей длинны: т.е. количество фичей + 1.\n",
        "Дальше в цикле (до n_iter):\n",
        "- Предсказать $\\hat{y}$.\n",
        "- Посчитать ошибку (LogLoss).\n",
        "- Вычислить градиент.\n",
        "- Сделать шаг размером learning rate в противоположную от градиента сторону.\n",
        "- Сохранить обновленные веса внутри класса.\n",
        "В процессе обучения необходимо выводить лог, в котором указывать номер итерации и значение функций потерь:\n",
        "start | loss: 42027.65\n",
        "\n",
        "100 | loss: 1222.87\n",
        "\n",
        "200 | loss: 232.17\n",
        "\n",
        "300 | loss: 202.4\n",
        "\n",
        "где start - значении функции потерь до начала обучения. Далее выводится каждое i-ое значение итерации, переданное в параметре verbose. Если verbose = False, то лог не выводится вовсе.\n",
        "Метод ничего не возвращает.\n",
        "Необходимо реализовать метод get_coef, который будет возвращать значения весов в виде массива NumPy.\n",
        "LogLoss\n",
        "\n",
        "В формуле LogLoss'а мы дважды вычисляем логарифм используя предсказания модели. И если аргумент логарифма будет равен нулю, то его вычисление выдаст: −inf.\n",
        "\n",
        "Чтобы избежать этого мы будем добавлять к предсказаниям очень малое число: eps = 1e-15\n",
        "\n",
        "Т.е. примерно так: log($\\hat{y}$+eps) и log(1 - $\\hat{y}$ + eps)\n",
        "\n",
        "Проверка\n",
        "\n",
        "Входные данные: несколько наборов параметров для логистической регрессии\n",
        "Выходные данные: коэффициенты обученной логистической регрессии (их среднее)"
      ],
      "metadata": {
        "id": "8OogKP5ukGAI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# X_mk.shape[0]"
      ],
      "metadata": {
        "id": "SgUFZAzcraYK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X = X_mk.copy()\n",
        "# y = y_mk.copy()\n",
        "# y"
      ],
      "metadata": {
        "id": "ciIFvuu7sGU6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = X_mk.copy()\n",
        "y = y_mk.copy()\n",
        "\n",
        "class MyLogReg():\n",
        "    def __init__(self,\n",
        "               n_iter: int = 100,\n",
        "               learning_rate: float = 0.1) -> None:\n",
        "\n",
        "        self.n_iter = n_iter\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"MyLogReg class: n_iter={self.n_iter}, learning_rate={self.learning_rate}\"\n",
        "\n",
        "    def predict_proba(self, X: pd.DataFrame):\n",
        "        return 1 / (1 + np.exp(-np.dot(X, self.weights)))\n",
        "\n",
        "    def grad(self, y: pd.Series, y_pred: pd.Series, X: pd.DataFrame) -> pd.Series:\n",
        "          grad = (y_pred - y) @ X / y.shape[0]\n",
        "          return grad\n",
        "\n",
        "\n",
        "    def logloss(self, y: pd.Series, y_pred: pd.Series, eps=1e-15) -> float:\n",
        "        # loss = -(y @ (np.log(y_pred + eps)) + (1 - y) @ np.log(1 - y_pred + eps)) / y.shape[0]\n",
        "        loss = -(y * (np.log(y_pred + eps)) + (1 - y) * np.log(1 - y_pred + eps)).mean()\n",
        "        return loss\n",
        "\n",
        "    def get_coef(self):\n",
        "        return self.weights[1:]\n",
        "\n",
        "    def fit(self, X: pd.DataFrame, y: pd.Series, verbose: int = False):\n",
        "        X.insert(loc=0, column='x_0', value=1)\n",
        "        self.weights = np.ones(X.shape[1])\n",
        "\n",
        "        for i in range(self.n_iter):\n",
        "            y_hat = self.predict_proba(X)\n",
        "            # print(y)\n",
        "            # print(y_hat)\n",
        "            loss = self.logloss(y, y_hat)\n",
        "            nabla = self.grad(y, y_hat, X)\n",
        "            self.weights -= self.learning_rate * nabla\n",
        "\n",
        "\n",
        "            if verbose and i % verbose == 0:\n",
        "                print(f'start | loss = {loss} | learning_rate = {self.learning_rate}') if i == 0 else print(f'i = {i} | loss = {loss} | learning_rate = {self.learning_rate}')\n",
        "              #  if self.metric:\n",
        "              #      print(f'start | loss = {loss} | {self.score} | learning_rate = {self.learning_rate}') if i == 0 else print(f'i = {i} | loss = {loss} | {self.score} | learning_rate = {self.learning_rate}')\n",
        "              #  else:\n",
        "              #      print(f'start | loss = {loss} | learning_rate = {self.learning_rate}') if i == 0 else print(f'i = {i} | loss = {loss} | learning_rate = {self.learning_rate}')\n",
        "\n",
        "clf = MyLogReg()\n",
        "clf.fit(X, y, verbose=10)"
      ],
      "metadata": {
        "id": "HXZ6Q-GzqbaT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3af15e2e-9ac7-4703-8222-ab376460a118"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "start | loss = 0.5937865210317561 | learning_rate = 0.1\n",
            "i = 10 | loss = 0.4110638433751645 | learning_rate = 0.1\n",
            "i = 20 | loss = 0.33636178796349653 | learning_rate = 0.1\n",
            "i = 30 | loss = 0.286821163369284 | learning_rate = 0.1\n",
            "i = 40 | loss = 0.24930821978877918 | learning_rate = 0.1\n",
            "i = 50 | loss = 0.21972658546903495 | learning_rate = 0.1\n",
            "i = 60 | loss = 0.1960242134344399 | learning_rate = 0.1\n",
            "i = 70 | loss = 0.176819652231451 | learning_rate = 0.1\n",
            "i = 80 | loss = 0.16107744742028882 | learning_rate = 0.1\n",
            "i = 90 | loss = 0.14800996362317612 | learning_rate = 0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = np.array([0, 1, 1, 1, 1, 0, 0, 1, 0, 0])\n",
        "y_pred = np.array([0.23073016, 0.9295853,  0.59687533, 0.94353315, 0.92068336, 0.50009443,\n",
        " 0.44126321, 0.12791097, 0.72269096, 0.28198784])"
      ],
      "metadata": {
        "id": "RMUhm08UQ7Ti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "-(y * (np.log(y_pred)) + (1 - y) * np.log(1 - y_pred)).mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_4s3HHlTJQA",
        "outputId": "b3c7519b-2b79-4bd3-d395-6819c0d23610"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5937865215294601"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = (y * (np.log(y_pred)) + (1 - y) * np.log(1 - y_pred))"
      ],
      "metadata": {
        "id": "rU5bwLI9RQEx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.sum(a) / 10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QL84a6eaTbup",
        "outputId": "dbe2574f-02ff-44a9-d309-b9c539401141"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.5937865215294601"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y @ np.log(y_pred) + (1 - y) @ np.log(1 - y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5EPgee-RSmq",
        "outputId": "e7a6e3d1-4549-4610-dc99-c5849f491e26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-5.9378652152946"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2_2_6\n",
        "\n",
        "\n",
        "Предсказание\n",
        "Научим модель выдавать предсказания. Добавьте в класс MyLogReg два метода predict и predict_proba. Оба метода должны делать следующее:\n",
        "\n",
        "На вход принимать матрицу фичей в виде датафрейма пандаса.\n",
        "Дополнять матрицу фичей единичным вектором (первый столбец).\n",
        "Возвращать вектор предсказаний. Но только с одним отличием:\n",
        "predict_proba – возвращает вероятности (логиты прогнанные через функцию сигмоиды).\n",
        "predict – переводит вероятности в бинарные классы по порогу > 0.5\n",
        "Напомню, что предсказание вероятностей выполняется следующим образом:\n",
        "$\\hat{y} = \\frac{1}{1+e^{-WX}}$\n",
        "где:\n",
        "\n",
        "X – матрица фичей\n",
        "\n",
        "W – вектор весов\n",
        "\n",
        "Проверка\n",
        "\n",
        "Входные данные: несколько датасетов с различными параметрами\n",
        "\n",
        "Выходные данные: возвращенные предсказания (сумма для классов и среднее для вероятностей)\n",
        "\n",
        "Sample Input:\n",
        "\n",
        "{\"n_samples\": 400, \"n_informative\": 5}\n",
        "\n",
        "Sample Output:\n",
        "\n",
        "(266, 0.6535825014)"
      ],
      "metadata": {
        "id": "N7w7RVkZX9Ws"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = X_mk.copy()\n",
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "SbfJeNVTdfSX",
        "outputId": "0952c689-5590-4f14-c1aa-8e4af1f341d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      col_0     col_1     col_2     col_3     col_4\n",
              "0 -0.461711 -0.587231 -1.220844  2.037310 -1.971718\n",
              "1  1.547117  1.899693 -0.301104 -2.399814  0.834445\n",
              "2  0.883943  1.068339 -1.328186 -0.261560 -0.970073\n",
              "3  1.440444  1.777367 -0.115648 -2.797760  1.511576\n",
              "4  1.425444  1.727259  0.196861 -0.712069 -1.185827\n",
              "5 -0.925336 -1.140215  0.208864  1.695858 -0.838792\n",
              "6 -1.597318 -1.962874  0.738467  2.577940 -0.992251\n",
              "7 -0.762815 -0.938205 -1.959670  1.284181 -0.543048\n",
              "8 -0.580675 -0.720634  0.822545  1.397206 -0.960593\n",
              "9 -2.389360 -2.895397  0.171368  1.201904  1.976862"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b58bda73-d9c4-4886-b8f8-b63a58652b72\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>col_0</th>\n",
              "      <th>col_1</th>\n",
              "      <th>col_2</th>\n",
              "      <th>col_3</th>\n",
              "      <th>col_4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.461711</td>\n",
              "      <td>-0.587231</td>\n",
              "      <td>-1.220844</td>\n",
              "      <td>2.037310</td>\n",
              "      <td>-1.971718</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.547117</td>\n",
              "      <td>1.899693</td>\n",
              "      <td>-0.301104</td>\n",
              "      <td>-2.399814</td>\n",
              "      <td>0.834445</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.883943</td>\n",
              "      <td>1.068339</td>\n",
              "      <td>-1.328186</td>\n",
              "      <td>-0.261560</td>\n",
              "      <td>-0.970073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.440444</td>\n",
              "      <td>1.777367</td>\n",
              "      <td>-0.115648</td>\n",
              "      <td>-2.797760</td>\n",
              "      <td>1.511576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.425444</td>\n",
              "      <td>1.727259</td>\n",
              "      <td>0.196861</td>\n",
              "      <td>-0.712069</td>\n",
              "      <td>-1.185827</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>-0.925336</td>\n",
              "      <td>-1.140215</td>\n",
              "      <td>0.208864</td>\n",
              "      <td>1.695858</td>\n",
              "      <td>-0.838792</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>-1.597318</td>\n",
              "      <td>-1.962874</td>\n",
              "      <td>0.738467</td>\n",
              "      <td>2.577940</td>\n",
              "      <td>-0.992251</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>-0.762815</td>\n",
              "      <td>-0.938205</td>\n",
              "      <td>-1.959670</td>\n",
              "      <td>1.284181</td>\n",
              "      <td>-0.543048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>-0.580675</td>\n",
              "      <td>-0.720634</td>\n",
              "      <td>0.822545</td>\n",
              "      <td>1.397206</td>\n",
              "      <td>-0.960593</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>-2.389360</td>\n",
              "      <td>-2.895397</td>\n",
              "      <td>0.171368</td>\n",
              "      <td>1.201904</td>\n",
              "      <td>1.976862</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b58bda73-d9c4-4886-b8f8-b63a58652b72')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b58bda73-d9c4-4886-b8f8-b63a58652b72 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b58bda73-d9c4-4886-b8f8-b63a58652b72');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-24329faa-3b25-4285-9f3e-884d2d373581\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-24329faa-3b25-4285-9f3e-884d2d373581')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-24329faa-3b25-4285-9f3e-884d2d373581 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = X_mk.copy()\n",
        "y = y_mk.copy()\n",
        "\n",
        "class MyLogReg():\n",
        "    def __init__(self,\n",
        "               n_iter: int = 100,\n",
        "               learning_rate: float = 0.1) -> None:\n",
        "\n",
        "        self.n_iter = n_iter\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"MyLogReg class: n_iter={self.n_iter}, learning_rate={self.learning_rate}\"\n",
        "\n",
        "    def predict_proba(self, X: pd.DataFrame):\n",
        "        X = pd.concat([pd.DataFrame([1] * X.shape[0]), X], axis=1)\n",
        "        return 1 / (1 + np.exp(-np.dot(X, self.weights)))\n",
        "\n",
        "    def predict(self, X: pd.DataFrame) -> pd.Series:\n",
        "        return (self.predict_proba(X) > 0.5).astype(int)\n",
        "\n",
        "    def grad(self, y: pd.Series, y_pred: pd.Series, X: pd.DataFrame) -> pd.Series:\n",
        "          grad = (y_pred - y) @ X / y.shape[0]\n",
        "          return grad\n",
        "\n",
        "    def logloss(self, y: pd.Series, y_pred: pd.Series, eps=1e-15) -> float:\n",
        "        loss = -(y * (np.log(y_pred + eps)) + (1 - y) * np.log(1 - y_pred + eps)).mean()\n",
        "        return loss\n",
        "\n",
        "    def get_coef(self):\n",
        "        return self.weights[1:]\n",
        "\n",
        "    def fit(self, X: pd.DataFrame, y: pd.Series, verbose: int = False):\n",
        "        X = pd.concat([pd.DataFrame([1] * X.shape[0]), X], axis=1)\n",
        "        self.weights = np.ones(X.shape[1])\n",
        "\n",
        "        for i in range(self.n_iter):\n",
        "            y_hat = self.predict_proba(X.iloc[:, 1:])\n",
        "            loss = self.logloss(y, y_hat)\n",
        "            nabla = self.grad(y, y_hat, X)\n",
        "            self.weights -= self.learning_rate * nabla\n",
        "\n",
        "\n",
        "            if verbose and i % verbose == 0:\n",
        "                print(f'start | loss = {loss} | learning_rate = {self.learning_rate}') if i == 0 else print(f'i = {i} | loss = {loss} | learning_rate = {self.learning_rate}')\n",
        "              #  if self.metric:\n",
        "              #      print(f'start | loss = {loss} | {self.score} | learning_rate = {self.learning_rate}') if i == 0 else print(f'i = {i} | loss = {loss} | {self.score} | learning_rate = {self.learning_rate}')\n",
        "              #  else:\n",
        "              #      print(f'start | loss = {loss} | learning_rate = {self.learning_rate}') if i == 0 else print(f'i = {i} | loss = {loss} | learning_rate = {self.learning_rate}')\n",
        "\n",
        "clf = MyLogReg()\n",
        "clf.fit(X, y, verbose=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kS08gkQBY-Sz",
        "outputId": "0f116d04-ea5c-499a-8847-9f4b5af7cf9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "start | loss = 0.5937865210317561 | learning_rate = 0.1\n",
            "i = 10 | loss = 0.4110638433751645 | learning_rate = 0.1\n",
            "i = 20 | loss = 0.33636178796349653 | learning_rate = 0.1\n",
            "i = 30 | loss = 0.286821163369284 | learning_rate = 0.1\n",
            "i = 40 | loss = 0.24930821978877918 | learning_rate = 0.1\n",
            "i = 50 | loss = 0.21972658546903495 | learning_rate = 0.1\n",
            "i = 60 | loss = 0.1960242134344399 | learning_rate = 0.1\n",
            "i = 70 | loss = 0.176819652231451 | learning_rate = 0.1\n",
            "i = 80 | loss = 0.16107744742028882 | learning_rate = 0.1\n",
            "i = 90 | loss = 0.14800996362317612 | learning_rate = 0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame([1] * X.shape[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "al1r-XfxgYkl",
        "outputId": "7a001d4d-db2c-4ca5-b255-f6d6324d5635"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   0\n",
              "0  1\n",
              "1  1\n",
              "2  1\n",
              "3  1\n",
              "4  1\n",
              "5  1\n",
              "6  1\n",
              "7  1\n",
              "8  1\n",
              "9  1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-aed00f69-48ce-4cc6-879a-5cfd8189e7a8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aed00f69-48ce-4cc6-879a-5cfd8189e7a8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-aed00f69-48ce-4cc6-879a-5cfd8189e7a8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-aed00f69-48ce-4cc6-879a-5cfd8189e7a8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a2b3c649-8ddf-46c8-b4de-089649a9efae\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a2b3c649-8ddf-46c8-b4de-089649a9efae')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a2b3c649-8ddf-46c8-b4de-089649a9efae button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "LPngbgHueO6I",
        "outputId": "f3f24fe7-3304-424b-bd70-8b0fd160f5df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      col_0     col_1     col_2     col_3     col_4\n",
              "0 -0.461711 -0.587231 -1.220844  2.037310 -1.971718\n",
              "1  1.547117  1.899693 -0.301104 -2.399814  0.834445\n",
              "2  0.883943  1.068339 -1.328186 -0.261560 -0.970073\n",
              "3  1.440444  1.777367 -0.115648 -2.797760  1.511576\n",
              "4  1.425444  1.727259  0.196861 -0.712069 -1.185827\n",
              "5 -0.925336 -1.140215  0.208864  1.695858 -0.838792\n",
              "6 -1.597318 -1.962874  0.738467  2.577940 -0.992251\n",
              "7 -0.762815 -0.938205 -1.959670  1.284181 -0.543048\n",
              "8 -0.580675 -0.720634  0.822545  1.397206 -0.960593\n",
              "9 -2.389360 -2.895397  0.171368  1.201904  1.976862"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-007a2cf2-ac7d-4405-89e3-6275307f5610\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>col_0</th>\n",
              "      <th>col_1</th>\n",
              "      <th>col_2</th>\n",
              "      <th>col_3</th>\n",
              "      <th>col_4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.461711</td>\n",
              "      <td>-0.587231</td>\n",
              "      <td>-1.220844</td>\n",
              "      <td>2.037310</td>\n",
              "      <td>-1.971718</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.547117</td>\n",
              "      <td>1.899693</td>\n",
              "      <td>-0.301104</td>\n",
              "      <td>-2.399814</td>\n",
              "      <td>0.834445</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.883943</td>\n",
              "      <td>1.068339</td>\n",
              "      <td>-1.328186</td>\n",
              "      <td>-0.261560</td>\n",
              "      <td>-0.970073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.440444</td>\n",
              "      <td>1.777367</td>\n",
              "      <td>-0.115648</td>\n",
              "      <td>-2.797760</td>\n",
              "      <td>1.511576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.425444</td>\n",
              "      <td>1.727259</td>\n",
              "      <td>0.196861</td>\n",
              "      <td>-0.712069</td>\n",
              "      <td>-1.185827</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>-0.925336</td>\n",
              "      <td>-1.140215</td>\n",
              "      <td>0.208864</td>\n",
              "      <td>1.695858</td>\n",
              "      <td>-0.838792</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>-1.597318</td>\n",
              "      <td>-1.962874</td>\n",
              "      <td>0.738467</td>\n",
              "      <td>2.577940</td>\n",
              "      <td>-0.992251</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>-0.762815</td>\n",
              "      <td>-0.938205</td>\n",
              "      <td>-1.959670</td>\n",
              "      <td>1.284181</td>\n",
              "      <td>-0.543048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>-0.580675</td>\n",
              "      <td>-0.720634</td>\n",
              "      <td>0.822545</td>\n",
              "      <td>1.397206</td>\n",
              "      <td>-0.960593</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>-2.389360</td>\n",
              "      <td>-2.895397</td>\n",
              "      <td>0.171368</td>\n",
              "      <td>1.201904</td>\n",
              "      <td>1.976862</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-007a2cf2-ac7d-4405-89e3-6275307f5610')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-007a2cf2-ac7d-4405-89e3-6275307f5610 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-007a2cf2-ac7d-4405-89e3-6275307f5610');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d4bb19f4-1cf3-4814-8580-3b168fbb4ec8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d4bb19f4-1cf3-4814-8580-3b168fbb4ec8')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d4bb19f4-1cf3-4814-8580-3b168fbb4ec8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf.predict(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oa5fIupnafZi",
        "outputId": "25a16717-ed3a-40a0-9943-82628cf76ad0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 1, 1, 1, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf.predict_proba(X_mk)"
      ],
      "metadata": {
        "id": "SJwIe6TLbTTq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd0e8338-6b91-40e0-e9dc-abe2f84d4a73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.23749903, 0.99760194, 0.96457826, 0.99812512, 0.96962927,\n",
              "       0.09669955, 0.01147201, 0.47922473, 0.13249227, 0.03626499])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = np.array([0.23073016, 0.9295853,  0.59687533, 0.94353315, 0.92068336, 0.50009443,\n",
        " 0.44126321, 0.12791097, 0.72269096, 0.28198784])\n",
        "\n",
        "(y_pred > 0.5).astype(int)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GvVgSHLzZhay",
        "outputId": "71107e5e-c77b-465c-affd-4b53b68cb16b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 1, 1, 1, 1, 0, 0, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2_2_9"
      ],
      "metadata": {
        "id": "9A1501eesbcr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# last_version\n",
        "class MyLogReg():\n",
        "    def __init__(self,\n",
        "                 n_iter: int = 10,\n",
        "                 learning_rate: float = 0.1,\n",
        "                 metric:str = None,\n",
        "                 reg: str = None,\n",
        "                 l1_coef: float = 0.,\n",
        "                 l2_coef: float = 0.,\n",
        "                 sgd_sample: float = None,\n",
        "                 random_state: int = 42) -> None:\n",
        "\n",
        "        self.n_iter = n_iter\n",
        "        self.learning_rate = learning_rate\n",
        "        self.metric = metric\n",
        "        self.reg = reg\n",
        "        self.l1_coef = l1_coef\n",
        "        self.l2_coef = l2_coef\n",
        "        self.sgd_sample = sgd_sample\n",
        "        #random.seed(random_state)\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"MyLogReg class: n_iter={self.n_iter}, learning_rate={self.learning_rate}\"\n",
        "\n",
        "    def predict_proba(self, X: pd.DataFrame):\n",
        "        X = pd.concat([pd.DataFrame([1] * X.shape[0], index=X.index), X], axis=1)\n",
        "\n",
        "        return 1 / (1 + np.exp(-np.dot(X, self.weights)))\n",
        "\n",
        "    def predict(self, X: pd.DataFrame) -> pd.Series:\n",
        "        return (self.predict_proba(X) > 0.5).astype(int)\n",
        "\n",
        "    def get_batch(self, x_length):\n",
        "        return random.sample(range(x_length), int(self.sgd_sample * x_length)) if isinstance(self.sgd_sample, float) else random.sample(range(x_length), self.sgd_sample)\n",
        "\n",
        "    @staticmethod\n",
        "    def confusion_measure(y, y_pred):\n",
        "        TP = 0\n",
        "        FP = 0\n",
        "        TN = 0\n",
        "        FN = 0\n",
        "\n",
        "        for i in range(len(y_pred)):\n",
        "            if y[i] == y_pred[i] == 1:\n",
        "               TP += 1\n",
        "            if y_pred[i] == 1 and y[i] != y_pred[i]:\n",
        "               FP += 1\n",
        "            if y[i] == y_pred[i] == 0:\n",
        "               TN += 1\n",
        "            if y_pred[i] == 0 and y[i] != y_pred[i]:\n",
        "               FN += 1\n",
        "\n",
        "        return(TP, FP, TN, FN)\n",
        "\n",
        "    @staticmethod\n",
        "    def get_metric_score(metric: str, y_true, y_pred):\n",
        "        if metric != 'roc_auc':\n",
        "            TP, FP, TN, FN = MyLogReg.confusion_measure(y_true, y_pred)\n",
        "\n",
        "            if metric == 'accuracy':\n",
        "                score = (TP + TN) / (TP + FP + TN + FN)\n",
        "            elif metric == 'precision':\n",
        "                score = (TP) / (TP + FP)\n",
        "            elif metric == 'recall':\n",
        "                score = (TP) / (TP + FN)\n",
        "            elif metric == 'f1':\n",
        "                precision = (TP) / (TP + FP)\n",
        "                recall = (TP) / (TP + FN)\n",
        "                score = 2 * precision * recall / (precision + recall)\n",
        "        else:\n",
        "            # y_pred = y_pred.round(10)\n",
        "\n",
        "            total = 0\n",
        "\n",
        "            P = np.sum(y_true == 1)\n",
        "            N = np.sum(y_true == 0)\n",
        "\n",
        "            sorted_idx = np.argsort(-np.array(np.round(y_pred, 10)))\n",
        "            y_sorted = np.array(y_true)[sorted_idx]\n",
        "            y_prob_sorted = y_pred[sorted_idx]\n",
        "\n",
        "            total = 0\n",
        "\n",
        "            for prob, pred in zip(y_prob_sorted, y_sorted):\n",
        "                if pred == 0:\n",
        "                     total += (np.sum(y_sorted[y_prob_sorted > prob])\n",
        "                               + np.sum(y_sorted[y_prob_sorted == prob]) / len(y_sorted[y_prob_sorted == prob])\n",
        "                )\n",
        "\n",
        "            score = total / (P * N)\n",
        "\n",
        "        return score\n",
        "\n",
        "    def get_best_score(self):\n",
        "        return self.score\n",
        "\n",
        "    def grad(self, y: pd.Series, y_pred: pd.Series, X: pd.DataFrame) -> pd.Series:\n",
        "          grad = (y_pred - y) @ X / y.shape[0]\n",
        "          return grad\n",
        "\n",
        "    def loss(self, y: pd.Series, y_pred: pd.DataFrame) -> float:\n",
        "        if self.reg == 'None':\n",
        "            loss = MyLogReg.logloss(y, y_pred)\n",
        "        elif self.reg == 'l1':\n",
        "            loss = MyLogReg.logloss(y, y_pred) + self.l1_coef * np.sum(self.weights)\n",
        "        elif self.reg == 'l2':\n",
        "            loss = MyLogReg.logloss(y, y_pred) + self.l2_coef * np.sum(self.weights**2)\n",
        "        else:\n",
        "            loss = MyLogReg.logloss(y, y_pred) + self.l1_coef * np.sum(self.weights) + self.l2_coef * np.sum(self.weights**2)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    @staticmethod\n",
        "    def logloss(y: pd.Series, y_pred: pd.Series, eps=1e-15) -> float:\n",
        "        loss = -(y * (np.log(y_pred + eps)) + (1 - y) * np.log(1 - y_pred + eps)).mean()\n",
        "        return loss\n",
        "\n",
        "    def get_coef(self):\n",
        "        return self.weights[1:]\n",
        "\n",
        "    def fit(self, X: pd.DataFrame, y: pd.Series, verbose: int = False):\n",
        "        X = pd.concat([pd.DataFrame([1] * X.shape[0]), X], axis=1)\n",
        "        self.weights = np.ones(X.shape[1])\n",
        "\n",
        "        for i in range(0, self.n_iter + 1):\n",
        "            y_hat = self.predict_proba(X.iloc[:, 1:])\n",
        "            loss = self.logloss(y, y_hat)\n",
        "            nabla = self.grad(y, y_hat, X)\n",
        "            self.weights -= self.learning_rate * nabla\n",
        "\n",
        "            if self.metric:\n",
        "                if self.metric != 'roc_auc':\n",
        "                    y_pred = self.predict(X.iloc[:, 1:])\n",
        "                    self.score = getattr(self, 'get_metric_score')(self.metric, y, y_pred)\n",
        "                else:\n",
        "                    self.score = getattr(self, 'get_metric_score')(self.metric, y, y_hat)\n",
        "\n",
        "            if verbose and i % verbose == 0:\n",
        "                if self.metric:\n",
        "                   print(f'start | loss = {loss} | {self.metric} = {self.score} | learning_rate = {self.learning_rate}') if i == 0 else print(f'i = {i} | loss = {loss} | {self.metric} = {self.score} | learning_rate = {self.learning_rate}')\n",
        "                else:\n",
        "                   print(f'start | loss = {loss} | learning_rate = {self.learning_rate}') if i == 0 else print(f'i = {i} | loss = {loss} | learning_rate = {self.learning_rate}')\n"
      ],
      "metadata": {
        "id": "sxXLuw2psf8i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = MyLogReg(metric='roc_auc')\n",
        "# clf = MyLogReg()\n",
        "clf.fit(X, y, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4hoG46FVvsh",
        "outputId": "0318d041-ad51-4e63-cab3-3a56bbd7db63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "start | loss = 3.6736886876615524 | roc_auc = 0.5326141304565218 | learning_rate = 0.1\n",
            "i = 1 | loss = 3.399345496011302 | roc_auc = 0.5383301533206133 | learning_rate = 0.1\n",
            "i = 2 | loss = 3.1414206361343004 | roc_auc = 0.5452061808247233 | learning_rate = 0.1\n",
            "i = 3 | loss = 2.9017043294408578 | roc_auc = 0.5527142108568435 | learning_rate = 0.1\n",
            "i = 4 | loss = 2.681294069812125 | roc_auc = 0.5609102436409745 | learning_rate = 0.1\n",
            "i = 5 | loss = 2.480888351294942 | roc_auc = 0.5696102784411138 | learning_rate = 0.1\n",
            "i = 6 | loss = 2.30062735806605 | roc_auc = 0.5792103168412673 | learning_rate = 0.1\n",
            "i = 7 | loss = 2.140094583056409 | roc_auc = 0.5889743558974236 | learning_rate = 0.1\n",
            "i = 8 | loss = 1.9981029436942546 | roc_auc = 0.599750399001596 | learning_rate = 0.1\n",
            "i = 9 | loss = 1.8729518266222966 | roc_auc = 0.6106664426657706 | learning_rate = 0.1\n",
            "i = 10 | loss = 1.7627744144564494 | roc_auc = 0.6219904879619519 | learning_rate = 0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# start | loss: 3.6736886876615524| roc_auc: 0.5326141304565218\n",
        "# 1 | loss: 3.6736886876615524| roc_auc: 0.5326141304565218\n",
        "# 2 | loss: 3.399345496011302| roc_auc: 0.5383301533206133\n",
        "# 3 | loss: 3.1414206361343004| roc_auc: 0.5452061808247233\n",
        "# 4 | loss: 2.9017043294408578| roc_auc: 0.5527142108568435\n",
        "# 5 | loss: 2.681294069812125| roc_auc: 0.5609102436409745\n",
        "# 6 | loss: 2.480888351294942| roc_auc: 0.5696102784411138\n",
        "# 7 | loss: 2.30062735806605| roc_auc: 0.5792103168412673\n",
        "# 8 | loss: 2.140094583056409| roc_auc: 0.5889743558974236\n",
        "# 9 | loss: 1.9981029436942546| roc_auc: 0.599750399001596\n",
        "# 10 | loss: 1.8729518266222966| roc_auc: 0.6106664426657706"
      ],
      "metadata": {
        "id": "Y0cPyHGAWFSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = X_mk.copy()\n",
        "y = y_mk.copy()\n",
        "\n",
        "class MyLogReg():\n",
        "    def __init__(self,\n",
        "               n_iter: int = 10,\n",
        "               learning_rate: float = 0.1,\n",
        "              metric=None) -> None:\n",
        "\n",
        "        self.n_iter = n_iter\n",
        "        self.learning_rate = learning_rate\n",
        "        self.metric = metric\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"MyLogReg class: n_iter={self.n_iter}, learning_rate={self.learning_rate}\"\n",
        "\n",
        "    def predict_proba(self, X: pd.DataFrame):\n",
        "        X = pd.concat([pd.DataFrame([1] * X.shape[0]), X], axis=1)\n",
        "        return 1 / (1 + np.exp(-np.dot(X, self.weights)))\n",
        "\n",
        "    def predict(self, X: pd.DataFrame) -> pd.Series:\n",
        "        return (self.predict_proba(X) > 0.5).astype(int)\n",
        "\n",
        "    def _sigmoid(self, X):\n",
        "        return 1 / (1 + np.exp(-X))\n",
        "\n",
        "    @staticmethod\n",
        "    def confusion_measure(y, y_pred):\n",
        "        TP = 0\n",
        "        FP = 0\n",
        "        TN = 0\n",
        "        FN = 0\n",
        "\n",
        "        for i in range(len(y_pred)):\n",
        "            if y[i] == y_pred[i] == 1:\n",
        "               TP += 1\n",
        "            if y_pred[i] == 1 and y[i] != y_pred[i]:\n",
        "               FP += 1\n",
        "            if y[i] == y_pred[i] == 0:\n",
        "               TN += 1\n",
        "            if y_pred[i] == 0 and y[i] != y_pred[i]:\n",
        "               FN += 1\n",
        "\n",
        "        return(TP, FP, TN, FN)\n",
        "\n",
        "    @staticmethod\n",
        "    def get_metric_score(metric: str, y_true, y_pred):\n",
        "        if metric != 'roc_auc':\n",
        "            TP, FP, TN, FN = MyLogReg.confusion_measure(y_true, y_pred)\n",
        "            # tp = ((y_true == 1) & (y_pred == 1)).sum()\n",
        "            # fn = ((y_true == 1) & (y_pred == 0)).sum()\n",
        "            # fp = ((y_true == 0) & (y_pred == 1)).sum()\n",
        "\n",
        "            if metric == 'accuracy':\n",
        "                score = (TP + TN) / (TP + FP + TN + FN)\n",
        "            elif metric == 'precision':\n",
        "                score = (TP) / (TP + FP)\n",
        "            elif metric == 'recall':\n",
        "                score = (TP) / (TP + FN)\n",
        "            elif metric == 'f1':\n",
        "                precision = (TP) / (TP + FP)\n",
        "                recall = (TP) / (TP + FN)\n",
        "                score = 2 * precision * recall / (precision + recall)\n",
        "        else:\n",
        "            y_pred = y_pred.round(10)\n",
        "            # df_ = pd.DataFrame(zip(y_pred, y_true), columns=['Probability', 'Class'])\n",
        "            # df_ = df_.sort_values(by='Probability', ascending=False)\n",
        "\n",
        "            # N = df_['Class'].value_counts()[0]\n",
        "            # P = df_['Class'].value_counts()[1]\n",
        "\n",
        "            # total = 0\n",
        "\n",
        "            # # перестало работать.\n",
        "\n",
        "            # # for i in range(len(df_)):\n",
        "            # #     if df_.iloc[i]['Class'] == 0:\n",
        "            # #         prop = df_.iloc[i]['Probability']\n",
        "            # #         l = len(df_[df_['Probability'] == prop])\n",
        "\n",
        "            # #         if l == 1:\n",
        "            # #             tot = df_['Class'][0:i].value_counts()[1]\n",
        "            # #         else:\n",
        "            # #             df_mini_up = df_[0:i]\n",
        "            # #             df_mini_up = df_mini_up[~(df_mini_up['Probability'] == prop)]\n",
        "            # #             df_mini_down = df_[df_['Probability'] == prop]\n",
        "\n",
        "            # #             tot = df_mini_up['Class'].value_counts()[1] + df_mini_down['Class'].value_counts()[1] / 2\n",
        "            # #         total += tot\n",
        "\n",
        "            # рабочая, но медленная версия\n",
        "            #  for prob, pred in zip(df_['Probability'], df_['Class']):\n",
        "            #      if pred == 0:\n",
        "            #          total += (\n",
        "            #               np.sum(df_['Class'][df_['Probability'] > prob])\n",
        "            #          + np.sum(df_['Class'][df_['Probability'] == prob]) / 2\n",
        "            #      )\n",
        "\n",
        "            P = np.sum(y_true == 1)\n",
        "            N = np.sum(y_true == 0)\n",
        "\n",
        "            sorted_idx = np.argsort(-np.array(np.round(y_pred, 10)))\n",
        "            y_sorted = np.array(y_true)[sorted_idx]\n",
        "            y_prob_sorted = y_pred[sorted_idx]\n",
        "\n",
        "            total = 0\n",
        "\n",
        "            for prob, pred in zip(y_prob_sorted, y_sorted):\n",
        "                if pred == 0:\n",
        "                     total += (np.sum(y_sorted[y_prob_sorted > prob])\n",
        "                               + np.sum(y_sorted[y_prob_sorted == prob]) / 2\n",
        "                )\n",
        "\n",
        "            score = total / (P * N)\n",
        "\n",
        "        return score\n",
        "\n",
        "    def get_best_score(self):\n",
        "        return self.score\n",
        "\n",
        "    def grad(self, y: pd.Series, y_pred: pd.Series, X: pd.DataFrame) -> pd.Series:\n",
        "          grad = (y_pred - y) @ X / y.shape[0]\n",
        "          return grad\n",
        "\n",
        "    def logloss(self, y: pd.Series, y_pred: pd.Series, eps=1e-15) -> float:\n",
        "        loss = -(y * (np.log(y_pred + eps)) + (1 - y) * np.log(1 - y_pred + eps)).mean()\n",
        "        return loss\n",
        "\n",
        "    def get_coef(self):\n",
        "        return self.weights[1:]\n",
        "\n",
        "    def fit(self, X: pd.DataFrame, y: pd.Series, verbose: int = False):\n",
        "        X = pd.concat([pd.DataFrame([1] * X.shape[0]), X], axis=1)\n",
        "        self.weights = np.ones(X.shape[1])\n",
        "\n",
        "        for i in range(self.n_iter):\n",
        "            y_hat = self.predict_proba(X.iloc[:, 1:])\n",
        "            loss = self.logloss(y, y_hat)\n",
        "            nabla = self.grad(y, y_hat, X)\n",
        "            self.weights -= self.learning_rate * nabla\n",
        "\n",
        "            if self.metric:\n",
        "                if self.metric != 'roc_auc':\n",
        "                    # y_pred = self.predict(X.iloc[:, 1:])\n",
        "                    y_pred = self._sigmoid(np.dot(X.values, self.weights))\n",
        "                    self.score = getattr(self, 'get_metric_score')(self.metric, y, y_pred)\n",
        "                else:\n",
        "                    self.score = getattr(self, 'get_metric_score')(self.metric, y, y_hat)\n",
        "\n",
        "            if verbose and i % verbose == 0:\n",
        "                if self.metric:\n",
        "                   print(f'start | loss = {loss} | {self.metric} = {self.score} | learning_rate = {self.learning_rate}') if i == 0 else print(f'i = {i} | loss = {loss} | {self.metric} = {self.score} | learning_rate = {self.learning_rate}')\n",
        "                else:\n",
        "                   print(f'start | loss = {loss} | learning_rate = {self.learning_rate}') if i == 0 else print(f'i = {i} | loss = {loss} | learning_rate = {self.learning_rate}')\n",
        "\n",
        "clf = MyLogReg(metric='accuracy')\n",
        "# clf = MyLogReg()\n",
        "clf.fit(X, y, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "a6AkSoruN8Iu",
        "outputId": "4eecaf39-8fb3-4a44-d33a-0d593d38ecd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ZeroDivisionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-140-0b5122e2e6de>\u001b[0m in \u001b[0;36m<cell line: 158>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMyLogReg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;31m# clf = MyLogReg()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-140-0b5122e2e6de>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, verbose)\u001b[0m\n\u001b[1;32m    144\u001b[0m                     \u001b[0;31m# y_pred = self.predict(X.iloc[:, 1:])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m                     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'get_metric_score'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'get_metric_score'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_hat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-140-0b5122e2e6de>\u001b[0m in \u001b[0;36mget_metric_score\u001b[0;34m(metric, y_true, y_pred)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmetric\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m                 \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTP\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mTN\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTP\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mFP\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mTN\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mFN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mmetric\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'precision'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                 \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTP\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTP\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mFP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## learner"
      ],
      "metadata": {
        "id": "f1wozLXXMmxR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# lear\\\n",
        "\n",
        "class MyLogReg():\n",
        "    def __init__(self,\n",
        "                 n_iter: int = 10,\n",
        "                 learning_rate: float = 0.1,\n",
        "                 metric:str = None,\n",
        "                 reg: str = None,\n",
        "                 l1_coef: float = 0.,\n",
        "                 l2_coef: float = 0.,\n",
        "                 sgd_sample: float = None,\n",
        "                 random_state: int = 42) -> None:\n",
        "\n",
        "        self.n_iter = n_iter\n",
        "        self.learning_rate = learning_rate\n",
        "        self.metric = metric\n",
        "        self.reg = reg\n",
        "        self.l1_coef = l1_coef\n",
        "        self.l2_coef = l2_coef\n",
        "        self.sgd_sample = sgd_sample\n",
        "        #random.seed(random_state)\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"MyLogReg class: n_iter={self.n_iter}, learning_rate={self.learning_rate}\"\n",
        "\n",
        "    def predict_proba(self, X: pd.DataFrame):\n",
        "        n_samples, n_features = X.shape\n",
        "        X = pd.concat([pd.DataFrame([1] * X.shape[0], index=X.index), X], axis=1)\n",
        "\n",
        "        return 1 / (1 + np.exp(-np.dot(X, self.weights)))\n",
        "\n",
        "    def _sigmoid(self, X):\n",
        "        return 1 / (1 + np.exp(-X))\n",
        "\n",
        "    def predict(self, X: pd.DataFrame) -> pd.Series:\n",
        "        return (self.predict_proba(X) > 0.5).astype(int)\n",
        "\n",
        "    def get_batch(self, x_length):\n",
        "        return random.sample(range(x_length), int(self.sgd_sample * x_length)) if isinstance(self.sgd_sample, float) else random.sample(range(x_length), self.sgd_sample)\n",
        "\n",
        "    @staticmethod\n",
        "    def confusion_measure(y, y_pred):\n",
        "        TP = 0\n",
        "        FP = 0\n",
        "        TN = 0\n",
        "        FN = 0\n",
        "\n",
        "        for i in range(len(y_pred)):\n",
        "            if y[i] == y_pred[i] == 1:\n",
        "               TP += 1\n",
        "            if y_pred[i] == 1 and y[i] != y_pred[i]:\n",
        "               FP += 1\n",
        "            if y[i] == y_pred[i] == 0:\n",
        "               TN += 1\n",
        "            if y_pred[i] == 0 and y[i] != y_pred[i]:\n",
        "               FN += 1\n",
        "\n",
        "        return(TP, FP, TN, FN)\n",
        "\n",
        "    @staticmethod\n",
        "    def get_metric_score(metric: str, y_true, y_pred):\n",
        "        if metric != 'roc_auc':\n",
        "            TP, FP, TN, FN = MyLogReg.confusion_measure(y_true, y_pred)\n",
        "\n",
        "            if metric == 'accuracy':\n",
        "                score = (TP + TN) / (TP + FP + TN + FN)\n",
        "            elif metric == 'precision':\n",
        "                score = (TP) / (TP + FP)\n",
        "            elif metric == 'recall':\n",
        "                score = (TP) / (TP + FN)\n",
        "            elif metric == 'f1':\n",
        "                precision = (TP) / (TP + FP)\n",
        "                recall = (TP) / (TP + FN)\n",
        "                score = 2 * precision * recall / (precision + recall)\n",
        "        else:\n",
        "            total = 0\n",
        "\n",
        "            P = np.sum(y_true == 1)\n",
        "            N = np.sum(y_true == 0)\n",
        "\n",
        "            sorted_idx = np.argsort(-np.array(np.round(y_pred, 10)))\n",
        "            y_sorted = np.array(y_true)[sorted_idx]\n",
        "            y_prob_sorted = y_pred[sorted_idx]\n",
        "\n",
        "            total = 0\n",
        "\n",
        "            for prob, pred in zip(y_prob_sorted, y_sorted):\n",
        "                if pred == 0:\n",
        "                     total += (np.sum(y_sorted[y_prob_sorted > prob])\n",
        "                               + np.sum(y_sorted[y_prob_sorted == prob]) / 2\n",
        "                )\n",
        "\n",
        "            score = total / (P * N)\n",
        "\n",
        "        return score\n",
        "\n",
        "    def get_best_score(self):\n",
        "        return self.score\n",
        "\n",
        "    def grad(self, y: pd.Series, y_pred: pd.Series, X: pd.DataFrame) -> pd.Series:\n",
        "          #X = pd.concat([pd.DataFrame({\"bias\": [1] * n_samples}), X.reset_index(drop=True)], axis=1)\n",
        "          grad = (y_pred - y) @ X / y.shape[0]\n",
        "          return grad\n",
        "\n",
        "    def loss(self, y: pd.Series, y_pred: pd.DataFrame) -> float:\n",
        "        if self.reg == 'None':\n",
        "            loss = MyLogReg.logloss(y, y_pred)\n",
        "        elif self.reg == 'l1':\n",
        "            loss = MyLogReg.logloss(y, y_pred) + self.l1_coef * np.sum(self.weights)\n",
        "        elif self.reg == 'l2':\n",
        "            loss = MyLogReg.logloss(y, y_pred) + self.l2_coef * np.sum(self.weights**2)\n",
        "        else:\n",
        "            loss = MyLogReg.logloss(y, y_pred) + self.l1_coef * np.sum(self.weights) + self.l2_coef * np.sum(self.weights**2)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    @staticmethod\n",
        "    def logloss(y: pd.Series, y_pred: pd.Series, eps=1e-15) -> float:\n",
        "        loss = -(y * (np.log(y_pred + eps)) + (1 - y) * np.log(1 - y_pred + eps)).mean()\n",
        "        return loss\n",
        "\n",
        "    def get_coef(self):\n",
        "        return self.weights[1:]\n",
        "\n",
        "    def fit(self, X: pd.DataFrame, y: pd.Series, verbose: int = False):\n",
        "        n_samples, n_features = X.shape\n",
        "        X = pd.concat([pd.DataFrame({\"bias\": [1] * n_samples}), X.reset_index(drop=True)], axis=1)\n",
        "        self.weights = np.ones(X.shape[1])\n",
        "\n",
        "        for i in range(self.n_iter):\n",
        "            y_hat = self.predict_proba(X.iloc[:, 1:])\n",
        "            loss = self.logloss(y, y_hat)\n",
        "            nabla = self.grad(y, y_hat, X)\n",
        "            self.weights -= self.learning_rate * nabla\n",
        "\n",
        "            if self.metric:\n",
        "                if self.metric != 'roc_auc':\n",
        "                    #y_pred = self.predict(X.iloc[:, 1:])\n",
        "\n",
        "                    self.score = getattr(self, 'get_metric_score')(self.metric, y, y_pred)\n",
        "                else:\n",
        "                    self.score = getattr(self, 'get_metric_score')(self.metric, y, y_hat)\n",
        "\n",
        "            if verbose and i % verbose == 0:\n",
        "                if self.metric:\n",
        "                   print(f'start | loss = {loss} | {self.metric} = {self.score} | learning_rate = {self.learning_rate}') if i == 0 else print(f'i = {i} | loss = {loss} | {self.metric} = {self.score} | learning_rate = {self.learning_rate}')\n",
        "                else:\n",
        "                   print(f'start | loss = {loss} | learning_rate = {self.learning_rate}') if i == 0 else print(f'i = {i} | loss = {loss} | learning_rate = {self.learning_rate}')\n"
      ],
      "metadata": {
        "id": "S8omdwr-VFFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class MyLogReg:\n",
        "    def __init__(\n",
        "        self,\n",
        "        n_iter: int = 10,\n",
        "        learning_rate: float = 0.1,\n",
        "        metric: str = None,\n",
        "        reg: str = None,\n",
        "        l1_coef: float = 0.0,\n",
        "        l2_coef: float = 0.0,\n",
        "        sgd_sample: float = None,\n",
        "        random_state: int = 42,\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Construct logistic regression class.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        n_iter : int, optional\n",
        "            Number of iterations, by default 100\n",
        "        learning_rate : float, optional\n",
        "            Learning rate, by default 3e-4\n",
        "        metric : str, optional\n",
        "            Metric to calculate during training, by default None\n",
        "        reg : str, optional\n",
        "            Type of regularization:\n",
        "            'l1', 'l2', 'elasticnet', by default None.\n",
        "        l1_coef : float, optional\n",
        "            L1 regularization coefficient, by default 0.0\n",
        "        l2_coef : float, optional\n",
        "            L2 regularization coefficient, by default 0.0\n",
        "        sgd_sample : float, optional\n",
        "            Stochastic gradient descent sample, by default None\n",
        "        random_state : int, optional\n",
        "            Random state, by default 42\n",
        "        \"\"\"\n",
        "\n",
        "        self.n_iter = n_iter\n",
        "        self.learning_rate = learning_rate\n",
        "        self.metric = metric\n",
        "        self.reg = reg\n",
        "        self.l1_coef = l1_coef\n",
        "        self.l2_coef = l2_coef\n",
        "        self._weights = None\n",
        "        self._eps = 1e-15\n",
        "        self._threshold = 0.5\n",
        "        self._best_score = None\n",
        "        self.sgd_sample = sgd_sample\n",
        "        self.random_state = random_state\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        \"\"\"\n",
        "        Get class representation in readable form.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        str\n",
        "            String with class representation\n",
        "        \"\"\"\n",
        "        class_name = type(self).__name__\n",
        "        return f\"{class_name} class: n_iter={self.n_iter}, learning_rate={self.learning_rate}\"\n",
        "\n",
        "    def _sigmoid(self, x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    def _confusion_matrix(self, y: np.array, y_pred: np.array) -> tuple:\n",
        "        \"\"\"\n",
        "        Calculate confusion matrix.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        y : np.array\n",
        "            True values\n",
        "        y_pred : np.array\n",
        "            Predicted values\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        tuple\n",
        "            TP, FN, FP, TN\n",
        "        \"\"\"\n",
        "        y_pred = np.where(y_pred > self._threshold, 1, 0)\n",
        "        TP = np.logical_and(y == 1, y_pred == 1).sum()\n",
        "        FN = np.logical_and(y == 1, y_pred == 0).sum()\n",
        "        FP = np.logical_and(y == 0, y_pred == 1).sum()\n",
        "        TN = np.logical_and(y == 0, y_pred == 0).sum()\n",
        "\n",
        "        return TP, FN, FP, TN\n",
        "\n",
        "    def _accuracy(self, y: np.array, y_pred: np.array) -> float:\n",
        "        \"\"\"\n",
        "        Calculate accuracy.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        y : np.array\n",
        "            True values\n",
        "        y_pred : np.array\n",
        "            Predicted values\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        float\n",
        "            Calculated metric\n",
        "        \"\"\"\n",
        "        TP, FN, FP, TN = self._confusion_matrix(y, y_pred)\n",
        "        return (TP + TN) / (TP + FN + FP + TN)\n",
        "\n",
        "    def _precision(self, sy: np.array, y_pred: np.array) -> float:\n",
        "        \"\"\"\n",
        "        Calculate precision.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        y : np.array\n",
        "            True values\n",
        "        y_pred : np.array\n",
        "            Predicted values\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        float\n",
        "            Calculated metric\n",
        "        \"\"\"\n",
        "        TP, _, FP, _ = self._confusion_matrix(y, y_pred)\n",
        "        return TP / (TP + FP)\n",
        "\n",
        "    def _recall(self, y: np.array, y_pred: np.array) -> float:\n",
        "        \"\"\"\n",
        "        Calculate recall.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        y : np.array\n",
        "            True values\n",
        "        y_pred : np.array\n",
        "            Predicted values\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        float\n",
        "            Calculated metric\n",
        "        \"\"\"\n",
        "        TP, FN, _, _ = self._confusion_matrix(y, y_pred)\n",
        "        return TP / (TP + FN)\n",
        "\n",
        "    def _f1(self, y: np.array, y_pred: np.array, beta: float = 1) -> float:\n",
        "        \"\"\"\n",
        "        Calculate F1 score.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        y : np.array\n",
        "            True values\n",
        "        y_pred : np.array\n",
        "            Predicted values\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        float\n",
        "            Calculated metric\n",
        "        \"\"\"\n",
        "        recall = self._recall(y, y_pred)\n",
        "        precision = self._precision(y, y_pred)\n",
        "\n",
        "        return (1 + beta**2) * (precision * recall) / (beta**2 * precision + recall)\n",
        "\n",
        "    def _roc_auc(self, y: np.array, y_prob: np.array, beta: float = 1) -> float:\n",
        "        \"\"\"\n",
        "        Calculate ROC AUC score.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        y : np.array\n",
        "            True values\n",
        "        y_prob : np.array\n",
        "            Predicted probabilities\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        float\n",
        "            Calculated metric\n",
        "        \"\"\"\n",
        "        positives = np.sum(y == 1)\n",
        "        negatives = np.sum(y == 0)\n",
        "\n",
        "        sorted_idx = np.argsort(-np.array(np.round(y_prob, 10)))\n",
        "        y_sorted = np.array(y)[sorted_idx]\n",
        "        y_prob_sorted = y_prob[sorted_idx]\n",
        "\n",
        "        roc_auc_score = 0\n",
        "\n",
        "        for prob, pred in zip(y_prob_sorted, y_sorted):\n",
        "            if pred == 0:\n",
        "                roc_auc_score += (\n",
        "                    np.sum(y_sorted[y_prob_sorted > prob])\n",
        "                    + np.sum(y_sorted[y_prob_sorted == prob]) / 2\n",
        "                )\n",
        "\n",
        "        roc_auc_score /= positives * negatives\n",
        "\n",
        "        return roc_auc_score\n",
        "\n",
        "    def _loss(self, y: np.array, y_pred: np.array, **kwargs) -> float:\n",
        "        \"\"\"\n",
        "        Calculate LogLoss.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        y : np.array\n",
        "            True values\n",
        "        y_pred : np.array\n",
        "            Predicted values\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        float\n",
        "            Calculated loss\n",
        "        \"\"\"\n",
        "        return -np.mean(y * np.log(y_pred + self._eps) + (1 - y) * np.log(1 - y_pred + self._eps))\n",
        "\n",
        "    def _l1_loss(\n",
        "        self, y: np.array, y_pred: np.array, l1_coef: float, weights: np.array, **kwargs\n",
        "    ) -> float:\n",
        "        \"\"\"\n",
        "        Calculate LogLoss with L1 regularization.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        y : np.array\n",
        "            True values\n",
        "        y_pred : np.array\n",
        "            Predicted values\n",
        "        l1_coef : float\n",
        "            L1 regularization coefficient\n",
        "        weights : np.array\n",
        "            Linear regression weights\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        float\n",
        "            Calculated loss\n",
        "        \"\"\"\n",
        "        return self._loss(y, y_pred) + l1_coef * np.sum(weights)\n",
        "\n",
        "    def _l2_loss(\n",
        "        self, y: np.array, y_pred: np.array, l2_coef: float, weights: np.array, **kwargs\n",
        "    ) -> float:\n",
        "        \"\"\"\n",
        "        Calculate LogLoss with L2 regularization.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        y : np.array\n",
        "            True values\n",
        "        y_pred : np.array\n",
        "            Predicted values\n",
        "        l2_coef : float\n",
        "            L2 regularization coefficient\n",
        "        weights : np.array\n",
        "            Linear regression weights\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        float\n",
        "            Calculated loss\n",
        "        \"\"\"\n",
        "        return self._loss(y, y_pred) + l2_coef * np.sum(weights**2)\n",
        "\n",
        "    def _elasticnet_loss(\n",
        "        self,\n",
        "        y: np.array,\n",
        "        y_pred: np.array,\n",
        "        l1_coef: float,\n",
        "        l2_coef: float,\n",
        "        weights: np.array,\n",
        "        **kwargs,\n",
        "    ) -> float:\n",
        "        \"\"\"\n",
        "        Calculate LogLoss with Elasticnet regularization.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        y : np.array\n",
        "            True values\n",
        "        y_pred : np.array\n",
        "            Predicted values\n",
        "        l1_coef : float\n",
        "            L1 regularization coefficient\n",
        "        l2_coef : float\n",
        "            L2 regularization coefficient\n",
        "        weights : np.array\n",
        "            Linear regression weights\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        float\n",
        "            Calculated loss\n",
        "        \"\"\"\n",
        "        return (\n",
        "            self._l1_loss(y, y_pred, l1_coef, weights)\n",
        "            + self._l2_loss(y, y_pred, l2_coef, weights)\n",
        "            - self._loss(y, y_pred)\n",
        "        )\n",
        "\n",
        "    def _grad(self, y: np.array, y_pred: np.array, X: np.array, **kwargs) -> np.array:\n",
        "        \"\"\"\n",
        "        Calculate gradient.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        y : np.array\n",
        "            True values\n",
        "        y_pred : np.array\n",
        "            Predicted values\n",
        "        X : np.array\n",
        "            Training data\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        np.array\n",
        "            Gradient vector\n",
        "        \"\"\"\n",
        "        return 1 / X.shape[0] * np.dot((y_pred - y), X.values)\n",
        "\n",
        "    def _l1_grad(\n",
        "        self,\n",
        "        y: np.array,\n",
        "        y_pred: np.array,\n",
        "        X: np.array,\n",
        "        l1_coef: float,\n",
        "        weights: np.array,\n",
        "        **kwargs,\n",
        "    ) -> np.array:\n",
        "        \"\"\"\n",
        "        Calculate gradient for L1 regularization.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        y : np.array\n",
        "            True values\n",
        "        y_pred : np.array\n",
        "            Predicted values\n",
        "        X : np.array\n",
        "            Training data\n",
        "        l1_coef : float\n",
        "            L1 regularization coefficient\n",
        "        weights : np.array\n",
        "            Linear regression weights\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        np.array\n",
        "            Gradient vector\n",
        "        \"\"\"\n",
        "        return self._grad(y, y_pred, X) + l1_coef * np.sign(weights)\n",
        "\n",
        "    def _l2_grad(\n",
        "        self,\n",
        "        y: np.array,\n",
        "        y_pred: np.array,\n",
        "        X: np.array,\n",
        "        l2_coef: float,\n",
        "        weights: np.array,\n",
        "        **kwargs,\n",
        "    ) -> np.array:\n",
        "        \"\"\"\n",
        "        Calculate gradient for L2 regularization.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        y : np.array\n",
        "            True values\n",
        "        y_pred : np.array\n",
        "            Predicted values\n",
        "        X : np.array\n",
        "            Training data\n",
        "        l2_coef : float\n",
        "            L2 regularization coefficient\n",
        "        weights : np.array\n",
        "            Linear regression weights\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        np.array\n",
        "            Gradient vector\n",
        "        \"\"\"\n",
        "        return self._grad(y, y_pred, X) + l2_coef * 2 * weights\n",
        "\n",
        "    def _elasticnet_grad(\n",
        "        self,\n",
        "        y: np.array,\n",
        "        y_pred: np.array,\n",
        "        X: np.array,\n",
        "        l1_coef: float,\n",
        "        l2_coef: float,\n",
        "        weights: np.array,\n",
        "        **kwargs,\n",
        "    ) -> np.array:\n",
        "        \"\"\"\n",
        "        Calculate gradient for Elasticnet regularization.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        y : np.array\n",
        "            True values\n",
        "        y_pred : np.array\n",
        "            Predicted values\n",
        "        X : np.array\n",
        "            Training data\n",
        "        l1_coef : float\n",
        "            L1 regularization coefficient\n",
        "        l2_coef : float\n",
        "            L2 regularization coefficient\n",
        "        weights : np.array\n",
        "            Linear regression weights\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        np.array\n",
        "            Gradient vector\n",
        "        \"\"\"\n",
        "        return (\n",
        "            self._l1_grad(y, y_pred, X, l1_coef, weights)\n",
        "            + self._l2_grad(y, y_pred, X, l2_coef, weights)\n",
        "            - self._grad(y, y_pred, X)\n",
        "        )\n",
        "\n",
        "    def _get_loss(self, loss: str) -> callable:\n",
        "        \"\"\"\n",
        "        Get loss function for calculation.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        loss : str\n",
        "            Loss name\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        callable\n",
        "            Metric function\n",
        "        \"\"\"\n",
        "\n",
        "        _losses = {\n",
        "            \"l1\": self._l1_loss,\n",
        "            \"l2\": self._l2_loss,\n",
        "            \"elasticnet\": self._elasticnet_loss,\n",
        "            None: self._loss,\n",
        "        }\n",
        "        return _losses[loss]\n",
        "\n",
        "    def _get_grad(self, loss: str) -> callable:\n",
        "        \"\"\"\n",
        "        Get gradient function for calculation.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        loss : str\n",
        "            Loss name\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        callable\n",
        "            Metric function\n",
        "        \"\"\"\n",
        "\n",
        "        _grads = {\n",
        "            \"l1\": self._l1_grad,\n",
        "            \"l2\": self._l2_grad,\n",
        "            \"elasticnet\": self._elasticnet_grad,\n",
        "            None: self._grad,\n",
        "        }\n",
        "        return _grads[loss]\n",
        "\n",
        "    def _get_metrics(self, metric: str) -> callable:\n",
        "        \"\"\"\n",
        "        Get metric function for calculation.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        metric : str\n",
        "            Metric name\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        callable\n",
        "            Metric function\n",
        "        \"\"\"\n",
        "\n",
        "        _metrics = {\n",
        "            \"accuracy\": self._accuracy,\n",
        "            \"precision\": self._precision,\n",
        "            \"recall\": self._recall,\n",
        "            \"f1\": self._f1,\n",
        "            \"roc_auc\": self._roc_auc,\n",
        "            None: self._accuracy,\n",
        "        }\n",
        "        return _metrics[metric]\n",
        "\n",
        "    def fit(self, X: pd.DataFrame, y: pd.Series, verbose: int = False) -> None:\n",
        "        \"\"\"\n",
        "        Fit logistic regression.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : pd.DataFrame\n",
        "            Training data\n",
        "        y : pd.Series\n",
        "            True values\n",
        "        verbose : int, optional\n",
        "            Verbosity of training, by default False\n",
        "        \"\"\"\n",
        "        random.seed(self.random_state)\n",
        "\n",
        "        n_samples, n_features = X.shape\n",
        "        X = pd.concat([pd.DataFrame({\"bias\": [1] * n_samples}), X.reset_index(drop=True)], axis=1)\n",
        "        self.weights = np.ones(n_features + 1)\n",
        "\n",
        "        if isinstance(self.sgd_sample, int):\n",
        "            n_samples = self.sgd_sample\n",
        "        elif isinstance(self.sgd_sample, float):\n",
        "            n_samples = int(np.round(self.sgd_sample * X.shape[0]))\n",
        "\n",
        "        for i in range(1, self.n_iter + 1):\n",
        "            # sample_rows_idx = random.sample(range(X.shape[0]), n_samples)\n",
        "            y_pred = self._sigmoid(np.dot(X.values, self.weights))\n",
        "            loss = self._get_loss(self.reg)(\n",
        "                y=y,\n",
        "                y_pred=y_pred,\n",
        "                l1_coef=self.l1_coef,\n",
        "                l2_coef=self.l2_coef,\n",
        "                weights=self.weights,\n",
        "            )\n",
        "            self._best_score = self._get_metrics(self.metric)(y, y_pred)\n",
        "            if verbose and i == 1:\n",
        "                print(\n",
        "                    f\"start | loss: {loss}\"\n",
        "                    + (f\"| {self.metric}: {self._best_score}\" if self.metric else \"\")\n",
        "                )\n",
        "            if verbose and i % verbose == 0:\n",
        "                print(\n",
        "                    f\"{i} | loss: {loss}\"\n",
        "                    + (f\"| {self.metric}: {self._best_score}\" if self.metric else \"\")\n",
        "                )\n",
        "            grad = self._get_grad(self.reg)(\n",
        "                y=y,\n",
        "                y_pred=y_pred,\n",
        "                X=X,\n",
        "                # y=y.iloc[sample_rows_idx],\n",
        "                # y_pred=y_pred[sample_rows_idx],\n",
        "                # X=X.iloc[sample_rows_idx],\n",
        "                l1_coef=self.l1_coef,\n",
        "                l2_coef=self.l2_coef,\n",
        "                weights=self.weights,\n",
        "            )\n",
        "            if callable(self.learning_rate):\n",
        "                learning_rate = self.learning_rate(i)\n",
        "            elif isinstance(self.learning_rate, (int, float)):\n",
        "                learning_rate = self.learning_rate\n",
        "            self.weights -= learning_rate * grad\n",
        "\n",
        "        self._best_score = self._get_metrics(self.metric)(\n",
        "            y, self._sigmoid(np.dot(X.values, self.weights))\n",
        "        )\n",
        "\n",
        "    def predict_proba(self, X: pd.DataFrame) -> np.array:\n",
        "        \"\"\"\n",
        "        Predict probabilities using the trained model.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : pd.DataFrame\n",
        "            Data for prediction\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        np.array\n",
        "            Predicted values\n",
        "        \"\"\"\n",
        "        n_samples, n_features = X.shape\n",
        "        X = pd.concat([pd.DataFrame({\"bias\": [1] * n_samples}), X.reset_index(drop=True)], axis=1)\n",
        "        y_pred = self._sigmoid(np.dot(X.values, self.weights))\n",
        "        return y_pred\n",
        "\n",
        "    def predict(self, X: pd.DataFrame) -> np.array:\n",
        "        \"\"\"\n",
        "        Predict using the trained model.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : pd.DataFrame\n",
        "            Data for prediction\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        np.array\n",
        "            Predicted values\n",
        "        \"\"\"\n",
        "        y_pred = self.predict_proba(X)\n",
        "        y_pred = np.where(y_pred > self._threshold, 1, 0)\n",
        "        return y_pred\n",
        "\n",
        "    def get_coef(self) -> np.array:\n",
        "        \"\"\"\n",
        "        Get logistic regression weights\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        np.array\n",
        "            Weights\n",
        "        \"\"\"\n",
        "        return self.weights[1:]\n",
        "\n",
        "    def get_best_score(self) -> float:\n",
        "        \"\"\"\n",
        "        Get last calculated score.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        float\n",
        "            Calculated value\n",
        "        \"\"\"\n",
        "        return self._best_score"
      ],
      "metadata": {
        "id": "HTjZGIYeMoz7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## learner clean for"
      ],
      "metadata": {
        "id": "OkhpijYAU-ET"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class MyLogRegP:\n",
        "    def __init__(\n",
        "        self,\n",
        "        n_iter: int = 10,\n",
        "        learning_rate: float = 0.1,\n",
        "        metric: str = None,\n",
        "        reg: str = None,\n",
        "        l1_coef: float = 0.0,\n",
        "        l2_coef: float = 0.0,\n",
        "        sgd_sample: float = None,\n",
        "        random_state: int = 42,\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Construct logistic regression class.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        n_iter : int, optional\n",
        "            Number of iterations, by default 100\n",
        "        learning_rate : float, optional\n",
        "            Learning rate, by default 3e-4\n",
        "        metric : str, optional\n",
        "            Metric to calculate during training, by default None\n",
        "        reg : str, optional\n",
        "            Type of regularization:\n",
        "            'l1', 'l2', 'elasticnet', by default None.\n",
        "        l1_coef : float, optional\n",
        "            L1 regularization coefficient, by default 0.0\n",
        "        l2_coef : float, optional\n",
        "            L2 regularization coefficient, by default 0.0\n",
        "        sgd_sample : float, optional\n",
        "            Stochastic gradient descent sample, by default None\n",
        "        random_state : int, optional\n",
        "            Random state, by default 42\n",
        "        \"\"\"\n",
        "\n",
        "        self.n_iter = n_iter\n",
        "        self.learning_rate = learning_rate\n",
        "        self.metric = metric\n",
        "        self.reg = reg\n",
        "        self.l1_coef = l1_coef\n",
        "        self.l2_coef = l2_coef\n",
        "        self._weights = None\n",
        "        self._eps = 1e-15\n",
        "        self._threshold = 0.5\n",
        "        self._best_score = None\n",
        "        self.sgd_sample = sgd_sample\n",
        "        self.random_state = random_state\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        \"\"\"\n",
        "        Get class representation in readable form.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        str\n",
        "            String with class representation\n",
        "        \"\"\"\n",
        "        class_name = type(self).__name__\n",
        "        return f\"{class_name} class: n_iter={self.n_iter}, learning_rate={self.learning_rate}\"\n",
        "\n",
        "    def _sigmoid(self, x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    def _confusion_matrix(self, y: np.array, y_pred: np.array) -> tuple:\n",
        "        \"\"\"\n",
        "        Calculate confusion matrix.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        y : np.array\n",
        "            True values\n",
        "        y_pred : np.array\n",
        "            Predicted values\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        tuple\n",
        "            TP, FN, FP, TN\n",
        "        \"\"\"\n",
        "        y_pred = np.where(y_pred > self._threshold, 1, 0)\n",
        "        TP = np.logical_and(y == 1, y_pred == 1).sum()\n",
        "        FN = np.logical_and(y == 1, y_pred == 0).sum()\n",
        "        FP = np.logical_and(y == 0, y_pred == 1).sum()\n",
        "        TN = np.logical_and(y == 0, y_pred == 0).sum()\n",
        "\n",
        "        return TP, FN, FP, TN\n",
        "\n",
        "    def _accuracy(self, y: np.array, y_pred: np.array) -> float:\n",
        "        \"\"\"\n",
        "        Calculate accuracy.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        y : np.array\n",
        "            True values\n",
        "        y_pred : np.array\n",
        "            Predicted values\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        float\n",
        "            Calculated metric\n",
        "        \"\"\"\n",
        "        TP, FN, FP, TN = self._confusion_matrix(y, y_pred)\n",
        "        return (TP + TN) / (TP + FN + FP + TN)\n",
        "\n",
        "    def _precision(self, sy: np.array, y_pred: np.array) -> float:\n",
        "        \"\"\"\n",
        "        Calculate precision.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        y : np.array\n",
        "            True values\n",
        "        y_pred : np.array\n",
        "            Predicted values\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        float\n",
        "            Calculated metric\n",
        "        \"\"\"\n",
        "        TP, _, FP, _ = self._confusion_matrix(y, y_pred)\n",
        "        return TP / (TP + FP)\n",
        "\n",
        "    def _recall(self, y: np.array, y_pred: np.array) -> float:\n",
        "        \"\"\"\n",
        "        Calculate recall.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        y : np.array\n",
        "            True values\n",
        "        y_pred : np.array\n",
        "            Predicted values\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        float\n",
        "            Calculated metric\n",
        "        \"\"\"\n",
        "        TP, FN, _, _ = self._confusion_matrix(y, y_pred)\n",
        "        return TP / (TP + FN)\n",
        "\n",
        "    def _f1(self, y: np.array, y_pred: np.array, beta: float = 1) -> float:\n",
        "        \"\"\"\n",
        "        Calculate F1 score.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        y : np.array\n",
        "            True values\n",
        "        y_pred : np.array\n",
        "            Predicted values\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        float\n",
        "            Calculated metric\n",
        "        \"\"\"\n",
        "        recall = self._recall(y, y_pred)\n",
        "        precision = self._precision(y, y_pred)\n",
        "\n",
        "        return (1 + beta**2) * (precision * recall) / (beta**2 * precision + recall)\n",
        "\n",
        "    def _roc_auc(self, y: np.array, y_prob: np.array, beta: float = 1) -> float:\n",
        "        \"\"\"\n",
        "        Calculate ROC AUC score.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        y : np.array\n",
        "            True values\n",
        "        y_prob : np.array\n",
        "            Predicted probabilities\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        float\n",
        "            Calculated metric\n",
        "        \"\"\"\n",
        "        positives = np.sum(y == 1)\n",
        "        negatives = np.sum(y == 0)\n",
        "\n",
        "        sorted_idx = np.argsort(-np.array(np.round(y_prob, 10)))\n",
        "        y_sorted = np.array(y)[sorted_idx]\n",
        "        y_prob_sorted = y_prob[sorted_idx]\n",
        "\n",
        "        roc_auc_score = 0\n",
        "\n",
        "        for prob, pred in zip(y_prob_sorted, y_sorted):\n",
        "            if pred == 0:\n",
        "                roc_auc_score += (\n",
        "                    np.sum(y_sorted[y_prob_sorted > prob])\n",
        "                    + np.sum(y_sorted[y_prob_sorted == prob]) / 2\n",
        "                )\n",
        "\n",
        "        roc_auc_score /= positives * negatives\n",
        "\n",
        "        return roc_auc_score\n",
        "\n",
        "    def _loss(self, y: np.array, y_pred: np.array, **kwargs) -> float:\n",
        "        \"\"\"\n",
        "        Calculate LogLoss.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        y : np.array\n",
        "            True values\n",
        "        y_pred : np.array\n",
        "            Predicted values\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        float\n",
        "            Calculated loss\n",
        "        \"\"\"\n",
        "        return -np.mean(y * np.log(y_pred + self._eps) + (1 - y) * np.log(1 - y_pred + self._eps))\n",
        "\n",
        "    def _l1_loss(\n",
        "        self, y: np.array, y_pred: np.array, l1_coef: float, weights: np.array, **kwargs\n",
        "    ) -> float:\n",
        "        \"\"\"\n",
        "        Calculate LogLoss with L1 regularization.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        y : np.array\n",
        "            True values\n",
        "        y_pred : np.array\n",
        "            Predicted values\n",
        "        l1_coef : float\n",
        "            L1 regularization coefficient\n",
        "        weights : np.array\n",
        "            Linear regression weights\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        float\n",
        "            Calculated loss\n",
        "        \"\"\"\n",
        "        return self._loss(y, y_pred) + l1_coef * np.sum(weights)\n",
        "\n",
        "    def _l2_loss(\n",
        "        self, y: np.array, y_pred: np.array, l2_coef: float, weights: np.array, **kwargs\n",
        "    ) -> float:\n",
        "        \"\"\"\n",
        "        Calculate LogLoss with L2 regularization.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        y : np.array\n",
        "            True values\n",
        "        y_pred : np.array\n",
        "            Predicted values\n",
        "        l2_coef : float\n",
        "            L2 regularization coefficient\n",
        "        weights : np.array\n",
        "            Linear regression weights\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        float\n",
        "            Calculated loss\n",
        "        \"\"\"\n",
        "        return self._loss(y, y_pred) + l2_coef * np.sum(weights**2)\n",
        "\n",
        "    def _elasticnet_loss(\n",
        "        self,\n",
        "        y: np.array,\n",
        "        y_pred: np.array,\n",
        "        l1_coef: float,\n",
        "        l2_coef: float,\n",
        "        weights: np.array,\n",
        "        **kwargs,\n",
        "    ) -> float:\n",
        "        \"\"\"\n",
        "        Calculate LogLoss with Elasticnet regularization.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        y : np.array\n",
        "            True values\n",
        "        y_pred : np.array\n",
        "            Predicted values\n",
        "        l1_coef : float\n",
        "            L1 regularization coefficient\n",
        "        l2_coef : float\n",
        "            L2 regularization coefficient\n",
        "        weights : np.array\n",
        "            Linear regression weights\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        float\n",
        "            Calculated loss\n",
        "        \"\"\"\n",
        "        return (\n",
        "            self._l1_loss(y, y_pred, l1_coef, weights)\n",
        "            + self._l2_loss(y, y_pred, l2_coef, weights)\n",
        "            - self._loss(y, y_pred)\n",
        "        )\n",
        "\n",
        "    def _grad(self, y: np.array, y_pred: np.array, X: np.array, **kwargs) -> np.array:\n",
        "        \"\"\"\n",
        "        Calculate gradient.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        y : np.array\n",
        "            True values\n",
        "        y_pred : np.array\n",
        "            Predicted values\n",
        "        X : np.array\n",
        "            Training data\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        np.array\n",
        "            Gradient vector\n",
        "        \"\"\"\n",
        "        return 1 / X.shape[0] * np.dot((y_pred - y), X.values)\n",
        "\n",
        "    def _l1_grad(\n",
        "        self,\n",
        "        y: np.array,\n",
        "        y_pred: np.array,\n",
        "        X: np.array,\n",
        "        l1_coef: float,\n",
        "        weights: np.array,\n",
        "        **kwargs,\n",
        "    ) -> np.array:\n",
        "        \"\"\"\n",
        "        Calculate gradient for L1 regularization.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        y : np.array\n",
        "            True values\n",
        "        y_pred : np.array\n",
        "            Predicted values\n",
        "        X : np.array\n",
        "            Training data\n",
        "        l1_coef : float\n",
        "            L1 regularization coefficient\n",
        "        weights : np.array\n",
        "            Linear regression weights\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        np.array\n",
        "            Gradient vector\n",
        "        \"\"\"\n",
        "        return self._grad(y, y_pred, X) + l1_coef * np.sign(weights)\n",
        "\n",
        "    def _l2_grad(\n",
        "        self,\n",
        "        y: np.array,\n",
        "        y_pred: np.array,\n",
        "        X: np.array,\n",
        "        l2_coef: float,\n",
        "        weights: np.array,\n",
        "        **kwargs,\n",
        "    ) -> np.array:\n",
        "        \"\"\"\n",
        "        Calculate gradient for L2 regularization.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        y : np.array\n",
        "            True values\n",
        "        y_pred : np.array\n",
        "            Predicted values\n",
        "        X : np.array\n",
        "            Training data\n",
        "        l2_coef : float\n",
        "            L2 regularization coefficient\n",
        "        weights : np.array\n",
        "            Linear regression weights\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        np.array\n",
        "            Gradient vector\n",
        "        \"\"\"\n",
        "        return self._grad(y, y_pred, X) + l2_coef * 2 * weights\n",
        "\n",
        "    def _elasticnet_grad(\n",
        "        self,\n",
        "        y: np.array,\n",
        "        y_pred: np.array,\n",
        "        X: np.array,\n",
        "        l1_coef: float,\n",
        "        l2_coef: float,\n",
        "        weights: np.array,\n",
        "        **kwargs,\n",
        "    ) -> np.array:\n",
        "        \"\"\"\n",
        "        Calculate gradient for Elasticnet regularization.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        y : np.array\n",
        "            True values\n",
        "        y_pred : np.array\n",
        "            Predicted values\n",
        "        X : np.array\n",
        "            Training data\n",
        "        l1_coef : float\n",
        "            L1 regularization coefficient\n",
        "        l2_coef : float\n",
        "            L2 regularization coefficient\n",
        "        weights : np.array\n",
        "            Linear regression weights\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        np.array\n",
        "            Gradient vector\n",
        "        \"\"\"\n",
        "        return (\n",
        "            self._l1_grad(y, y_pred, X, l1_coef, weights)\n",
        "            + self._l2_grad(y, y_pred, X, l2_coef, weights)\n",
        "            - self._grad(y, y_pred, X)\n",
        "        )\n",
        "\n",
        "    def _get_loss(self, loss: str) -> callable:\n",
        "        \"\"\"\n",
        "        Get loss function for calculation.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        loss : str\n",
        "            Loss name\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        callable\n",
        "            Metric function\n",
        "        \"\"\"\n",
        "\n",
        "        _losses = {\n",
        "            \"l1\": self._l1_loss,\n",
        "            \"l2\": self._l2_loss,\n",
        "            \"elasticnet\": self._elasticnet_loss,\n",
        "            None: self._loss,\n",
        "        }\n",
        "        return _losses[loss]\n",
        "\n",
        "    def _get_grad(self, loss: str) -> callable:\n",
        "        \"\"\"\n",
        "        Get gradient function for calculation.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        loss : str\n",
        "            Loss name\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        callable\n",
        "            Metric function\n",
        "        \"\"\"\n",
        "\n",
        "        _grads = {\n",
        "            \"l1\": self._l1_grad,\n",
        "            \"l2\": self._l2_grad,\n",
        "            \"elasticnet\": self._elasticnet_grad,\n",
        "            None: self._grad,\n",
        "        }\n",
        "        return _grads[loss]\n",
        "\n",
        "    def _get_metrics(self, metric: str) -> callable:\n",
        "        \"\"\"\n",
        "        Get metric function for calculation.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        metric : str\n",
        "            Metric name\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        callable\n",
        "            Metric function\n",
        "        \"\"\"\n",
        "\n",
        "        _metrics = {\n",
        "            \"accuracy\": self._accuracy,\n",
        "            \"precision\": self._precision,\n",
        "            \"recall\": self._recall,\n",
        "            \"f1\": self._f1,\n",
        "            \"roc_auc\": self._roc_auc,\n",
        "            None: self._accuracy,\n",
        "        }\n",
        "        return _metrics[metric]\n",
        "\n",
        "    def fit(self, X: pd.DataFrame, y: pd.Series, verbose: int = False) -> None:\n",
        "        \"\"\"\n",
        "        Fit logistic regression.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : pd.DataFrame\n",
        "            Training data\n",
        "        y : pd.Series\n",
        "            True values\n",
        "        verbose : int, optional\n",
        "            Verbosity of training, by default False\n",
        "        \"\"\"\n",
        "        #random.seed(self.random_state)\n",
        "\n",
        "        n_samples, n_features = X.shape\n",
        "        X = pd.concat([pd.DataFrame({\"bias\": [1] * n_samples}), X.reset_index(drop=True)], axis=1)\n",
        "        self.weights = np.ones(n_features + 1)\n",
        "\n",
        "        if isinstance(self.sgd_sample, int):\n",
        "            n_samples = self.sgd_sample\n",
        "        elif isinstance(self.sgd_sample, float):\n",
        "            n_samples = int(np.round(self.sgd_sample * X.shape[0]))\n",
        "\n",
        "        for i in range(1, self.n_iter + 1):\n",
        "            # sample_rows_idx = random.sample(range(X.shape[0]), n_samples)\n",
        "            y_pred = self._sigmoid(np.dot(X.values, self.weights))\n",
        "            loss = self._get_loss(self.reg)(\n",
        "                y=y,\n",
        "                y_pred=y_pred,\n",
        "                l1_coef=self.l1_coef,\n",
        "                l2_coef=self.l2_coef,\n",
        "                weights=self.weights,\n",
        "            )\n",
        "            self._best_score = self._get_metrics(self.metric)(y, y_pred)\n",
        "            if verbose and i == 1:\n",
        "                print(\n",
        "                    f\"start | loss: {loss}\"\n",
        "                    + (f\"| {self.metric}: {self._best_score}\" if self.metric else \"\")\n",
        "                )\n",
        "            if verbose and i % verbose == 0:\n",
        "                print(\n",
        "                    f\"{i} | loss: {loss}\"\n",
        "                    + (f\"| {self.metric}: {self._best_score}\" if self.metric else \"\")\n",
        "                )\n",
        "            grad = self._get_grad(self.reg)(\n",
        "                y=y,\n",
        "                y_pred=y_pred,\n",
        "                X=X,\n",
        "                l1_coef=self.l1_coef,\n",
        "                l2_coef=self.l2_coef,\n",
        "                weights=self.weights,\n",
        "            )\n",
        "            if callable(self.learning_rate):\n",
        "                learning_rate = self.learning_rate(i)\n",
        "            elif isinstance(self.learning_rate, (int, float)):\n",
        "                learning_rate = self.learning_rate\n",
        "            self.weights -= learning_rate * grad\n",
        "\n",
        "        self._best_score = self._get_metrics(self.metric)(\n",
        "            y, self._sigmoid(np.dot(X.values, self.weights))\n",
        "        )\n",
        "\n",
        "    def predict_proba(self, X: pd.DataFrame) -> np.array:\n",
        "        \"\"\"\n",
        "        Predict probabilities using the trained model.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : pd.DataFrame\n",
        "            Data for prediction\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        np.array\n",
        "            Predicted values\n",
        "        \"\"\"\n",
        "        n_samples, n_features = X.shape\n",
        "        X = pd.concat([pd.DataFrame({\"bias\": [1] * n_samples}), X.reset_index(drop=True)], axis=1)\n",
        "        y_pred = self._sigmoid(np.dot(X.values, self.weights))\n",
        "        return y_pred\n",
        "\n",
        "    def predict(self, X: pd.DataFrame) -> np.array:\n",
        "        \"\"\"\n",
        "        Predict using the trained model.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : pd.DataFrame\n",
        "            Data for prediction\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        np.array\n",
        "            Predicted values\n",
        "        \"\"\"\n",
        "        y_pred = self.predict_proba(X)\n",
        "        y_pred = np.where(y_pred > self._threshold, 1, 0)\n",
        "        return y_pred\n",
        "\n",
        "    def get_coef(self) -> np.array:\n",
        "        \"\"\"\n",
        "        Get logistic regression weights\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        np.array\n",
        "            Weights\n",
        "        \"\"\"\n",
        "        return self.weights[1:]\n",
        "\n",
        "    def get_best_score(self) -> float:\n",
        "        \"\"\"\n",
        "        Get last calculated score.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        float\n",
        "            Calculated value\n",
        "        \"\"\"\n",
        "        return self._best_score"
      ],
      "metadata": {
        "id": "cjryMG6EVA2J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = MyLogRegP(metric='roc_auc')\n",
        "# clf = MyLogReg()\n",
        "clf.fit(X, y, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYwuO_wTMvkL",
        "outputId": "8f4fa013-316e-4b29-be8c-4490244dbba7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "start | loss: 3.6736886876615524| roc_auc: 0.5326141304565218\n",
            "1 | loss: 3.6736886876615524| roc_auc: 0.5326141304565218\n",
            "2 | loss: 3.399345496011302| roc_auc: 0.5383301533206133\n",
            "3 | loss: 3.1414206361343004| roc_auc: 0.5452061808247233\n",
            "4 | loss: 2.9017043294408578| roc_auc: 0.5527142108568435\n",
            "5 | loss: 2.681294069812125| roc_auc: 0.5609102436409745\n",
            "6 | loss: 2.480888351294942| roc_auc: 0.5696102784411138\n",
            "7 | loss: 2.30062735806605| roc_auc: 0.5792103168412673\n",
            "8 | loss: 2.140094583056409| roc_auc: 0.5889743558974236\n",
            "9 | loss: 1.9981029436942546| roc_auc: 0.599750399001596\n",
            "10 | loss: 1.8729518266222966| roc_auc: 0.6106664426657706\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf.get_best_score()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1sjUcAuboEO3",
        "outputId": "810ca644-a5f6-4af9-e8a9-36da410a38e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ds = [0.91, 0.86, 0.78, 0.6, 0.6, 0.55, 0.51, 0.46, 0.42]\n",
        "# # ds = np.sort(ds)\n",
        "# cl_lst = [1, 0, 0, 1, 0, 1, 0, 0, 0, 0]\n",
        "\n",
        "ds = [ 0.91, 0.86, 0.78, 0.6, 0.6, 0.55, 0.51, 0.46, 0.42,]\n",
        "cl_lst = [1, 0, 0, 1, 0, 1, 0, 0, 0]\n",
        "# cl_lst = [9, 1, 2, 3, 4, 5, 6, 7, 8]\n",
        "len(ds), len(cl_lst)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3ap0Lp1p6cX",
        "outputId": "054df394-417d-492f-f3b4-c0b3565b27db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(zip(ds, cl_lst), columns=['Probability', 'Class'])\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "-m3hHlIT5l_C",
        "outputId": "fa50ae65-e4f9-4aec-e3e8-3093b68a49a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Probability  Class\n",
              "0         0.91      1\n",
              "1         0.86      0\n",
              "2         0.78      0\n",
              "3         0.60      1\n",
              "4         0.60      0\n",
              "5         0.55      1\n",
              "6         0.51      0\n",
              "7         0.46      0\n",
              "8         0.42      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9b063055-82ba-4e86-a543-2f13f1f2ed79\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Probability</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.91</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.86</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.78</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.60</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.60</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.55</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.51</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.46</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.42</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9b063055-82ba-4e86-a543-2f13f1f2ed79')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9b063055-82ba-4e86-a543-2f13f1f2ed79 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9b063055-82ba-4e86-a543-2f13f1f2ed79');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-69e27707-6330-4e77-a938-c839bc4fc342\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-69e27707-6330-4e77-a938-c839bc4fc342')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-69e27707-6330-4e77-a938-c839bc4fc342 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.sort_values(by='Probability', ascending=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "lDEuMm4x8nhg",
        "outputId": "0eda72c6-2088-4c89-cc60-f5884171a8ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Probability  Class\n",
              "0         0.91      1\n",
              "1         0.86      0\n",
              "2         0.78      0\n",
              "3         0.60      1\n",
              "4         0.60      0\n",
              "5         0.55      1\n",
              "6         0.51      0\n",
              "7         0.46      0\n",
              "8         0.42      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8c7c3479-ce47-4e66-9c70-8753b392aeec\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Probability</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.91</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.86</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.78</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.60</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.60</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.55</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.51</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.46</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.42</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8c7c3479-ce47-4e66-9c70-8753b392aeec')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8c7c3479-ce47-4e66-9c70-8753b392aeec button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8c7c3479-ce47-4e66-9c70-8753b392aeec');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a3b20160-5919-4dcd-92b4-8bd9b608d147\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a3b20160-5919-4dcd-92b4-8bd9b608d147')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a3b20160-5919-4dcd-92b4-8bd9b608d147 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(df[~(df['Probability'] == 0.6)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "mndYFUFtVE1z",
        "outputId": "a54f38f1-c4c8-477d-a69b-f5f8af5620d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Probability  Class\n",
              "0         0.91      1\n",
              "1         0.86      0\n",
              "2         0.78      0\n",
              "5         0.55      1\n",
              "6         0.51      0\n",
              "7         0.46      0\n",
              "8         0.42      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8d2b8a2a-bcfa-4243-b409-f148a17426b1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Probability</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.91</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.86</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.78</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.55</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.51</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.46</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.42</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8d2b8a2a-bcfa-4243-b409-f148a17426b1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8d2b8a2a-bcfa-4243-b409-f148a17426b1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8d2b8a2a-bcfa-4243-b409-f148a17426b1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d24e07c7-117a-416d-a838-30f2f5c6b75f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d24e07c7-117a-416d-a838-30f2f5c6b75f')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d24e07c7-117a-416d-a838-30f2f5c6b75f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['Class'][0:3].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fO-3_5UKFUJ3",
        "outputId": "fba1b314-b813-4e59-c437-115ae3d75667"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    2\n",
              "1    1\n",
              "Name: Class, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['Probability'] == 0.6"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7giajD6ImFl",
        "outputId": "f792624a-479e-478a-98fb-3b1a8acb3f9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    False\n",
              "1    False\n",
              "2    False\n",
              "3     True\n",
              "4     True\n",
              "5    False\n",
              "6    False\n",
              "7    False\n",
              "8    False\n",
              "Name: Probability, dtype: bool"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tot = 0\n",
        "total = 0\n",
        "\n",
        "for i in range(len(df)):\n",
        "    if df.iloc[i]['Class'] == 0:\n",
        "        prop = df.iloc[i]['Probability']\n",
        "        print('prop = ', prop)\n",
        "        l = len(df[df['Probability'] == prop])\n",
        "        print('l = ', l)\n",
        "        # print('counts', df['Class'][0:i].value_counts()[1])\n",
        "        if l == 1:\n",
        "            tot = df['Class'][0:i].value_counts()[1]\n",
        "        else:\n",
        "            df_mini_up = df[0:i]\n",
        "            df_mini_up = df_mini_up[~(df_mini_up['Probability'] == prop)]\n",
        "            df_mini_down = df[df['Probability'] == prop]\n",
        "\n",
        "            tot = df_mini_up['Class'].value_counts()[1] + df_mini_down['Class'].value_counts()[1] / len(df_mini_down)\n",
        "        print('tot', tot)\n",
        "        total += tot\n",
        "\n",
        "total / (3 * 6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZEzqH7HEdG_",
        "outputId": "35454f30-3a6b-4c90-ee03-cf589b50b651"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prop =  0.86\n",
            "l =  1\n",
            "tot 1\n",
            "prop =  0.78\n",
            "l =  1\n",
            "tot 1\n",
            "prop =  0.6\n",
            "l =  2\n",
            "tot 1.5\n",
            "prop =  0.51\n",
            "l =  1\n",
            "tot 3\n",
            "prop =  0.46\n",
            "l =  1\n",
            "tot 3\n",
            "prop =  0.42\n",
            "l =  1\n",
            "tot 3\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6944444444444444"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def sum_(row):\n",
        "#     if row['Class'] == 0\n",
        "#     return df['Class'][0:]"
      ],
      "metadata": {
        "id": "MOWb2HNQB9XH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N = df['Class'].value_counts()[0]\n",
        "P = df['Class'].value_counts()[1]"
      ],
      "metadata": {
        "id": "6QWav6Xo9lkO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# rocauc_score = (1 / (P * N)) * ()\n",
        "# rocauc_score"
      ],
      "metadata": {
        "id": "xP5osTSk-rb3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# q = 10\n",
        "\n",
        "# for i in range(q)\n",
        "#     for j in range(q):\n",
        "#         if ds[i] < ds[j]:\n",
        "#           a ="
      ],
      "metadata": {
        "id": "jNhC6BnE38Z7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df = zip(ds, cl_lst)\n",
        "# df"
      ],
      "metadata": {
        "id": "JGTTibyXwYbD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for i, j in df:\n",
        "#     print(i, j)"
      ],
      "metadata": {
        "id": "7Zx7IfRKwq8E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score\n",
        "X, y = load_breast_cancer(return_X_y=True)\n",
        "clf = LogisticRegression(solver=\"liblinear\", random_state=0).fit(X, y)\n",
        "roc_auc_score(y, clf.predict_proba(X)[:, 1])\n"
      ],
      "metadata": {
        "id": "wMmDwDf7zWS_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f440b032-b221-4d6e-a7d5-b21d6cc7bbb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.994767718408118"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# clf.predict_proba(X)[:, 1]"
      ],
      "metadata": {
        "id": "GSnqQZy9ziJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# y"
      ],
      "metadata": {
        "id": "Gatwmhhwze5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds = np.sort(ds)[::-1]\n",
        "# clas = ds"
      ],
      "metadata": {
        "id": "OtZszMYUr63x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "B = np.where(ds > 0.5, 1, 0)\n",
        "B"
      ],
      "metadata": {
        "id": "frnnlDF9spdF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fe585cb-f6d8-479b-e4cb-82942254cfff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 1, 1, 1, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2_2_10"
      ],
      "metadata": {
        "id": "FsE59OxxlAxf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyLogReg():\n",
        "    def __init__(self,\n",
        "                 n_iter: int = 100,\n",
        "                 learning_rate: float = 0.1,\n",
        "                 metric:str = None,\n",
        "                 reg: str = None,\n",
        "                 l1_coef: float = 0.,\n",
        "                 l2_coef: float = 0.,) -> None:\n",
        "\n",
        "        self.n_iter = n_iter\n",
        "        self.learning_rate = learning_rate\n",
        "        self.metric = metric\n",
        "        self.reg = reg\n",
        "        self.l1_coef = l1_coef\n",
        "        self.l2_coef = l2_coef\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"MyLogReg class: n_iter={self.n_iter}, learning_rate={self.learning_rate}\"\n",
        "\n",
        "    def predict_proba(self, X: pd.DataFrame):\n",
        "        X = pd.concat([pd.DataFrame([1] * X.shape[0]), X], axis=1)\n",
        "        return 1 / (1 + np.exp(-np.dot(X, self.weights)))\n",
        "\n",
        "    def predict(self, X: pd.DataFrame) -> pd.Series:\n",
        "        return (self.predict_proba(X) > 0.5).astype(int)\n",
        "\n",
        "    @staticmethod\n",
        "    def confusion_measure(y, y_pred):\n",
        "        TP = 0\n",
        "        FP = 0\n",
        "        TN = 0\n",
        "        FN = 0\n",
        "\n",
        "        for i in range(len(y_pred)):\n",
        "            if y[i] == y_pred[i] == 1:\n",
        "               TP += 1\n",
        "            if y_pred[i] == 1 and y[i] != y_pred[i]:\n",
        "               FP += 1\n",
        "            if y[i] == y_pred[i] == 0:\n",
        "               TN += 1\n",
        "            if y_pred[i] == 0 and y[i] != y_pred[i]:\n",
        "               FN += 1\n",
        "\n",
        "        return(TP, FP, TN, FN)\n",
        "\n",
        "    @staticmethod\n",
        "    def get_metric_score(metric: str, y_true, y_pred):\n",
        "        if metric != 'roc_auc':\n",
        "            TP, FP, TN, FN = MyLogReg.confusion_measure(y_true, y_pred)\n",
        "\n",
        "            if metric == 'accuracy':\n",
        "                score = (TP + TN) / (TP + FP + TN + FN)\n",
        "            elif metric == 'precision':\n",
        "                score = (TP) / (TP + FP)\n",
        "            elif metric == 'recall':\n",
        "                score = (TP) / (TP + FN)\n",
        "            elif metric == 'f1':\n",
        "                precision = (TP) / (TP + FP)\n",
        "                recall = (TP) / (TP + FN)\n",
        "                score = 2 * precision * recall / (precision + recall)\n",
        "        else:\n",
        "            y_pred = y_pred.round(10)\n",
        "            df_ = pd.DataFrame(zip(y_pred, y_true), columns=['Probability', 'Class'])\n",
        "            df_ = df_.sort_values(by='Probability', ascending=False)\n",
        "\n",
        "            N = df_['Class'].value_counts()[0]\n",
        "            P = df_['Class'].value_counts()[1]\n",
        "\n",
        "            total = 0\n",
        "\n",
        "            for i in range(len(df_)):\n",
        "                if df_.iloc[i]['Class'] == 0:\n",
        "                    prop = df_.iloc[i]['Probability']\n",
        "                    l = len(df_[df_['Probability'] == prop])\n",
        "\n",
        "                    if l == 1:\n",
        "                        tot = df_['Class'][0:i].value_counts()[1]\n",
        "                    else:\n",
        "                        df_mini_up = df_[0:i]\n",
        "                        df_mini_up = df_mini_up[~(df_mini_up['Probability'] == prop)]\n",
        "                        df_mini_down = df_[df_['Probability'] == prop]\n",
        "\n",
        "                        tot = df_mini_up['Class'].value_counts()[1] + df_mini_down['Class'].value_counts()[1] / len(df_mini_down)\n",
        "\n",
        "                    total += tot\n",
        "\n",
        "            score = total / (P * N)\n",
        "\n",
        "        return score\n",
        "\n",
        "    def get_best_score(self):\n",
        "        return self.score\n",
        "\n",
        "    def grad(self, y: pd.Series, y_pred: pd.Series, X: pd.DataFrame) -> pd.Series:\n",
        "          if not self.reg:\n",
        "              grad = (y_pred - y) @ X / y.shape[0]\n",
        "          elif self.reg == 'l1':\n",
        "              grad = (y_pred - y) @ X / y.shape[0] + self.l1_coef * np.sign(self.weights)\n",
        "          elif self.reg == 'l2':\n",
        "              grad = (y_pred - y) @ X / y.shape[0] + self.l2_coef * 2 * (self.weights)\n",
        "          elif self.reg == 'elasticnet':\n",
        "              grad = (y_pred - y) @ X / y.shape[0] + self.l1_coef * np.sign(self.weights) + self.l2_coef * 2 * (self.weights)\n",
        "\n",
        "          return grad\n",
        "\n",
        "    def logloss(self, y: pd.Series, y_pred: pd.Series, eps=1e-15) -> float:\n",
        "        loss = -(y * (np.log(y_pred + eps)) + (1 - y) * np.log(1 - y_pred + eps)).mean()\n",
        "        return loss\n",
        "\n",
        "    def get_coef(self):\n",
        "        return self.weights[1:]\n",
        "\n",
        "    def fit(self, X: pd.DataFrame, y: pd.Series, verbose: int = False):\n",
        "        X = pd.concat([pd.DataFrame([1] * X.shape[0]), X], axis=1)\n",
        "        self.weights = np.ones(X.shape[1])\n",
        "\n",
        "        for i in range(self.n_iter):\n",
        "            y_hat = self.predict_proba(X.iloc[:, 1:])\n",
        "            loss = self.logloss(y, y_hat)\n",
        "            nabla = self.grad(y, y_hat, X)\n",
        "            self.weights -= self.learning_rate * nabla\n",
        "\n",
        "            if self.metric:\n",
        "                if self.metric != 'roc_auc':\n",
        "                    y_pred = self.predict(X.iloc[:, 1:])\n",
        "                    self.score = getattr(self, 'get_metric_score')(self.metric, y, y_pred)\n",
        "                else:\n",
        "                    self.score = getattr(self, 'get_metric_score')(self.metric, y, y_hat)\n",
        "\n",
        "            if verbose and i % verbose == 0:\n",
        "                if self.metric:\n",
        "                   print(f'start | loss = {loss} | {self.metric} = {self.score} | learning_rate = {self.learning_rate}') if i == 0 else print(f'i = {i} | loss = {loss} | {self.metric} = {self.score} | learning_rate = {self.learning_rate}')\n",
        "                else:\n",
        "                   print(f'start | loss = {loss} | learning_rate = {self.learning_rate}') if i == 0 else print(f'i = {i} | loss = {loss} | learning_rate = {self.learning_rate}')\n"
      ],
      "metadata": {
        "id": "yh0GiT7MlC3Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2_2_11"
      ],
      "metadata": {
        "id": "eH35AW42qsh6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyLogReg():\n",
        "    def __init__(self,\n",
        "                 n_iter: int = 100,\n",
        "                 learning_rate: float = 0.1,\n",
        "                 metric:str = None,\n",
        "                 reg: str = None,\n",
        "                 l1_coef: float = 0.,\n",
        "                 l2_coef: float = 0.,) -> None:\n",
        "\n",
        "        self.n_iter = n_iter\n",
        "        self.learning_rate = learning_rate\n",
        "        self.metric = metric\n",
        "        self.reg = reg\n",
        "        self.l1_coef = l1_coef\n",
        "        self.l2_coef = l2_coef\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"MyLogReg class: n_iter={self.n_iter}, learning_rate={self.learning_rate}\"\n",
        "\n",
        "    def predict_proba(self, X: pd.DataFrame):\n",
        "        X = pd.concat([pd.DataFrame([1] * X.shape[0]), X], axis=1)\n",
        "        return 1 / (1 + np.exp(-np.dot(X, self.weights)))\n",
        "\n",
        "    def predict(self, X: pd.DataFrame) -> pd.Series:\n",
        "        return (self.predict_proba(X) > 0.5).astype(int)\n",
        "\n",
        "    @staticmethod\n",
        "    def confusion_measure(y, y_pred):\n",
        "        TP = 0\n",
        "        FP = 0\n",
        "        TN = 0\n",
        "        FN = 0\n",
        "\n",
        "        for i in range(len(y_pred)):\n",
        "            if y[i] == y_pred[i] == 1:\n",
        "               TP += 1\n",
        "            if y_pred[i] == 1 and y[i] != y_pred[i]:\n",
        "               FP += 1\n",
        "            if y[i] == y_pred[i] == 0:\n",
        "               TN += 1\n",
        "            if y_pred[i] == 0 and y[i] != y_pred[i]:\n",
        "               FN += 1\n",
        "\n",
        "        return(TP, FP, TN, FN)\n",
        "\n",
        "    @staticmethod\n",
        "    def get_metric_score(metric: str, y_true, y_pred):\n",
        "        if metric != 'roc_auc':\n",
        "            TP, FP, TN, FN = MyLogReg.confusion_measure(y_true, y_pred)\n",
        "\n",
        "            if metric == 'accuracy':\n",
        "                score = (TP + TN) / (TP + FP + TN + FN)\n",
        "            elif metric == 'precision':\n",
        "                score = (TP) / (TP + FP)\n",
        "            elif metric == 'recall':\n",
        "                score = (TP) / (TP + FN)\n",
        "            elif metric == 'f1':\n",
        "                precision = (TP) / (TP + FP)\n",
        "                recall = (TP) / (TP + FN)\n",
        "                score = 2 * precision * recall / (precision + recall)\n",
        "        else:\n",
        "            y_pred = y_pred.round(10)\n",
        "            df_ = pd.DataFrame(zip(y_pred, y_true), columns=['Probability', 'Class'])\n",
        "            df_ = df_.sort_values(by='Probability', ascending=False)\n",
        "\n",
        "            N = df_['Class'].value_counts()[0]\n",
        "            P = df_['Class'].value_counts()[1]\n",
        "\n",
        "            total = 0\n",
        "\n",
        "            for i in range(len(df_)):\n",
        "                if df_.iloc[i]['Class'] == 0:\n",
        "                    prop = df_.iloc[i]['Probability']\n",
        "                    l = len(df_[df_['Probability'] == prop])\n",
        "\n",
        "                    if l == 1:\n",
        "                        tot = df_['Class'][0:i].value_counts()[1]\n",
        "                    else:\n",
        "                        df_mini_up = df_[0:i]\n",
        "                        df_mini_up = df_mini_up[~(df_mini_up['Probability'] == prop)]\n",
        "                        df_mini_down = df_[df_['Probability'] == prop]\n",
        "\n",
        "                        tot = df_mini_up['Class'].value_counts()[1] + df_mini_down['Class'].value_counts()[1] / len(df_mini_down)\n",
        "\n",
        "                    total += tot\n",
        "\n",
        "            score = total / (P * N)\n",
        "\n",
        "        return score\n",
        "\n",
        "    def get_best_score(self):\n",
        "        return self.score\n",
        "\n",
        "    def grad(self, y: pd.Series, y_pred: pd.Series, X: pd.DataFrame) -> pd.Series:\n",
        "          if not self.reg:\n",
        "              grad = (y_pred - y) @ X / y.shape[0]\n",
        "          elif self.reg == 'l1':\n",
        "              grad = (y_pred - y) @ X / y.shape[0] + self.l1_coef * np.sign(self.weights)\n",
        "          elif self.reg == 'l2':\n",
        "              grad = (y_pred - y) @ X / y.shape[0] + self.l2_coef * 2 * (self.weights)\n",
        "          elif self.reg == 'elasticnet':\n",
        "              grad = (y_pred - y) @ X / y.shape[0] + self.l1_coef * np.sign(self.weights) + self.l2_coef * 2 * (self.weights)\n",
        "\n",
        "          return grad\n",
        "\n",
        "    def logloss(self, y: pd.Series, y_pred: pd.Series, eps=1e-15) -> float:\n",
        "        loss = -(y * (np.log(y_pred + eps)) + (1 - y) * np.log(1 - y_pred + eps)).mean()\n",
        "        return loss\n",
        "\n",
        "    def get_coef(self):\n",
        "        return self.weights[1:]\n",
        "\n",
        "    def fit(self, X: pd.DataFrame, y: pd.Series, verbose: int = False):\n",
        "        X = pd.concat([pd.DataFrame([1] * X.shape[0]), X], axis=1)\n",
        "        self.weights = np.ones(X.shape[1])\n",
        "\n",
        "        for i in range(self.n_iter):\n",
        "            y_hat = self.predict_proba(X.iloc[:, 1:])\n",
        "            loss = self.logloss(y, y_hat)\n",
        "            nabla = self.grad(y, y_hat, X)\n",
        "\n",
        "            if isinstance(self.learning_rate, (int, float)):\n",
        "                self.weights -= self.learning_rate * nabla\n",
        "            else:\n",
        "                self.weights -= self.learning_rate(i + 1) * nabla\n",
        "\n",
        "            if self.metric:\n",
        "                if self.metric != 'roc_auc':\n",
        "                    y_pred = self.predict(X.iloc[:, 1:])\n",
        "                    self.score = getattr(self, 'get_metric_score')(self.metric, y, y_pred)\n",
        "                else:\n",
        "                    self.score = getattr(self, 'get_metric_score')(self.metric, y, y_hat)\n",
        "\n",
        "            if verbose and i % verbose == 0:\n",
        "                if self.metric:\n",
        "                   print(f'start | loss = {loss} | {self.metric} = {self.score} | learning_rate = {self.learning_rate}') if i == 0 else print(f'i = {i} | loss = {loss} | {self.metric} = {self.score} | learning_rate = {self.learning_rate}')\n",
        "                else:\n",
        "                   print(f'start | loss = {loss} | learning_rate = {self.learning_rate}') if i == 0 else print(f'i = {i} | loss = {loss} | learning_rate = {self.learning_rate}')\n"
      ],
      "metadata": {
        "id": "k0ZgneDCqupi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2_2_12"
      ],
      "metadata": {
        "id": "FmPBOJtPrzX0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_classification\n",
        "\n",
        "# X_mk, y_mk = make_classification(n_samples=5, n_features=3)\n",
        "X_mk, y_mk = make_classification(n_samples=1000, n_features=14, n_informative=10, random_state=42)\n",
        "X_mk = pd.DataFrame(X_mk)\n",
        "y_mk = pd.Series(y_mk)\n",
        "X_mk.columns = [f'col_{col}' for col in X_mk.columns]"
      ],
      "metadata": {
        "id": "2JHtZMv0haCs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.datasets import make_classification\n",
        "\n",
        "# X, y = make_classification(n_samples=1000, n_features=14, n_informative=10, random_state=42)\n",
        "# X = pd.DataFrame(X)\n",
        "# y = pd.Series(y)\n",
        "# X.columns = [f'col_{col}' for col in X.columns]"
      ],
      "metadata": {
        "id": "Ks5iIhBenjBK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = X_mk.copy()\n",
        "y = y_mk.copy()\n",
        "\n",
        "class MyLogReg():\n",
        "    def __init__(self,\n",
        "                 n_iter: int = 10,\n",
        "                 learning_rate: float = 0.1,\n",
        "                 metric:str = None,\n",
        "                 reg: str = None,\n",
        "                 l1_coef: float = 0.,\n",
        "                 l2_coef: float = 0.,\n",
        "                 sgd_sample: float = None,\n",
        "                 random_state: int = 42) -> None:\n",
        "\n",
        "        self.n_iter = n_iter\n",
        "        self.learning_rate = learning_rate\n",
        "        self.metric = metric\n",
        "        self.reg = reg\n",
        "        self.l1_coef = l1_coef\n",
        "        self.l2_coef = l2_coef\n",
        "        self.sgd_sample = sgd_sample\n",
        "        random.seed(random_state)\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"MyLogReg class: n_iter={self.n_iter}, learning_rate={self.learning_rate}\"\n",
        "\n",
        "    def predict_proba(self, X: pd.DataFrame):\n",
        "        X = pd.concat([pd.DataFrame([1] * X.shape[0]), X], axis=1)\n",
        "        return 1 / (1 + np.exp(-np.dot(X, self.weights)))\n",
        "\n",
        "    def predict(self, X: pd.DataFrame) -> pd.Series:\n",
        "        return (self.predict_proba(X) > 0.5).astype(int)\n",
        "\n",
        "    def get_batch(self, x_length):\n",
        "        return random.sample(range(x_length), int(self.sgd_sample * x_length)) if isinstance(self.sgd_sample, float) else random.sample(range(x_length), self.sgd_sample)\n",
        "\n",
        "    @staticmethod\n",
        "    def confusion_measure(y, y_pred):\n",
        "        TP = 0\n",
        "        FP = 0\n",
        "        TN = 0\n",
        "        FN = 0\n",
        "\n",
        "        for i in range(len(y_pred)):\n",
        "            if y[i] == y_pred[i] == 1:\n",
        "               TP += 1\n",
        "            if y_pred[i] == 1 and y[i] != y_pred[i]:\n",
        "               FP += 1\n",
        "            if y[i] == y_pred[i] == 0:\n",
        "               TN += 1\n",
        "            if y_pred[i] == 0 and y[i] != y_pred[i]:\n",
        "               FN += 1\n",
        "\n",
        "        return(TP, FP, TN, FN)\n",
        "\n",
        "    @staticmethod\n",
        "    def get_metric_score(metric: str, y_true, y_pred):\n",
        "        if metric != 'roc_auc':\n",
        "            TP, FP, TN, FN = MyLogReg.confusion_measure(y_true, y_pred)\n",
        "\n",
        "            if metric == 'accuracy':\n",
        "                score = (TP + TN) / (TP + FP + TN + FN)\n",
        "            elif metric == 'precision':\n",
        "                score = (TP) / (TP + FP)\n",
        "            elif metric == 'recall':\n",
        "                score = (TP) / (TP + FN)\n",
        "            elif metric == 'f1':\n",
        "                precision = (TP) / (TP + FP)\n",
        "                recall = (TP) / (TP + FN)\n",
        "                score = 2 * precision * recall / (precision + recall)\n",
        "        else:\n",
        "            y_pred = y_pred.round(10)\n",
        "            df_ = pd.DataFrame(zip(y_pred, y_true), columns=['Probability', 'Class'])\n",
        "            df_ = df_.sort_values(by='Probability', ascending=False)\n",
        "\n",
        "            N = df_['Class'].value_counts()[0]\n",
        "            P = df_['Class'].value_counts()[1]\n",
        "\n",
        "            total = 0\n",
        "\n",
        "            for i in range(len(df_)):\n",
        "                if df_.iloc[i]['Class'] == 0:\n",
        "                    prop = df_.iloc[i]['Probability']\n",
        "                    l = len(df_[df_['Probability'] == prop])\n",
        "\n",
        "                    if l == 1:\n",
        "                        tot = df_['Class'][0:i].value_counts()[1]\n",
        "                    else:\n",
        "                        df_mini_up = df_[0:i]\n",
        "                        df_mini_up = df_mini_up[~(df_mini_up['Probability'] == prop)]\n",
        "                        df_mini_down = df_[df_['Probability'] == prop]\n",
        "\n",
        "                        tot = df_mini_up['Class'].value_counts()[1] + df_mini_down['Class'].value_counts()[1] / len(df_mini_down)\n",
        "\n",
        "                    total += tot\n",
        "\n",
        "            score = total / (P * N)\n",
        "\n",
        "        return score\n",
        "\n",
        "    def get_best_score(self):\n",
        "        return self.score\n",
        "\n",
        "    def grad(self, y: pd.Series, y_pred: pd.Series, X: pd.DataFrame, batch_idxs: list) -> pd.Series:\n",
        "\n",
        "          y = y.iloc[batch_idxs]\n",
        "          y_pred = y_pred[batch_idxs]\n",
        "          X = X.iloc[batch_idxs, :]\n",
        "\n",
        "          if not self.reg:\n",
        "              grad = (y_pred - y) @ X / y.shape[0]\n",
        "          elif self.reg == 'l1':\n",
        "              grad = (y_pred - y) @ X / y.shape[0] + self.l1_coef * np.sign(self.weights)\n",
        "          elif self.reg == 'l2':\n",
        "              grad = (y_pred - y) @ X / y.shape[0] + self.l2_coef * 2 * (self.weights)\n",
        "          elif self.reg == 'elasticnet':\n",
        "              grad = (y_pred - y) @ X / y.shape[0] + self.l1_coef * np.sign(self.weights) + self.l2_coef * 2 * (self.weights)\n",
        "\n",
        "          return grad\n",
        "\n",
        "    def loss(self, y: pd.Series, y_pred: pd.DataFrame) -> float:\n",
        "        if self.reg == 'None':\n",
        "            loss = MyLogReg.logloss(y, y_pred)\n",
        "        elif self.reg == 'l1':\n",
        "            loss = MyLogReg.logloss(y, y_pred) + \\\n",
        "                self.l1_coef * np.sum(self.weights)\n",
        "        elif self.reg == 'l2':\n",
        "            loss = MyLogReg.logloss(y, y_pred) + \\\n",
        "                self.l2_coef * np.sum(self.weights**2)\n",
        "        else:\n",
        "            loss = MyLogReg.logloss(y, y_pred) + \\\n",
        "                self.l1_coef * np.sum(self.weights) + \\\n",
        "                self.l2_coef * np.sum(self.weights**2)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    @staticmethod\n",
        "    def logloss(y: pd.Series, y_pred: pd.Series, eps=1e-15) -> float:\n",
        "        loss = -(y * (np.log(y_pred + eps)) + (1 - y) * np.log(1 - y_pred + eps)).mean()\n",
        "        return loss\n",
        "\n",
        "    def get_coef(self):\n",
        "        return self.weights[1:]\n",
        "\n",
        "    def fit(self, X: pd.DataFrame, y: pd.Series, verbose: int = False):\n",
        "        X = pd.concat([pd.DataFrame([1] * X.shape[0], index=X.index), X], axis=1)\n",
        "        self.weights = np.ones(X.shape[1])\n",
        "\n",
        "        for i in range(self.n_iter):\n",
        "            sample_rows_idx = self.get_batch(X.shape[0]) if self.sgd_sample else range(X.shape[0])\n",
        "\n",
        "            y_hat = self.predict_proba(X.iloc[:, 1:])\n",
        "            loss = self.loss(y, y_hat)\n",
        "            nabla = self.grad(y, y_hat, X, sample_rows_idx)\n",
        "\n",
        "            if isinstance(self.learning_rate, (int, float)):\n",
        "                self.weights -= self.learning_rate * nabla\n",
        "            else:\n",
        "                self.weights -= self.learning_rate(i + 1) * nabla\n",
        "\n",
        "            if self.metric:\n",
        "                if self.metric != 'roc_auc':\n",
        "                    y_pred = self.predict(X.iloc[:, 1:])\n",
        "                    self.score = getattr(self, 'get_metric_score')(self.metric, y, y_pred)\n",
        "                else:\n",
        "                    self.score = getattr(self, 'get_metric_score')(self.metric, y, y_hat)\n",
        "\n",
        "            if verbose and i % verbose == 0:\n",
        "                if self.metric:\n",
        "                   print(f'start | loss = {loss} | {self.metric} = {self.score} | learning_rate = {self.learning_rate}') if i == 0 else print(f'i = {i} | loss = {loss} | {self.metric} = {self.score} | learning_rate = {self.learning_rate}')\n",
        "                else:\n",
        "                   print(f'start | loss = {loss} | learning_rate = {self.learning_rate}') if i == 0 else print(f'i = {i} | loss = {loss} | learning_rate = {self.learning_rate}')\n",
        "\n",
        "\n",
        "clf = MyLogReg(sgd_sample=0.1)\n",
        "# clf = MyLogReg()\n",
        "clf.fit(X, y, verbose=1)"
      ],
      "metadata": {
        "id": "DFmFg4qbr1ty",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4af29ddb-4c4e-4ade-a4c4-4e29c0d6a752"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "start | loss = 3.6736886876615524 | learning_rate = 0.1\n",
            "i = 1 | loss = 3.4241851254786493 | learning_rate = 0.1\n",
            "i = 2 | loss = 3.157886767435104 | learning_rate = 0.1\n",
            "i = 3 | loss = 2.9537891625262236 | learning_rate = 0.1\n",
            "i = 4 | loss = 2.8121736390373675 | learning_rate = 0.1\n",
            "i = 5 | loss = 2.5770024605245156 | learning_rate = 0.1\n",
            "i = 6 | loss = 2.3308388074218422 | learning_rate = 0.1\n",
            "i = 7 | loss = 2.1964325366398385 | learning_rate = 0.1\n",
            "i = 8 | loss = 2.0130395000232495 | learning_rate = 0.1\n",
            "i = 9 | loss = 1.8933371570144186 | learning_rate = 0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start | loss: 3.6736886876615524\n",
        "1 | loss: 3.6736886876615524\n",
        "2 | loss: 3.4241851254786493\n",
        "3 | loss: 3.157886767435104\n",
        "4 | loss: 2.9537891625262236\n",
        "5 | loss: 2.8121736390373675\n",
        "6 | loss: 2.5770024605245156\n",
        "7 | loss: 2.3308388074218422\n",
        "8 | loss: 2.1964325366398385\n",
        "9 | loss: 2.0130395000232495\n",
        "10 | loss: 1.8933371570144186"
      ],
      "metadata": {
        "id": "oZ3HTGrx9XAI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# wright\n",
        "\n",
        "class MyLogReg():\n",
        "    def __init__(self,\n",
        "                 n_iter: int = 10,\n",
        "                 learning_rate: float = 0.1,\n",
        "                 metric:str = None,\n",
        "                 reg: str = None,\n",
        "                 l1_coef: float = 0.,\n",
        "                 l2_coef: float = 0.,\n",
        "                 sgd_sample: float = None,\n",
        "                 random_state: int = 42) -> None:\n",
        "\n",
        "        self.n_iter = n_iter\n",
        "        self.learning_rate = learning_rate\n",
        "        self.metric = metric\n",
        "        self.reg = reg\n",
        "        self.l1_coef = l1_coef\n",
        "        self.l2_coef = l2_coef\n",
        "        self.sgd_sample = sgd_sample\n",
        "        random.seed(random_state)\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"MyLogReg class: n_iter={self.n_iter}, learning_rate={self.learning_rate}\"\n",
        "\n",
        "    def predict_proba(self, X: pd.DataFrame):\n",
        "        X = pd.concat([pd.DataFrame([1] * X.shape[0], index=X.index), X], axis=1)\n",
        "\n",
        "        return 1 / (1 + np.exp(-np.dot(X, self.weights)))\n",
        "\n",
        "    def predict(self, X: pd.DataFrame) -> pd.Series:\n",
        "        return (self.predict_proba(X) > 0.5).astype(int)\n",
        "\n",
        "    def get_batch(self, x_length):\n",
        "        return random.sample(range(x_length), int(self.sgd_sample * x_length)) if isinstance(self.sgd_sample, float) else random.sample(range(x_length), self.sgd_sample)\n",
        "\n",
        "    @staticmethod\n",
        "    def confusion_measure(y, y_pred):\n",
        "        TP = 0\n",
        "        FP = 0\n",
        "        TN = 0\n",
        "        FN = 0\n",
        "\n",
        "        for i in range(len(y_pred)):\n",
        "            if y[i] == y_pred[i] == 1:\n",
        "               TP += 1\n",
        "            if y_pred[i] == 1 and y[i] != y_pred[i]:\n",
        "               FP += 1\n",
        "            if y[i] == y_pred[i] == 0:\n",
        "               TN += 1\n",
        "            if y_pred[i] == 0 and y[i] != y_pred[i]:\n",
        "               FN += 1\n",
        "\n",
        "        return(TP, FP, TN, FN)\n",
        "\n",
        "    @staticmethod\n",
        "    def get_metric_score(metric: str, y_true, y_pred):\n",
        "        if metric != 'roc_auc':\n",
        "            TP, FP, TN, FN = MyLogReg.confusion_measure(y_true, y_pred)\n",
        "\n",
        "            if metric == 'accuracy':\n",
        "                score = (TP + TN) / (TP + FP + TN + FN)\n",
        "            elif metric == 'precision':\n",
        "                score = (TP) / (TP + FP)\n",
        "            elif metric == 'recall':\n",
        "                score = (TP) / (TP + FN)\n",
        "            elif metric == 'f1':\n",
        "                precision = (TP) / (TP + FP)\n",
        "                recall = (TP) / (TP + FN)\n",
        "                score = 2 * precision * recall / (precision + recall)\n",
        "        else:\n",
        "            total = 0\n",
        "\n",
        "            P = np.sum(y_true == 1)\n",
        "            N = np.sum(y_true == 0)\n",
        "\n",
        "            sorted_idx = np.argsort(-np.array(np.round(y_pred, 10)))\n",
        "            y_sorted = np.array(y_true)[sorted_idx]\n",
        "            y_prob_sorted = y_pred[sorted_idx]\n",
        "\n",
        "            total = 0\n",
        "\n",
        "            for prob, pred in zip(y_prob_sorted, y_sorted):\n",
        "                if pred == 0:\n",
        "                     total += (np.sum(y_sorted[y_prob_sorted > prob])\n",
        "                               + np.sum(y_sorted[y_prob_sorted == prob]) / len(y_sorted[y_prob_sorted == prob]))\n",
        "\n",
        "            score = total / (P * N)\n",
        "\n",
        "        return score\n",
        "\n",
        "    def get_best_score(self):\n",
        "        return self.score\n",
        "\n",
        "    def grad(self, y: pd.Series, y_pred: pd.Series, X: pd.DataFrame, batch_idxs: list) -> pd.Series:\n",
        "\n",
        "          y = y.iloc[batch_idxs]\n",
        "          y_pred = y_pred[batch_idxs]\n",
        "          X = X.iloc[batch_idxs, :]\n",
        "\n",
        "          if not self.reg:\n",
        "              grad = (y_pred - y) @ X / y.shape[0]\n",
        "          elif self.reg == 'l1':\n",
        "              grad = (y_pred - y) @ X / y.shape[0] + self.l1_coef * np.sign(self.weights)\n",
        "          elif self.reg == 'l2':\n",
        "              grad = (y_pred - y) @ X / y.shape[0] + self.l2_coef * 2 * (self.weights)\n",
        "          elif self.reg == 'elasticnet':\n",
        "              grad = (y_pred - y) @ X / y.shape[0] + self.l1_coef * np.sign(self.weights) + self.l2_coef * 2 * (self.weights)\n",
        "\n",
        "          return grad\n",
        "\n",
        "    def loss(self, y: pd.Series, y_pred: pd.DataFrame) -> float:\n",
        "        if self.reg == 'None':\n",
        "            loss = MyLogReg.logloss(y, y_pred)\n",
        "        elif self.reg == 'l1':\n",
        "            loss = MyLogReg.logloss(y, y_pred) + self.l1_coef * np.sum(self.weights)\n",
        "        elif self.reg == 'l2':\n",
        "            loss = MyLogReg.logloss(y, y_pred) + self.l2_coef * np.sum(self.weights**2)\n",
        "        else:\n",
        "            loss = MyLogReg.logloss(y, y_pred) + self.l1_coef * np.sum(self.weights) + self.l2_coef * np.sum(self.weights**2)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    @staticmethod\n",
        "    def logloss(y: pd.Series, y_pred: pd.Series, eps=1e-15) -> float:\n",
        "        loss = -(y * (np.log(y_pred + eps)) + (1 - y) * np.log(1 - y_pred + eps)).mean()\n",
        "        return loss\n",
        "\n",
        "    def get_coef(self):\n",
        "        return self.weights[1:]\n",
        "\n",
        "    def fit(self, X: pd.DataFrame, y: pd.Series, verbose: int = False):\n",
        "        X = pd.concat([pd.DataFrame([1] * X.shape[0], index=X.index), X], axis=1)\n",
        "        self.weights = np.ones(X.shape[1])\n",
        "\n",
        "        for i in range(self.n_iter):\n",
        "            sample_rows_idx = self.get_batch(X.shape[0]) if self.sgd_sample else range(X.shape[0])\n",
        "\n",
        "            y_hat = self.predict_proba(X.iloc[:, 1:])\n",
        "            loss = self.loss(y, y_hat)\n",
        "            nabla = self.grad(y, y_hat, X, sample_rows_idx)\n",
        "\n",
        "            if isinstance(self.learning_rate, (int, float)):\n",
        "                self.weights -= self.learning_rate * nabla\n",
        "            else:\n",
        "                self.weights -= self.learning_rate(i + 1) * nabla\n",
        "\n",
        "            if self.metric:\n",
        "                if self.metric != 'roc_auc':\n",
        "                    y_pred = self.predict(X.iloc[:, 1:])\n",
        "                    self.score = getattr(self, 'get_metric_score')(self.metric, y, y_pred)\n",
        "                else:\n",
        "                    self.score = getattr(self, 'get_metric_score')(self.metric, y, y_hat)\n",
        "\n",
        "            if verbose and i % verbose == 0:\n",
        "                if self.metric:\n",
        "                   print(f'start | loss = {loss} | {self.metric} = {self.score} | learning_rate = {self.learning_rate}') if i == 0 else print(f'i = {i} | loss = {loss} | {self.metric} = {self.score} | learning_rate = {self.learning_rate}')\n",
        "                else:\n",
        "                   print(f'start | loss = {loss} | learning_rate = {self.learning_rate}') if i == 0 else print(f'i = {i} | loss = {loss} | learning_rate = {self.learning_rate}')\n"
      ],
      "metadata": {
        "id": "UvYw6PgF99hb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## another"
      ],
      "metadata": {
        "id": "ez1sPuzzCgnW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyLogReg:\n",
        "    def __init__(self,\n",
        "                 n_iter: int = 10,\n",
        "                 learning_rate=0.1,\n",
        "                 metric: str = None,\n",
        "                 reg: str = 'None',\n",
        "                 l1_coef: float = 0.,\n",
        "                 l2_coef: float = 0.,\n",
        "                 sgd_sample: float = None,\n",
        "                 random_state: int = 42) -> None:\n",
        "        self.score = None\n",
        "        self.n_iter = n_iter\n",
        "        self.learning_rate = learning_rate\n",
        "        self._weights = None\n",
        "        self.metric = metric  # accuracy precision recall f1 roc_auc\n",
        "        self.reg = reg  # 'l1', 'l2', 'elasticnet'\n",
        "        self.l1_coef = l1_coef\n",
        "        self.l2_coef = l2_coef\n",
        "        self.sgd_sample = sgd_sample\n",
        "        random.seed(random_state)\n",
        "\n",
        "    def __str__(self):\n",
        "        return f'MyLogReg class: n_iter={self.n_iter}, learning_rate={self.learning_rate}'\n",
        "\n",
        "    def _loss(self, y_true: pd.Series, y_pred: pd.DataFrame) -> float:\n",
        "        if self.reg == 'None':\n",
        "            return log_loss(y_true, y_pred)\n",
        "        elif self.reg == 'l1':\n",
        "            return log_loss(y_true, y_pred) + \\\n",
        "                self.l1_coef * self._weights.abs().sum()\n",
        "        elif self.reg == 'l2':\n",
        "            return log_loss(y_true, y_pred) + \\\n",
        "                self.l2_coef * self._weights.pow(2).sum()\n",
        "        else:\n",
        "            return log_loss(y_true, y_pred) + \\\n",
        "                self.l1_coef * self._weights.abs().sum() + \\\n",
        "                self.l2_coef * self._weights.pow(2).sum()\n",
        "\n",
        "    def _grad(self,\n",
        "              y_true: pd.Series,\n",
        "              y_pred: pd.DataFrame,\n",
        "              X: pd.DataFrame,\n",
        "              mini_batch_idx: pd.DataFrame.index) -> pd.Series:\n",
        "        y_true = y_true.iloc[mini_batch_idx]\n",
        "        y_pred = y_pred[mini_batch_idx]\n",
        "        X = X.iloc[mini_batch_idx, :]\n",
        "\n",
        "        if self.reg == 'None':\n",
        "            return (y_pred - y_true) @ X / y_true.shape[0]\n",
        "        elif self.reg == 'l1':\n",
        "            return (y_pred - y_true) @ X / y_true.shape[0] + \\\n",
        "                self.l1_coef * np.sign(self._weights)\n",
        "        elif self.reg == 'l2':\n",
        "            return (y_pred - y_true) @ X / y_true.shape[0] + \\\n",
        "                self.l2_coef * 2 * self._weights\n",
        "        else:\n",
        "            return (y_pred - y_true) @ X / y_true.shape[0] + \\\n",
        "                self.l1_coef * np.sign(self._weights) + \\\n",
        "                self.l2_coef * 2 * self._weights\n",
        "\n",
        "    @staticmethod\n",
        "    def _get_minibatch_idx(x_length: int, sample) -> list:\n",
        "        sample = int(sample * x_length) if isinstance(sample, float) else sample\n",
        "        return random.sample(range(x_length), int(sample * x_length)) if isinstance(sample, float) else random.sample(range(x_length), sample)\n",
        "\n",
        "    def fit(self, X: pd.DataFrame, y: pd.Series, verbose: int = False) -> None:\n",
        "        X = pd.concat([pd.DataFrame([1] * X.shape[0], index=X.index), X], axis=1)\n",
        "        self._weights = pd.Series([1.] * X.shape[1], index=X.columns)\n",
        "        for i in range(self.n_iter):\n",
        "            minibatch_idx = self._get_minibatch_idx(X.shape[0],\n",
        "                                                    self.sgd_sample) if self.sgd_sample else range(X.shape[0])\n",
        "            y_hat = self.predict_proba(X.iloc[:, 1:])\n",
        "            loss = self._loss(y, y_hat)\n",
        "            grad = self._grad(y, y_hat, X, minibatch_idx)\n",
        "            print(type(grad))\n",
        "\n",
        "\n",
        "            if isinstance(self.learning_rate, (int, float)):\n",
        "                self._weights -= self.learning_rate * grad\n",
        "            elif callable(self.learning_rate):\n",
        "                self._weights -= self.learning_rate(i + 1) * grad\n",
        "            if self.metric and self.metric != 'roc_auc':\n",
        "                self.score = eval(self.metric)(y, self.predict(X.iloc[:, 1:]))\n",
        "            elif self.metric == 'roc_auc':\n",
        "                self.score = roc_auc(y, self.predict_proba(X.iloc[:, 1:]))\n",
        "            if verbose and i % verbose == 0:\n",
        "                if self.metric:\n",
        "                    print(f'{i} | loss: {loss} | {self.metric}: {self.score}')\n",
        "                else:\n",
        "                    print(f'{i} | loss: {loss}')\n",
        "\n",
        "    def get_coef(self):\n",
        "        return self._weights[1:]\n",
        "\n",
        "    def predict_proba(self, X: pd.DataFrame) -> pd.DataFrame:\n",
        "        X = pd.concat([pd.DataFrame([1] * X.shape[0], index=X.index), X], axis=1)\n",
        "        #return 1 / (1 + np.exp(- self._weights @ X.T))\n",
        "        return 1 / (1 + np.exp(-np.dot(X, self._weights)))\n",
        "\n",
        "    def predict(self, X: pd.DataFrame) -> pd.DataFrame:\n",
        "        return (self.predict_proba(X) > 0.5).astype(int)\n",
        "\n",
        "    def get_best_score(self):\n",
        "        return self.score\n",
        "\n",
        "\n",
        "def log_loss(y_true: pd.Series, y_pred: pd.DataFrame, eps=1e-15) -> float:\n",
        "    return -(y_true * (np.log(y_pred + eps)) + (1 - y_true) * np.log(1 - y_pred + eps)).mean()\n",
        "\n",
        "\n",
        "def f1(y_true: pd.Series, y_pred: pd.DataFrame) -> float:\n",
        "    pr = precision(y_true, y_pred)\n",
        "    rec = recall(y_true, y_pred)\n",
        "    return 2 * pr * rec / (pr + rec)\n",
        "\n",
        "\n",
        "def roc_auc(y_true: pd.Series, y_score: pd.DataFrame) -> float:\n",
        "    y_score = y_score.round(10)\n",
        "    df = pd.concat([y_score, y_true], axis=1)\n",
        "    df = df.sort_values(by=0, ascending=False)\n",
        "\n",
        "    positives = df[df[1] == 1]\n",
        "    negatives = df[df[1] == 0]\n",
        "\n",
        "    total = 0\n",
        "    for _, row in negatives.iterrows():\n",
        "        score_higher = (positives[0] > row[0]).sum()\n",
        "        score_equal = (positives[0] == row[0]).sum()\n",
        "        total += score_higher + 0.5 * score_equal\n",
        "\n",
        "    return total / (positives.shape[0] * negatives.shape[0])\n",
        "\n",
        "\n",
        "def recall(y_true: pd.Series, y_pred: pd.DataFrame) -> float:\n",
        "    tp = ((y_true == 1) & (y_pred == 1)).sum()\n",
        "    fn = ((y_true == 1) & (y_pred == 0)).sum()\n",
        "    return tp / (tp + fn)\n",
        "\n",
        "\n",
        "def precision(y_true: pd.Series, y_pred: pd.DataFrame) -> float:\n",
        "    tp = ((y_true == 1) & (y_pred == 1)).sum()\n",
        "    fp = ((y_true == 0) & (y_pred == 1)).sum()\n",
        "    return tp / (tp + fp)\n",
        "\n",
        "\n",
        "def accuracy(y_true: pd.Series, y_pred: pd.DataFrame) -> float:\n",
        "    return (y_true == y_pred).mean()\n",
        "\n",
        "\n",
        "\n",
        "clf = MyLogReg(sgd_sample=0.3)\n",
        "# clf = MyLogReg()\n",
        "clf.fit(X, y, verbose=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xze8ClqEyIbo",
        "outputId": "f8d1cbf7-de7a-4686-f5db-1d05225d99e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.series.Series'>\n",
            "0 | loss: 3.6736886876615524\n",
            "<class 'pandas.core.series.Series'>\n",
            "<class 'pandas.core.series.Series'>\n",
            "<class 'pandas.core.series.Series'>\n",
            "<class 'pandas.core.series.Series'>\n",
            "<class 'pandas.core.series.Series'>\n",
            "<class 'pandas.core.series.Series'>\n",
            "<class 'pandas.core.series.Series'>\n",
            "<class 'pandas.core.series.Series'>\n",
            "<class 'pandas.core.series.Series'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## learner"
      ],
      "metadata": {
        "id": "rRBLK6jf8ks9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyPrepLogReg:\n",
        "    def __init__(\n",
        "        self,\n",
        "        n_iter: int = 10,\n",
        "        learning_rate: float = 0.1,\n",
        "        metric: str = None,\n",
        "        reg: str = None,\n",
        "        l1_coef: float = 0.0,\n",
        "        l2_coef: float = 0.0,\n",
        "        sgd_sample: float = None,\n",
        "        random_state: int = 42,\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Construct logistic regression class.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        n_iter : int, optional\n",
        "            Number of iterations, by default 100\n",
        "        learning_rate : float, optional\n",
        "            Learning rate, by default 3e-4\n",
        "        metric : str, optional\n",
        "            Metric to calculate during training, by default None\n",
        "        reg : str, optional\n",
        "            Type of regularization:\n",
        "            'l1', 'l2', 'elasticnet', by default None.\n",
        "        l1_coef : float, optional\n",
        "            L1 regularization coefficient, by default 0.0\n",
        "        l2_coef : float, optional\n",
        "            L2 regularization coefficient, by default 0.0\n",
        "        sgd_sample : float, optional\n",
        "            Stochastic gradient descent sample, by default None\n",
        "        random_state : int, optional\n",
        "            Random state, by default 42\n",
        "        \"\"\"\n",
        "\n",
        "        self.n_iter = n_iter\n",
        "        self.learning_rate = learning_rate\n",
        "        self.metric = metric\n",
        "        self.reg = reg\n",
        "        self.l1_coef = l1_coef\n",
        "        self.l2_coef = l2_coef\n",
        "        self._weights = None\n",
        "        self._eps = 1e-15\n",
        "        self._threshold = 0.5\n",
        "        self._best_score = None\n",
        "        self.sgd_sample = sgd_sample\n",
        "        self.random_state = random_state\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        \"\"\"\n",
        "        Get class representation in readable form.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        str\n",
        "            String with class representation\n",
        "        \"\"\"\n",
        "        class_name = type(self).__name__\n",
        "        return f\"{class_name} class: n_iter={self.n_iter}, learning_rate={self.learning_rate}\"\n",
        "\n",
        "    def _sigmoid(self, x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    def _confusion_matrix(self, y: np.array, y_pred: np.array) -> tuple:\n",
        "        \"\"\"\n",
        "        Calculate confusion matrix.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        y : np.array\n",
        "            True values\n",
        "        y_pred : np.array\n",
        "            Predicted values\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        tuple\n",
        "            TP, FN, FP, TN\n",
        "        \"\"\"\n",
        "        y_pred = np.where(y_pred > self._threshold, 1, 0)\n",
        "        TP = np.logical_and(y == 1, y_pred == 1).sum()\n",
        "        FN = np.logical_and(y == 1, y_pred == 0).sum()\n",
        "        FP = np.logical_and(y == 0, y_pred == 1).sum()\n",
        "        TN = np.logical_and(y == 0, y_pred == 0).sum()\n",
        "\n",
        "        return TP, FN, FP, TN\n",
        "\n",
        "    def _accuracy(self, y: np.array, y_pred: np.array) -> float:\n",
        "        \"\"\"\n",
        "        Calculate accuracy.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        y : np.array\n",
        "            True values\n",
        "        y_pred : np.array\n",
        "            Predicted values\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        float\n",
        "            Calculated metric\n",
        "        \"\"\"\n",
        "        TP, FN, FP, TN = self._confusion_matrix(y, y_pred)\n",
        "        return (TP + TN) / (TP + FN + FP + TN)\n",
        "\n",
        "    def _precision(self, sy: np.array, y_pred: np.array) -> float:\n",
        "        \"\"\"\n",
        "        Calculate precision.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        y : np.array\n",
        "            True values\n",
        "        y_pred : np.array\n",
        "            Predicted values\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        float\n",
        "            Calculated metric\n",
        "        \"\"\"\n",
        "        TP, _, FP, _ = self._confusion_matrix(y, y_pred)\n",
        "        return TP / (TP + FP)\n",
        "\n",
        "    def _recall(self, y: np.array, y_pred: np.array) -> float:\n",
        "        \"\"\"\n",
        "        Calculate recall.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        y : np.array\n",
        "            True values\n",
        "        y_pred : np.array\n",
        "            Predicted values\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        float\n",
        "            Calculated metric\n",
        "        \"\"\"\n",
        "        TP, FN, _, _ = self._confusion_matrix(y, y_pred)\n",
        "        return TP / (TP + FN)\n",
        "\n",
        "    def _f1(self, y: np.array, y_pred: np.array, beta: float = 1) -> float:\n",
        "        \"\"\"\n",
        "        Calculate F1 score.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        y : np.array\n",
        "            True values\n",
        "        y_pred : np.array\n",
        "            Predicted values\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        float\n",
        "            Calculated metric\n",
        "        \"\"\"\n",
        "        recall = self._recall(y, y_pred)\n",
        "        precision = self._precision(y, y_pred)\n",
        "\n",
        "        return (1 + beta**2) * (precision * recall) / (beta**2 * precision + recall)\n",
        "\n",
        "    def _roc_auc(self, y: np.array, y_prob: np.array, beta: float = 1) -> float:\n",
        "        \"\"\"\n",
        "        Calculate ROC AUC score.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        y : np.array\n",
        "            True values\n",
        "        y_prob : np.array\n",
        "            Predicted probabilities\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        float\n",
        "            Calculated metric\n",
        "        \"\"\"\n",
        "        positives = np.sum(y == 1)\n",
        "        negatives = np.sum(y == 0)\n",
        "\n",
        "        sorted_idx = np.argsort(-np.array(np.round(y_prob, 10)))\n",
        "        y_sorted = np.array(y)[sorted_idx]\n",
        "        y_prob_sorted = y_prob[sorted_idx]\n",
        "\n",
        "        roc_auc_score = 0\n",
        "\n",
        "        for prob, pred in zip(y_prob_sorted, y_sorted):\n",
        "            if pred == 0:\n",
        "                roc_auc_score += (\n",
        "                    np.sum(y_sorted[y_prob_sorted > prob])\n",
        "                    + np.sum(y_sorted[y_prob_sorted == prob]) / 2\n",
        "                )\n",
        "\n",
        "        roc_auc_score /= positives * negatives\n",
        "\n",
        "        return roc_auc_score\n",
        "\n",
        "    def _loss(self, y: np.array, y_pred: np.array, **kwargs) -> float:\n",
        "        \"\"\"\n",
        "        Calculate LogLoss.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        y : np.array\n",
        "            True values\n",
        "        y_pred : np.array\n",
        "            Predicted values\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        float\n",
        "            Calculated loss\n",
        "        \"\"\"\n",
        "        return -np.mean(y * np.log(y_pred + self._eps) + (1 - y) * np.log(1 - y_pred + self._eps))\n",
        "\n",
        "    def _l1_loss(\n",
        "        self, y: np.array, y_pred: np.array, l1_coef: float, weights: np.array, **kwargs\n",
        "    ) -> float:\n",
        "        \"\"\"\n",
        "        Calculate LogLoss with L1 regularization.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        y : np.array\n",
        "            True values\n",
        "        y_pred : np.array\n",
        "            Predicted values\n",
        "        l1_coef : float\n",
        "            L1 regularization coefficient\n",
        "        weights : np.array\n",
        "            Linear regression weights\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        float\n",
        "            Calculated loss\n",
        "        \"\"\"\n",
        "        return self._loss(y, y_pred) + l1_coef * np.sum(weights)\n",
        "\n",
        "    def _l2_loss(\n",
        "        self, y: np.array, y_pred: np.array, l2_coef: float, weights: np.array, **kwargs\n",
        "    ) -> float:\n",
        "        \"\"\"\n",
        "        Calculate LogLoss with L2 regularization.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        y : np.array\n",
        "            True values\n",
        "        y_pred : np.array\n",
        "            Predicted values\n",
        "        l2_coef : float\n",
        "            L2 regularization coefficient\n",
        "        weights : np.array\n",
        "            Linear regression weights\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        float\n",
        "            Calculated loss\n",
        "        \"\"\"\n",
        "        return self._loss(y, y_pred) + l2_coef * np.sum(weights**2)\n",
        "\n",
        "    def _elasticnet_loss(\n",
        "        self,\n",
        "        y: np.array,\n",
        "        y_pred: np.array,\n",
        "        l1_coef: float,\n",
        "        l2_coef: float,\n",
        "        weights: np.array,\n",
        "        **kwargs,\n",
        "    ) -> float:\n",
        "        \"\"\"\n",
        "        Calculate LogLoss with Elasticnet regularization.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        y : np.array\n",
        "            True values\n",
        "        y_pred : np.array\n",
        "            Predicted values\n",
        "        l1_coef : float\n",
        "            L1 regularization coefficient\n",
        "        l2_coef : float\n",
        "            L2 regularization coefficient\n",
        "        weights : np.array\n",
        "            Linear regression weights\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        float\n",
        "            Calculated loss\n",
        "        \"\"\"\n",
        "        return (\n",
        "            self._l1_loss(y, y_pred, l1_coef, weights)\n",
        "            + self._l2_loss(y, y_pred, l2_coef, weights)\n",
        "            - self._loss(y, y_pred)\n",
        "        )\n",
        "\n",
        "    def _grad(self, y: np.array, y_pred: np.array, X: np.array, **kwargs) -> np.array:\n",
        "        \"\"\"\n",
        "        Calculate gradient.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        y : np.array\n",
        "            True values\n",
        "        y_pred : np.array\n",
        "            Predicted values\n",
        "        X : np.array\n",
        "            Training data\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        np.array\n",
        "            Gradient vector\n",
        "        \"\"\"\n",
        "        return 1 / X.shape[0] * np.dot((y_pred - y), X.values)\n",
        "\n",
        "    def _l1_grad(\n",
        "        self,\n",
        "        y: np.array,\n",
        "        y_pred: np.array,\n",
        "        X: np.array,\n",
        "        l1_coef: float,\n",
        "        weights: np.array,\n",
        "        **kwargs,\n",
        "    ) -> np.array:\n",
        "        \"\"\"\n",
        "        Calculate gradient for L1 regularization.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        y : np.array\n",
        "            True values\n",
        "        y_pred : np.array\n",
        "            Predicted values\n",
        "        X : np.array\n",
        "            Training data\n",
        "        l1_coef : float\n",
        "            L1 regularization coefficient\n",
        "        weights : np.array\n",
        "            Linear regression weights\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        np.array\n",
        "            Gradient vector\n",
        "        \"\"\"\n",
        "        return self._grad(y, y_pred, X) + l1_coef * np.sign(weights)\n",
        "\n",
        "    def _l2_grad(\n",
        "        self,\n",
        "        y: np.array,\n",
        "        y_pred: np.array,\n",
        "        X: np.array,\n",
        "        l2_coef: float,\n",
        "        weights: np.array,\n",
        "        **kwargs,\n",
        "    ) -> np.array:\n",
        "        \"\"\"\n",
        "        Calculate gradient for L2 regularization.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        y : np.array\n",
        "            True values\n",
        "        y_pred : np.array\n",
        "            Predicted values\n",
        "        X : np.array\n",
        "            Training data\n",
        "        l2_coef : float\n",
        "            L2 regularization coefficient\n",
        "        weights : np.array\n",
        "            Linear regression weights\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        np.array\n",
        "            Gradient vector\n",
        "        \"\"\"\n",
        "        return self._grad(y, y_pred, X) + l2_coef * 2 * weights\n",
        "\n",
        "    def _elasticnet_grad(\n",
        "        self,\n",
        "        y: np.array,\n",
        "        y_pred: np.array,\n",
        "        X: np.array,\n",
        "        l1_coef: float,\n",
        "        l2_coef: float,\n",
        "        weights: np.array,\n",
        "        **kwargs,\n",
        "    ) -> np.array:\n",
        "        \"\"\"\n",
        "        Calculate gradient for Elasticnet regularization.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        y : np.array\n",
        "            True values\n",
        "        y_pred : np.array\n",
        "            Predicted values\n",
        "        X : np.array\n",
        "            Training data\n",
        "        l1_coef : float\n",
        "            L1 regularization coefficient\n",
        "        l2_coef : float\n",
        "            L2 regularization coefficient\n",
        "        weights : np.array\n",
        "            Linear regression weights\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        np.array\n",
        "            Gradient vector\n",
        "        \"\"\"\n",
        "        return (\n",
        "            self._l1_grad(y, y_pred, X, l1_coef, weights)\n",
        "            + self._l2_grad(y, y_pred, X, l2_coef, weights)\n",
        "            - self._grad(y, y_pred, X)\n",
        "        )\n",
        "\n",
        "    def _get_loss(self, loss: str) -> callable:\n",
        "        \"\"\"\n",
        "        Get loss function for calculation.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        loss : str\n",
        "            Loss name\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        callable\n",
        "            Metric function\n",
        "        \"\"\"\n",
        "\n",
        "        _losses = {\n",
        "            \"l1\": self._l1_loss,\n",
        "            \"l2\": self._l2_loss,\n",
        "            \"elasticnet\": self._elasticnet_loss,\n",
        "            None: self._loss,\n",
        "        }\n",
        "        return _losses[loss]\n",
        "\n",
        "    def _get_grad(self, loss: str) -> callable:\n",
        "        \"\"\"\n",
        "        Get gradient function for calculation.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        loss : str\n",
        "            Loss name\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        callable\n",
        "            Metric function\n",
        "        \"\"\"\n",
        "\n",
        "        _grads = {\n",
        "            \"l1\": self._l1_grad,\n",
        "            \"l2\": self._l2_grad,\n",
        "            \"elasticnet\": self._elasticnet_grad,\n",
        "            None: self._grad,\n",
        "        }\n",
        "        return _grads[loss]\n",
        "\n",
        "    def _get_metrics(self, metric: str) -> callable:\n",
        "        \"\"\"\n",
        "        Get metric function for calculation.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        metric : str\n",
        "            Metric name\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        callable\n",
        "            Metric function\n",
        "        \"\"\"\n",
        "\n",
        "        _metrics = {\n",
        "            \"accuracy\": self._accuracy,\n",
        "            \"precision\": self._precision,\n",
        "            \"recall\": self._recall,\n",
        "            \"f1\": self._f1,\n",
        "            \"roc_auc\": self._roc_auc,\n",
        "            None: self._accuracy,\n",
        "        }\n",
        "        return _metrics[metric]\n",
        "\n",
        "    def fit(self, X: pd.DataFrame, y: pd.Series, verbose: int = False) -> None:\n",
        "        \"\"\"\n",
        "        Fit logistic regression.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : pd.DataFrame\n",
        "            Training data\n",
        "        y : pd.Series\n",
        "            True values\n",
        "        verbose : int, optional\n",
        "            Verbosity of training, by default False\n",
        "        \"\"\"\n",
        "        random.seed(self.random_state)\n",
        "\n",
        "        n_samples, n_features = X.shape\n",
        "        X = pd.concat([pd.DataFrame({\"bias\": [1] * n_samples}), X.reset_index(drop=True)], axis=1)\n",
        "        self.weights = np.ones(n_features + 1)\n",
        "\n",
        "        if isinstance(self.sgd_sample, int):\n",
        "            n_samples = self.sgd_sample\n",
        "        elif isinstance(self.sgd_sample, float):\n",
        "            n_samples = int(np.round(self.sgd_sample * X.shape[0]))\n",
        "\n",
        "        for i in range(1, self.n_iter + 1):\n",
        "            # sample_rows_idx = random.sample(range(X.shape[0]), n_samples)\n",
        "            y_pred = self._sigmoid(np.dot(X.values, self.weights))\n",
        "            loss = self._get_loss(self.reg)(\n",
        "                y=y,\n",
        "                y_pred=y_pred,\n",
        "                l1_coef=self.l1_coef,\n",
        "                l2_coef=self.l2_coef,\n",
        "                weights=self.weights,\n",
        "            )\n",
        "            self._best_score = self._get_metrics(self.metric)(y, y_pred)\n",
        "            if verbose and i == 1:\n",
        "                print(\n",
        "                    f\"start | loss: {loss}\"\n",
        "                    + (f\"| {self.metric}: {self._best_score}\" if self.metric else \"\")\n",
        "                )\n",
        "            if verbose and i % verbose == 0:\n",
        "                print(\n",
        "                    f\"{i} | loss: {loss}\"\n",
        "                    + (f\"| {self.metric}: {self._best_score}\" if self.metric else \"\")\n",
        "                )\n",
        "            grad = self._get_grad(self.reg)(\n",
        "                # y=y.iloc[sample_rows_idx],\n",
        "                # y_pred=y_pred[sample_rows_idx],\n",
        "                # X=X.iloc[sample_rows_idx],\n",
        "                l1_coef=self.l1_coef,\n",
        "                l2_coef=self.l2_coef,\n",
        "                weights=self.weights,\n",
        "            )\n",
        "            if callable(self.learning_rate):\n",
        "                learning_rate = self.learning_rate(i)\n",
        "            elif isinstance(self.learning_rate, (int, float)):\n",
        "                learning_rate = self.learning_rate\n",
        "            self.weights -= learning_rate * grad\n",
        "\n",
        "        self._best_score = self._get_metrics(self.metric)(\n",
        "            y, self._sigmoid(np.dot(X.values, self.weights))\n",
        "        )\n",
        "\n",
        "    def predict_proba(self, X: pd.DataFrame) -> np.array:\n",
        "        \"\"\"\n",
        "        Predict probabilities using the trained model.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : pd.DataFrame\n",
        "            Data for prediction\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        np.array\n",
        "            Predicted values\n",
        "        \"\"\"\n",
        "        n_samples, n_features = X.shape\n",
        "        X = pd.concat([pd.DataFrame({\"bias\": [1] * n_samples}), X.reset_index(drop=True)], axis=1)\n",
        "        y_pred = self._sigmoid(np.dot(X.values, self.weights))\n",
        "        return y_pred\n",
        "\n",
        "    def predict(self, X: pd.DataFrame) -> np.array:\n",
        "        \"\"\"\n",
        "        Predict using the trained model.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : pd.DataFrame\n",
        "            Data for prediction\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        np.array\n",
        "            Predicted values\n",
        "        \"\"\"\n",
        "        y_pred = self.predict_proba(X)\n",
        "        y_pred = np.where(y_pred > self._threshold, 1, 0)\n",
        "        return y_pred\n",
        "\n",
        "    def get_coef(self) -> np.array:\n",
        "        \"\"\"\n",
        "        Get logistic regression weights\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        np.array\n",
        "            Weights\n",
        "        \"\"\"\n",
        "        return self.weights[1:]\n",
        "\n",
        "    def get_best_score(self) -> float:\n",
        "        \"\"\"\n",
        "        Get last calculated score.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        float\n",
        "            Calculated value\n",
        "        \"\"\"\n",
        "        return self._best_score"
      ],
      "metadata": {
        "id": "mJ5yARCn8LWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = MyPrepLogReg(sgd_sample=0.1)\n",
        "# clf = MyLogReg()\n",
        "clf.fit(X, y, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "PhwJ5S_k8P00",
        "outputId": "67b34b09-8027-4505-b4b3-971d5b0d4453"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "start | loss: 3.6736886876615524\n",
            "1 | loss: 3.6736886876615524\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-148-c5b9f5fd4469>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMyPrepLogReg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msgd_sample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# clf = MyLogReg()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-147-e9f111f77276>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, verbose)\u001b[0m\n\u001b[1;32m    542\u001b[0m                     \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34mf\"| {self.metric}: {self._best_score}\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetric\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m                 )\n\u001b[0;32m--> 544\u001b[0;31m             grad = self._get_grad(self.reg)(\n\u001b[0m\u001b[1;32m    545\u001b[0m                 \u001b[0;31m# y=y.iloc[sample_rows_idx],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m                 \u001b[0;31m# y_pred=y_pred[sample_rows_idx],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: MyPrepLogReg._grad() missing 3 required positional arguments: 'y', 'y_pred', and 'X'"
          ]
        }
      ]
    }
  ]
}