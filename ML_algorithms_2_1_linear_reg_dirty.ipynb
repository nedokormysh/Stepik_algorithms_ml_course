{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": [
        "FYksezuWxkK7"
      ],
      "authorship_tag": "ABX9TyNlB+zDlYtsb/N/5IfPe0tk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nedokormysh/Stepik_algorithms_ml_course/blob/linear_regression/ML_algorithms_2_1_linear_reg_dirty.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "qptPF7UW8-9n"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_regression\n",
        "\n",
        "X_mk, y_mk = make_regression(n_samples=5, n_features=3, n_informative=10, noise=15, random_state=42)"
      ],
      "metadata": {
        "id": "Rptxv7QeNJse"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2_1_5\n",
        "\n",
        "Данный класс при инициализации должен принимать на вход два параметра:\n",
        "\n",
        "n_iter — количество шагов градиентного спуска.\n",
        "\n",
        "По-умолчанию: 100\n",
        "\n",
        "learning_rate — коэффициент скорости обучения градиентного спуска.\n",
        "\n",
        "По-умолчанию: 0.1\n",
        "\n",
        "Все переданные (или дефолтные) параметры должны быть сохранены внутри класса.\n",
        "\n",
        "При обращении к экземпляру класса (или при передачи его в функцию print) необходимо распечатать строку по следующему шаблону (строго в таком виде):\n",
        "\n",
        "\n",
        "MyLineReg class: n_iter=<n_iter>, learning_rate=<learning_rate>"
      ],
      "metadata": {
        "id": "oAiH2bPy8UDV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyLineReg():\n",
        "    def __init__(self, n_iter=100, learning_rate=1):\n",
        "        self.n_iter = n_iter\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"MyLineReg class: n_iter={self.n_iter}, learning_rate={self.learning_rate}\""
      ],
      "metadata": {
        "id": "UF9VVU5y8dqC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2_1_6\n",
        "\n",
        "1) В инициализатор класса добавить новый параметр — weights — который будет хранить веса модели. По умолчанию он ничего не содержит.\n",
        "2) Вам необходимо реализовать метод fit в Вашем классе. Данный метод должен делать следующее:\n",
        "На вход принимать три атрибута:\n",
        "- X — все фичи в виде датафрейма пандаса.\n",
        "  Примечание: даже если фича будет всего одна это все равно будет датафрейм, а не серия.\n",
        "- y — целевая переменная в виде пандасовской серии.\n",
        "- verbose — указывает на какой итерации выводить лог. Например, значение 10 означает, что на каждой 10 итерации градиентного спуска будет печататься лог. Значение по умолчанию: False (т.е. ничего не выводится).\n",
        "Дополнить переданную матрицу фичей единичным столбцом слева.\n",
        "Определить сколько фичей передано и создать вектор весов, состоящий из одних единиц соответствующей длинны: т.е. количество фичей + 1.\n",
        "Дальше в цикле (до n_iter):\n",
        "- Предсказать $y^$​\n",
        "\n",
        "- Посчитать ошибку (MSE)\n",
        "- Вычислить градиент\n",
        "- Сделать шаг размером learning rate в противоположную от градиента сторону\n",
        "- Сохранить обновленные веса внутри класса\n",
        "В процессе обучения необходимо выводить лог, в котором указывать номер итерации и значение функций потерь:\n",
        "start | loss: 42027.65\n",
        "100 | loss: 1222.87\n",
        "200 | loss: 232.17\n",
        "300 | loss: 202.4\n",
        "где start - значении функции потерь до начала обучения. Далее выводится каждое i-ое значение итерации переданное в параметре verbose. Если verbose = False, то лог не выводится вовсе.\n",
        "З.Ы. Данный вывод никак проверяться не будет. Он в основном нужен для отладки. Поэтому можете модифицировать его внешний вид под свои нужды.\n",
        "Метод ничего не возвращает.\n",
        "3) Необходимо реализовать метод get_coef, который будет возвращать значения весов в виде вектора NumPy, начиная со второго значения. Первое значение нам не нужно, потому что оно соответствует фиктивной фиче (единичке). Все же остальные могут использоваться для оценки важности фичей.\n",
        "Проверка\n",
        "\n",
        "Входные данные: несколько наборов параметров для линейной регрессии\n",
        "Выходные данные: коэффициенты обученной линейной регрессии (их среднее)"
      ],
      "metadata": {
        "id": "YmyiyHbT8jZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Добавление столбца единиц слева."
      ],
      "metadata": {
        "id": "Fd8g9y8y3olf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZ0_1cWD8xXw",
        "outputId": "90a81d89-243d-4da2-b7be-92924ba8f75f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.70457135, 0.429959  , 0.26054683],\n",
              "       [0.40852386, 0.88449507, 0.31293098],\n",
              "       [0.70437775, 0.61764497, 0.65022736],\n",
              "       [0.0955257 , 0.96940716, 0.12378805],\n",
              "       [0.8671371 , 0.86211975, 0.1572261 ]])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "X = np.random.uniform(size=(5, 3))\n",
        "X"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uvs9kuLd9OQQ",
        "outputId": "7dfcfea1-e0c8-460d-a2d7-5afedd49d1f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### numpy"
      ],
      "metadata": {
        "id": "IcP6GPmc3x5o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.c_[np.ones(X.shape[0]), X]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyWjD1fE9Hnm",
        "outputId": "0cdecff1-47c8-4e8d-d8b5-336277906cff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.        , 0.70457135, 0.429959  , 0.26054683],\n",
              "       [1.        , 0.40852386, 0.88449507, 0.31293098],\n",
              "       [1.        , 0.70437775, 0.61764497, 0.65022736],\n",
              "       [1.        , 0.0955257 , 0.96940716, 0.12378805],\n",
              "       [1.        , 0.8671371 , 0.86211975, 0.1572261 ]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### pandas"
      ],
      "metadata": {
        "id": "mvqupau78EVv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.random.uniform(size=(5, 3))\n",
        "X = pd.DataFrame(X)\n",
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "b9KuULZv95gP",
        "outputId": "47e51954-8a4c-43de-a5d3-4f9311c496c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          0         1         2\n",
              "0  0.549973  0.158042  0.350349\n",
              "1  0.730726  0.804798  0.691874\n",
              "2  0.503351  0.906758  0.906255\n",
              "3  0.183549  0.465526  0.249728\n",
              "4  0.907699  0.529097  0.692194"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-da79b79b-a6e7-48d2-8c61-49dd904b0805\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.549973</td>\n",
              "      <td>0.158042</td>\n",
              "      <td>0.350349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.730726</td>\n",
              "      <td>0.804798</td>\n",
              "      <td>0.691874</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.503351</td>\n",
              "      <td>0.906758</td>\n",
              "      <td>0.906255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.183549</td>\n",
              "      <td>0.465526</td>\n",
              "      <td>0.249728</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.907699</td>\n",
              "      <td>0.529097</td>\n",
              "      <td>0.692194</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-da79b79b-a6e7-48d2-8c61-49dd904b0805')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-da79b79b-a6e7-48d2-8c61-49dd904b0805 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-da79b79b-a6e7-48d2-8c61-49dd904b0805');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.insert(loc=0, column='x_0', value=1)\n",
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "UTie_aNW-fLZ",
        "outputId": "9b423ef9-df66-4e79-e45e-c10e96c9f034"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   x_0         0         1         2\n",
              "0    1  0.549973  0.158042  0.350349\n",
              "1    1  0.730726  0.804798  0.691874\n",
              "2    1  0.503351  0.906758  0.906255\n",
              "3    1  0.183549  0.465526  0.249728\n",
              "4    1  0.907699  0.529097  0.692194"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-da915950-e799-4776-936e-f0d49d2602ef\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x_0</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.549973</td>\n",
              "      <td>0.158042</td>\n",
              "      <td>0.350349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.730726</td>\n",
              "      <td>0.804798</td>\n",
              "      <td>0.691874</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0.503351</td>\n",
              "      <td>0.906758</td>\n",
              "      <td>0.906255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0.183549</td>\n",
              "      <td>0.465526</td>\n",
              "      <td>0.249728</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0.907699</td>\n",
              "      <td>0.529097</td>\n",
              "      <td>0.692194</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-da915950-e799-4776-936e-f0d49d2602ef')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-da915950-e799-4776-936e-f0d49d2602ef button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-da915950-e799-4776-936e-f0d49d2602ef');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wc0bmkDACqWU",
        "outputId": "027db26c-5255-4988-dfe6-87bd05b93466"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w = np.ones(X.shape[1])\n",
        "w"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wUEK1Wt_CtXy",
        "outputId": "8ef72252-74b0-45d4-8603-56b12e295d8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 1., 1., 1.])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w.shape[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNPMlspvGN-j",
        "outputId": "6c1a55e5-8a60-4808-ddf6-ca350f92e285"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Реализация.\n",
        "\n",
        "Делал реализацию через нампай. Но оказалось нужно через пандас."
      ],
      "metadata": {
        "id": "NdQeDTiz8NGN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_regression\n",
        "\n",
        "X_mk, y_mk = make_regression(n_samples=2, n_features=3, n_informative=10, noise=15, random_state=42)"
      ],
      "metadata": {
        "id": "YE95hMwTI40P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "6p6tFCFvORQt",
        "outputId": "dbe98baf-145a-49f4-e4dd-8e42e752bccb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   x_0         0         1         2\n",
              "0    1  0.549973  0.158042  0.350349\n",
              "1    1  0.730726  0.804798  0.691874\n",
              "2    1  0.503351  0.906758  0.906255\n",
              "3    1  0.183549  0.465526  0.249728\n",
              "4    1  0.907699  0.529097  0.692194"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a3cc5fbf-2ff1-469c-b8fa-1b5d66a701f2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x_0</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.549973</td>\n",
              "      <td>0.158042</td>\n",
              "      <td>0.350349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.730726</td>\n",
              "      <td>0.804798</td>\n",
              "      <td>0.691874</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0.503351</td>\n",
              "      <td>0.906758</td>\n",
              "      <td>0.906255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0.183549</td>\n",
              "      <td>0.465526</td>\n",
              "      <td>0.249728</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0.907699</td>\n",
              "      <td>0.529097</td>\n",
              "      <td>0.692194</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a3cc5fbf-2ff1-469c-b8fa-1b5d66a701f2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a3cc5fbf-2ff1-469c-b8fa-1b5d66a701f2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a3cc5fbf-2ff1-469c-b8fa-1b5d66a701f2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.to_numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vTkx8eSgvUK",
        "outputId": "85f09a49-fa8d-4896-9cb9-20afcee1ba13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.        , 0.5499732 , 0.15804208, 0.35034939],\n",
              "       [1.        , 0.73072586, 0.80479843, 0.69187437],\n",
              "       [1.        , 0.50335082, 0.90675829, 0.90625535],\n",
              "       [1.        , 0.18354927, 0.46552554, 0.24972843],\n",
              "       [1.        , 0.90769903, 0.52909714, 0.69219378]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pandas version"
      ],
      "metadata": {
        "id": "B4Ju7e81hRQU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# X = pd.DataFrame(X_mk)\n",
        "# y = pd.Series(y_mk)\n",
        "# X.columns = [f'col_{col}' for col in X.columns]\n",
        "\n",
        "\n",
        "# class MyLineReg():\n",
        "#     def __init__(self, n_iter=2, learning_rate=1, weights=None):\n",
        "#         self.n_iter = n_iter\n",
        "#         self.learning_rate = learning_rate\n",
        "#         self.weights = weights\n",
        "\n",
        "#     def __repr__(self):\n",
        "#         return f\"MyLineReg class: n_iter={self.n_iter}, learning_rate={self.learning_rate}\"\n",
        "\n",
        "#     def fit(self, X, y, verbose=False):\n",
        "#         X.insert(loc=0, column='x_0', value=1)\n",
        "#         self.weights = np.ones(X.shape[1])\n",
        "#         w = np.ones(X.shape[1])\n",
        "#         print(w)\n",
        "\n",
        "#         for i in range(self.n_iter):\n",
        "#             y_tilda = X.dot(self.weights)\n",
        "#             mse = ((y - y_tilda)**2) / y.shape[0]\n",
        "#             print('y_t\\n', y_tilda[0: 5])\n",
        "#             print('y\\n', y[0: 5])\n",
        "#             print('mse\\n', mse[0: 5])\n",
        "#             nabla_mse = (2 / y.shape[0]) * mse.dot(X)\n",
        "#             # print(nabla_mse)\n",
        "#             w = w - self.learning_rate * nabla_mse\n",
        "#             # print(w)\n",
        "#             self.weights = w.values\n",
        "#             print(self.weights)\n",
        "#         # return mse\n",
        "\n",
        "#     # def get_coef():\n",
        "# reg = MyLineReg()\n",
        "# mse = reg.fit(X, y)"
      ],
      "metadata": {
        "id": "OehaQ4woD94r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = pd.DataFrame(X_mk)\n",
        "y = pd.Series(y_mk)\n",
        "X.columns = [f'col_{col}' for col in X.columns]\n",
        "\n",
        "class MyLineReg():\n",
        "    def __init__(self, n_iter=50, learning_rate=0.01, weights=None):\n",
        "        self.n_iter = n_iter\n",
        "        self.learning_rate = learning_rate\n",
        "        self.weights = weights\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"MyLineReg class: n_iter={self.n_iter}, learning_rate={self.learning_rate}\"\n",
        "\n",
        "    def fit(self, X, y, verbose=False):\n",
        "        X.insert(loc=0, column='x_0', value=1)\n",
        "        w = np.ones(X.shape[1])\n",
        "\n",
        "        for i in range(self.n_iter):\n",
        "            y_tilda = np.dot(X, w)\n",
        "            nabla_mse = (2 / y.shape[0]) * ((y_tilda - y)).dot(X)\n",
        "            w -= self.learning_rate * nabla_mse\n",
        "\n",
        "            if verbose != False and i % verbose == 0:\n",
        "              err = np.mean((y - y_tilda)**2)\n",
        "              print(f'i = {i} | loss = {err}')\n",
        "            self.weights = w.to_numpy()\n",
        "    def get_coef(self):\n",
        "      return self.weights[1:]\n",
        "\n",
        "\n",
        "\n",
        "reg = MyLineReg()\n",
        "reg.fit(X, y, verbose=10)\n",
        "c = reg.get_coef()\n",
        "c"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HE2TXVDdha5W",
        "outputId": "85960851-7156-4dd4-9296-c17f7aa94408"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i = 0 | loss = 810.9197945296903\n",
            "i = 10 | loss = 606.6150502834279\n",
            "i = 20 | loss = 487.2410882189987\n",
            "i = 30 | loss = 407.1121904869559\n",
            "i = 40 | loss = 347.0692499463499\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  0.29935983,  10.34644432,   2.16254471, -10.75406276])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Верное решение pandas."
      ],
      "metadata": {
        "id": "E6H2A9M1-r4i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# правильное решение\n",
        "\n",
        "class MyLineReg():\n",
        "    def __init__(self, n_iter=50, learning_rate=0.01, weights=None):\n",
        "        self.n_iter = n_iter\n",
        "        self.learning_rate = learning_rate\n",
        "        self.weights = weights\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"MyLineReg class: n_iter={self.n_iter}, learning_rate={self.learning_rate}\"\n",
        "\n",
        "    def fit(self, X, y, verbose=False):\n",
        "        X.insert(loc=0, column='x_0', value=1)\n",
        "        w = np.ones(X.shape[1])\n",
        "\n",
        "        for i in range(self.n_iter):\n",
        "            y_tilda = np.dot(X, w)\n",
        "            nabla_mse = (2 / y.shape[0]) * ((y_tilda - y)).dot(X)\n",
        "            w -= self.learning_rate * nabla_mse\n",
        "\n",
        "            if verbose != False and i % verbose == 0:\n",
        "              err = np.mean((y - y_tilda)**2)\n",
        "              print(f'i = {i} | loss = {err}')\n",
        "            self.weights = w.to_numpy()\n",
        "    def get_coef(self):\n",
        "      return self.weights[1:]"
      ],
      "metadata": {
        "id": "20i4HQMR99gr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.sum([1,\t-0.234153,\t1.523030,\t-0.234137])\n",
        "np.sum([1,\t0.767435,\t1.579213,\t-0.469474])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lkCtRgxtTwom",
        "outputId": "49d2736f-572d-4f5f-a3f1-a6a872c5f80e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.877174"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# mse_x = mse"
      ],
      "metadata": {
        "id": "1msJGN9ENp0o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mse_x"
      ],
      "metadata": {
        "id": "8fbmBg_iP5OD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mse_x.values"
      ],
      "metadata": {
        "id": "oG-8-R1vSsiA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mse_x.dot(X)"
      ],
      "metadata": {
        "id": "woT04feXQ4cS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X"
      ],
      "metadata": {
        "id": "8heWcnMYP6Ky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X.mul(mse_x)"
      ],
      "metadata": {
        "id": "CETJGwi3QNkK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# np.dot(mse_x, X)"
      ],
      "metadata": {
        "id": "avTHvFhPPubW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Numpy version"
      ],
      "metadata": {
        "id": "WFIh2dzdhDcf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = pd.DataFrame(X_mk)\n",
        "y = pd.Series(y_mk)\n",
        "X.columns = [f'col_{col}' for col in X.columns]\n",
        "\n",
        "class MyLineReg():\n",
        "    def __init__(self, n_iter=50, learning_rate=0.01, weights=None):\n",
        "        self.n_iter = n_iter\n",
        "        self.learning_rate = learning_rate\n",
        "        self.weights = weights\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"MyLineReg class: n_iter={self.n_iter}, learning_rate={self.learning_rate}\"\n",
        "\n",
        "    def fit(self, X, y, verbose=False):\n",
        "        X.to_numpy()\n",
        "        y.to_numpy()\n",
        "        X = np.c_[np.ones(X.shape[0]), X]\n",
        "        w = np.ones(X.shape[1])\n",
        "\n",
        "        for i in range(self.n_iter):\n",
        "            y_tilda = np.dot(X, w)\n",
        "            # print(y_tilda)\n",
        "\n",
        "            # print('y_t\\n', y_tilda[0: 5])\n",
        "            # print('y\\n', y[0: 5])\n",
        "            # print('y-y', (y_tilda - y))\n",
        "            nabla_mse = (2 / y.shape[0]) * ((y_tilda - y)).dot(X)\n",
        "            # print('nabla_mse = ', nabla_mse)\n",
        "            w -= self.learning_rate * nabla_mse\n",
        "            # print(verbose)\n",
        "            # print(i % verbose)\n",
        "            if verbose != False and i % verbose == 0:\n",
        "              err = np.mean((y - y_tilda)**2)\n",
        "              print(f'i = {i} | loss = {err}')\n",
        "\n",
        "    def get_coef(self):\n",
        "      return self.weights\n",
        "\n",
        "\n",
        "\n",
        "reg = MyLineReg()\n",
        "mse = reg.fit(X, y, verbose=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YiGPj_fRIZnu",
        "outputId": "7dbce71e-1092-4a08-a8f4-c76a8e22ccf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i = 0 | loss = 810.9197945296903\n",
            "i = 10 | loss = 606.6150502834279\n",
            "i = 20 | loss = 487.2410882189987\n",
            "i = 30 | loss = 407.11219048695597\n",
            "i = 40 | loss = 347.0692499463499\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = pd.DataFrame(X_mk)\n",
        "y = pd.Series(y_mk)\n",
        "X.columns = [f'col_{col}' for col in X.columns]\n",
        "\n",
        "class MyLineReg():\n",
        "    def __init__(self, n_iter=10, learning_rate=0.01, weights=None):\n",
        "        self.n_iter = n_iter\n",
        "        self.learning_rate = learning_rate\n",
        "        self.weights = weights\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"MyLineReg class: n_iter={self.n_iter}, learning_rate={self.learning_rate}\"\n",
        "\n",
        "    def fit(self, X, y, verbose=False):\n",
        "        X.to_numpy()\n",
        "        y.to_numpy()\n",
        "        X = np.c_[np.ones(X.shape[0]), X]\n",
        "        # print(X)\n",
        "        w = np.ones(X.shape[1])\n",
        "\n",
        "        for i in range(self.n_iter):\n",
        "            y_tilda = np.dot(X, w)\n",
        "            # print(y_tilda)\n",
        "            err = np.mean((y - y_tilda)**2)\n",
        "            print('err', err)\n",
        "            # print('y_t\\n', y_tilda[0: 5])\n",
        "            # print('y\\n', y[0: 5])\n",
        "            # print('y-y', (y_tilda - y))\n",
        "            nabla_mse = (2 / y.shape[0]) * ((y_tilda - y)).dot(X)\n",
        "            # print('nabla_mse = ', nabla_mse)\n",
        "            w -= self.learning_rate * nabla_mse\n",
        "\n",
        "            print(w)\n",
        "            # for k in range(len(W)):\n",
        "            #     print(X[k])\n",
        "                # W[k] -= self.learning_rate * ((2 / y.shape[0]) * np.sum(X[k] * (y_tilda - y)))\n",
        "\n",
        "        #     # print(w)\n",
        "        # # self.weights = w\n",
        "        # # print(self.weights)\n",
        "        # # return mse\n",
        "\n",
        "    # # def get_coef():\n",
        "reg = MyLineReg()\n",
        "mse = reg.fit(X, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "caa7qK6QCCou",
        "outputId": "be1a9510-1541-48ec-f986-52556b6cc69e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "err 810.9197945296903\n",
            "[0.83681081 1.20684179 1.05654835 0.55519368]\n",
            "err 784.3136942324145\n",
            "[0.68522456 1.41324185 1.11062721 0.12541128]\n",
            "err 759.3965115754756\n",
            "[ 0.54469836  1.61915866  1.16234536 -0.28997777]\n",
            "err 736.0309942220578\n",
            "[ 0.41471352  1.82455298  1.21180678 -0.69157645]\n",
            "err 714.0916155375182\n",
            "[ 0.29477443  2.02938773  1.25911087 -1.07996136]\n",
            "err 693.4635643447316\n",
            "[ 0.18440758  2.23362786  1.30435264 -1.45568388]\n",
            "err 674.0418218386642\n",
            "[ 0.08316054  2.43724031  1.34762291 -1.81927128]\n",
            "err 655.7303181388013\n",
            "[-0.00939891  2.6401939   1.38900849 -2.17122779]\n",
            "err 638.4411616071235\n",
            "[-0.09368375  2.84245923  1.42859238 -2.51203561]\n",
            "err 622.0939346523971\n",
            "[-0.1700885   3.0440086   1.46645388 -2.84215589]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = pd.DataFrame(X_mk)\n",
        "y = pd.Series(y_mk)\n",
        "X.columns = [f'col_{col}' for col in X.columns]\n",
        "\n",
        "# X.to_numpy()\n",
        "# X = np.c_[np.ones(X.shape[0]), X]\n",
        "# w = np.ones(X.shape[1])\n",
        "# X.dot(w)\n",
        "\n",
        "\n",
        "def calc_mse(y, y_pred):\n",
        "    err = np.mean((y - y_pred)**2)\n",
        "    return err\n",
        "\n",
        "class MyLineReg():\n",
        "    def __init__(self, n_iter=2, learning_rate=1, weights=None):\n",
        "        self.n_iter = n_iter\n",
        "        self.learning_rate = learning_rate\n",
        "        self.weights = weights\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"MyLineReg class: n_iter={self.n_iter}, learning_rate={self.learning_rate}\"\n",
        "\n",
        "    def calc_mse(y_pred, y_true):\n",
        "      err = np.mean((y_true - y_pred)**2)\n",
        "      return err\n",
        "\n",
        "\n",
        "    def fit(self, X, y, verbose=False):\n",
        "        X.to_numpy()\n",
        "        y.to_numpy()\n",
        "        X = np.c_[np.ones(X.shape[0]), X]\n",
        "        w = np.ones(X.shape[1])\n",
        "        W = np.ones(X.shape[1])\n",
        "        # print(w)\n",
        "        # print(X)\n",
        "\n",
        "        for i in range(self.n_iter):\n",
        "        #     # y_tilda = w.dot(X)\n",
        "            y_tilda = np.dot(X, w)\n",
        "            # print(y_tilda)\n",
        "            # mse = np.mean((y - y_tilda)**2) #/ y.shape[0]\n",
        "            mse = (y_tilda - y)**2\n",
        "            err = calc_mse(y, y_tilda)\n",
        "            print('mse', mse)\n",
        "            # print('err', err)\n",
        "            # print('y_t\\n', y_tilda[0: 5])\n",
        "            # print('y\\n', y[0: 5])\n",
        "            nabla_mse = (2 / y.shape[0]) * mse.dot(X)\n",
        "            #     # print('nabla_mse = ', nabla_mse)\n",
        "            w -= self.learning_rate * nabla_mse\n",
        "\n",
        "            print(X[1])\n",
        "            # for k in range(len(W)):\n",
        "            #     print(X[k])\n",
        "                # W[k] -= self.learning_rate * ((2 / y.shape[0]) * np.sum(X[k] * (y_tilda - y)))\n",
        "\n",
        "        #     # print(w)\n",
        "        # # self.weights = w\n",
        "        # # print(self.weights)\n",
        "        # # return mse\n",
        "\n",
        "    # # def get_coef():\n",
        "reg = MyLineReg()\n",
        "mse = reg.fit(X, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9guW4lnhGJt",
        "outputId": "db641f37-ffb8-4811-f055-1d1a2cf011bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mse 0    1256.143148\n",
            "1     365.696441\n",
            "dtype: float64\n",
            "[ 1.          0.64768854 -0.1382643   0.49671415]\n",
            "mse 0    2.372607e+07\n",
            "1    7.247143e+06\n",
            "dtype: float64\n",
            "[ 1.          0.64768854 -0.1382643   0.49671415]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array([[ 1.,         -0.23415337,  1.52302986, -0.23413696],\n",
        " [ 1.,          0.76743473,  1.57921282, -0.46947439],\n",
        " [ 1.,         -0.1382643,   0.49671415,  0.64768854]])\n",
        "\n",
        "print(X.shape)\n",
        "\n",
        "w = np.ones(X.shape[0])\n",
        "w\n",
        "# w = [1, 1, 1]\n",
        "# np.dot(X, w)\n",
        "np.dot(w, X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2PSzs2JrTcH",
        "outputId": "45d2a5ee-c81b-401f-f60f-d8fb1da6d808"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3, 4)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 3.        ,  0.39501706,  3.59895683, -0.05592281])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array([[1, 1, 1, 1],\n",
        "              [1, 1, 2, 5],\n",
        "              [1, 1, 2, 5]])\n",
        "X\n",
        "print(X.shape)\n",
        "\n",
        "W = np.array([1, 1, 1])\n",
        "\n",
        "# w = np.ones(X.shape[1])\n",
        "np.dot(W, X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_nKdT_drhIo",
        "outputId": "00baebf7-c4f0-4545-e9c3-253847c8c9c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3, 4)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 3,  3,  5, 11])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = pd.DataFrame(X_mk)\n",
        "y = pd.Series(y_mk)\n",
        "X.columns = [f'col_{col}' for col in X.columns]\n",
        "\n",
        "class MyLineReg():\n",
        "    def __init__(self, n_iter=51, learning_rate=0.01, weights=None):\n",
        "        self.n_iter = n_iter\n",
        "        self.learning_rate = learning_rate\n",
        "        self.weights = weights\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"MyLineReg class: n_iter={self.n_iter}, learning_rate={self.learning_rate}\"\n",
        "\n",
        "    def fit(self, X, y, verbose=False):\n",
        "        X.to_numpy()\n",
        "        y.to_numpy()\n",
        "        X = np.c_[np.ones(X.shape[0]), X]\n",
        "        w = np.ones(X.shape[1])\n",
        "\n",
        "        for i in range(self.n_iter):\n",
        "            y_tilda = np.dot(X, w)\n",
        "            nabla_mse = (2 / y.shape[0]) * ((y_tilda - y)).dot(X)\n",
        "            w -= self.learning_rate * nabla_mse\n",
        "\n",
        "            if verbose != False and i % verbose == 0:\n",
        "              err = np.mean((y - y_tilda)**2)\n",
        "              print(f'i = {i} | loss = {err}')\n",
        "\n",
        "            self.weights = w\n",
        "\n",
        "    def get_coef(self):\n",
        "      return self.weights\n",
        "\n",
        "\n",
        "\n",
        "reg = MyLineReg()\n",
        "reg.fit(X, y, verbose=10)\n",
        "c = reg.get_coef()\n",
        "c"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UssWS75ZgLjW",
        "outputId": "d9680fc3-685b-4668-eaf1-703b287b9025"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i = 0 | loss = 810.9197945296903\n",
            "i = 10 | loss = 606.6150502834279\n",
            "i = 20 | loss = 487.2410882189987\n",
            "i = 30 | loss = 407.11219048695597\n",
            "i = 40 | loss = 347.0692499463499\n",
            "i = 50 | loss = 298.7940110048301\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  0.35326258,  10.50815526,   2.16887989, -10.87486366])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "7oyfscoa1v-_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_mse(y, y_pred):\n",
        "    print(y)\n",
        "    print(y_pred)\n",
        "    err = np.mean((y - y_pred)**2)\n",
        "    return err\n",
        "\n",
        "X = pd.DataFrame(X_mk)\n",
        "y = pd.Series(y_mk)\n",
        "X.columns = [f'col_{col}' for col in X.columns]\n",
        "\n",
        "X = X.to_numpy()\n",
        "y = y.to_numpy()\n",
        "\n",
        "X\n",
        "# W = np.ones(X.shape[1])\n",
        "# W\n",
        "# y_pred = np.dot(X, W)\n",
        "# y_pred\n",
        "# # y\n",
        "\n",
        "# print(X.shape)\n",
        "\n",
        "def alpha_iter_search(X, alpha=1e-2, n_iter=100):\n",
        "  \"\"\"Алгоритм градиентного спуска, завершающий работу по превышению количества итераций\n",
        "       Альфа неизменна\"\"\"\n",
        "  n = X.shape[1]\n",
        "  W = np.ones(X.shape[1])\n",
        "  print(f'Number of objects = {n} \\\n",
        "       \\nLearning rate = {alpha} \\\n",
        "       \\nInitial weights = {W} \\n')\n",
        "\n",
        "  for i in range(n_iter):\n",
        "        y_pred = np.dot(X, W)\n",
        "        err = calc_mse(y, y_pred)\n",
        "\n",
        "        for k in range(len(W)):\n",
        "            W[k] -= alpha * (1/n * 2 * np.sum(X[k] * (y_pred - y)))\n",
        "        if i % 50 == 0:\n",
        "            # alpha /= 1.1\n",
        "            print(f'Iteration #{i} W_new = {W}, MSE = {round(err, 2)}')\n",
        "\n",
        "alpha_iter_search(X, alpha=0.05, n_iter=300)\n",
        "\n",
        "print('Подобранный вариант скорости обучения = 0.05')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "id": "lDKxa94V1wTQ",
        "outputId": "dbf4f1fd-04bf-47f2-9031-b26f32906294"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of objects = 3        \n",
            "Learning rate = 0.05        \n",
            "Initial weights = [1. 1. 1.] \n",
            "\n",
            "[-33.38737028  21.12932958]\n",
            "[1.05473952 1.00613839]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-824e6dcfabb4>\u001b[0m in \u001b[0;36m<cell line: 42>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Iteration #{i} W_new = {W}, MSE = {round(err, 2)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0malpha_iter_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Подобранный вариант скорости обучения = 0.05'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-29-824e6dcfabb4>\u001b[0m in \u001b[0;36malpha_iter_search\u001b[0;34m(X, alpha, n_iter)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0mW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m50\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;31m# alpha /= 1.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (3,) (2,) "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_mse(y, y_pred):\n",
        "    print(y)\n",
        "    print(y_pred)\n",
        "    err = np.mean((y - y_pred)**2)\n",
        "    return err\n",
        "\n",
        "X = pd.DataFrame(X_mk)\n",
        "y = pd.Series(y_mk)\n",
        "X.columns = [f'col_{col}' for col in X.columns]\n",
        "\n",
        "X = X.to_numpy()\n",
        "y = y.to_numpy()\n",
        "\n",
        "def alpha_iter_search(X, alpha=1e-2, n_iter=100):\n",
        "  \"\"\"Алгоритм градиентного спуска, завершающий работу по превышению количества итераций\n",
        "       Альфа неизменна\"\"\"\n",
        "  n = X.shape[1]\n",
        "  W = np.ones(X.shape[0])\n",
        "  print(f'Number of objects = {n} \\\n",
        "       \\nLearning rate = {alpha} \\\n",
        "       \\nInitial weights = {W} \\n')\n",
        "\n",
        "  for i in range(n_iter):\n",
        "        y_pred = np.dot(W, X)\n",
        "        err = calc_mse(y, y_pred)"
      ],
      "metadata": {
        "id": "k3hUFy_G-nDD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### GB variant"
      ],
      "metadata": {
        "id": "Jxij_8QF_GKa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = pd.DataFrame(X_mk)\n",
        "y = pd.Series(y_mk)\n",
        "X.columns = [f'col_{col}' for col in X.columns]\n",
        "\n",
        "X = X.to_numpy()\n",
        "y = y.to_numpy()"
      ],
      "metadata": {
        "id": "tl98Lf-O_baM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gi1g-29q_cqh",
        "outputId": "b18de06e-6ea6-4163-be13-4eb339d3ad81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-33.38737028,  21.12932958])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# X = np.array([[-0.23413696, -0.23415337,  1.52302986],\n",
        "#        [ 0.64768854, -0.1382643 ,  0.49671415]])\n",
        "\n",
        "X = np.array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
        "              [1, 1, 2, 5, 3, 0, 5, 10, 1, 2]])\n",
        "X\n",
        "\n",
        "y = [45, 55, 50, 55, 60, 35, 75, 80, 50, 60]\n",
        "# y=[-33.38737028,  21.12932958]\n",
        "\n",
        "def calc_mse(y, y_pred):\n",
        "    err = np.mean((y - y_pred)**2)\n",
        "    return err\n",
        "\n",
        "\n",
        "def alpha_iter_search(X, alpha=1e-2, n_iter=100):\n",
        "  \"\"\"Алгоритм градиентного спуска, завершающий работу по превышению количества итераций\n",
        "       Альфа неизменна\"\"\"\n",
        "  n = X.shape[1]\n",
        "  W = np.array([1, .5])\n",
        "  print(f'Number of objects = {n} \\\n",
        "       \\nLearning rate = {alpha} \\\n",
        "       \\nInitial weights = {W} \\n')\n",
        "\n",
        "  for i in range(n_iter):\n",
        "        y_pred = np.dot(W, X)\n",
        "        # print(y_pred.shape)\n",
        "        err = calc_mse(y, y_pred)\n",
        "        for k in range(len(W)):\n",
        "            W[k] -= alpha * (1/n * 2 * np.sum(X[k] * (y_pred - y)))\n",
        "        if i % 50 == 0:\n",
        "            # alpha /= 1.1\n",
        "            print(f'Iteration #{i} W_new = {W}, MSE = {round(err, 2)}')\n",
        "\n",
        "alpha_iter_search(X, alpha=0.05, n_iter=300)\n",
        "\n",
        "print('Подобранный вариант скорости обучения = 0.05')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YqAut3CX_J9B",
        "outputId": "5b2177e9-42ed-4ecc-8d21-2144dee1ad6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of objects = 10        \n",
            "Learning rate = 0.05        \n",
            "Initial weights = [1.  0.5] \n",
            "\n",
            "Iteration #0 W_new = [ 6.4  19.35], MSE = 3047.75\n",
            "Iteration #50 W_new = [41.16920131  4.51849616], MSE = 51.81\n",
            "Iteration #100 W_new = [44.68506002  3.88094292], MSE = 44.04\n",
            "Iteration #150 W_new = [45.02590869  3.81913527], MSE = 43.97\n",
            "Iteration #200 W_new = [45.05895262  3.81314326], MSE = 43.97\n",
            "Iteration #250 W_new = [45.0621561   3.81256236], MSE = 43.97\n",
            "Подобранный вариант скорости обучения = 0.05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Another решение."
      ],
      "metadata": {
        "id": "R61DpYfkw_OS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = pd.DataFrame(X_mk)\n",
        "y = pd.Series(y_mk)\n",
        "X.columns = [f'col_{col}' for col in X.columns]\n",
        "\n",
        "class MyLineReg:\n",
        "\n",
        "    n_iter_: int = 2\n",
        "    learning_rate_: float = 0.1\n",
        "    weights_: pd.Series = None\n",
        "\n",
        "    def __init__(self,  n_iter=n_iter_, learning_rate=learning_rate_) -> None:\n",
        "        self.n_iter_ = n_iter\n",
        "        self.learning_rate_ = learning_rate\n",
        "        self.weights_ = None\n",
        "\n",
        "    def __str__(self) -> str:\n",
        "        return f'MyLineReg class: n_iter={self.n_iter_}, learning_rate={self.learning_rate_}'\n",
        "\n",
        "    @staticmethod\n",
        "    def MSE(prediction: pd.Series, y: pd.Series) -> float:\n",
        "        return 1 / y.shape[0] * sum((prediction - y) ** 2)\n",
        "\n",
        "    @staticmethod\n",
        "    def grad_mse(prediction: pd.Series, y: pd.Series, X: pd.DataFrame) -> pd.Series:\n",
        "        return pd.Series(2 / y.shape[0] * (prediction - y) @ X)\n",
        "\n",
        "    def fit(self, X: pd.DataFrame, y: pd.Series, verbose=False) -> None:\n",
        "        X.insert(0, '', np.ones(X.shape[0]))\n",
        "        X, y = X.values, y.values\n",
        "        weights = pd.Series(np.ones(X.shape[1]))\n",
        "        # prediction = X @ weights\n",
        "\n",
        "        # if verbose:\n",
        "        #     print(f'start | loss: {self.MSE(prediction, y)}')\n",
        "\n",
        "        for iter in range(self.n_iter_):\n",
        "            prediction = X @ weights\n",
        "            mse_iter = self.MSE(prediction, y)\n",
        "            grad = self.grad_mse(prediction, y, X)\n",
        "            # print(grad)\n",
        "            weights -= self.learning_rate_ * grad\n",
        "            self.weights_ = weights\n",
        "\n",
        "            if verbose and iter % verbose == 0:\n",
        "                print(f'{iter} | loss: {mse_iter}')\n",
        "\n",
        "        return None\n",
        "\n",
        "    def get_coef(self):\n",
        "        return self.weights_[1:]\n",
        "\n",
        "reg = MyLineReg()\n",
        "reg.fit(X, y, verbose=0)\n",
        "c = reg.get_coef()\n",
        "c"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qaTKQeQRxDEK",
        "outputId": "1e210560-a595-472c-c221-d68cb8c3f051"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    5.092662\n",
              "2    1.884018\n",
              "3   -6.393735\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = pd.DataFrame(X_mk)\n",
        "y = pd.Series(y_mk)\n",
        "X.columns = [f'col_{col}' for col in X.columns]\n",
        "\n",
        "class MyLineReg():\n",
        "\n",
        "    n_iter_: int = 2\n",
        "    learning_rate_: float = 0.1\n",
        "    weights_: pd.Series = None\n",
        "\n",
        "\n",
        "    def __init__(self,  n_iter=n_iter_, learning_rate=learning_rate_) -> None:\n",
        "        self.n_iter_ = n_iter\n",
        "        self.learning_rate_ = learning_rate\n",
        "        self.weights_ = None\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"MyLineReg class: n_iter={self.n_iter}, learning_rate={self.learning_rate}\"\n",
        "\n",
        "    @staticmethod\n",
        "    def MSE(prediction: pd.Series, y: pd.Series) -> float:\n",
        "        return 1 / y.shape[0] * sum((prediction - y) ** 2)\n",
        "\n",
        "    @staticmethod\n",
        "    def grad_mse(prediction: pd.Series, y: pd.Series, X: pd.DataFrame) -> pd.Series:\n",
        "        return pd.Series(2 / y.shape[0] * (prediction - y) @ X)\n",
        "\n",
        "    def fit(self, X, y, verbose=False):\n",
        "        X.insert(loc=0, column='x_0', value=1)\n",
        "        X, y = X.values, y.values\n",
        "\n",
        "        # w = np.ones(X.shape[1])\n",
        "        w = pd.Series(np.ones(X.shape[1]))\n",
        "\n",
        "        for i in range(self.n_iter_):\n",
        "            # y_tilda = np.dot(X, w)\n",
        "            prediction = X @ w\n",
        "            mse_iter = self.MSE(prediction, y)\n",
        "            # nabla_mse = (2 / y.shape[0]) * ((prediction - y)).dot(X)\n",
        "            w -= self.learning_rate_ * mse_iter\n",
        "\n",
        "            if verbose != False and i % verbose == 0:\n",
        "              err = np.mean((y - prediction)**2)\n",
        "              print(f'i = {i} | loss = {err}')\n",
        "            self.weights = w\n",
        "\n",
        "    def get_coef(self):\n",
        "      return self.weights\n",
        "\n",
        "reg = MyLineReg()\n",
        "reg.fit(X, y, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iCXXsfS9_iw5",
        "outputId": "2b8f30fc-1f2b-4632-a079-e8c7149ac38c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i = 0 | loss = 810.9197945296903\n",
            "i = 1 | loss = 25130.71449162592\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = pd.DataFrame(X_mk)\n",
        "y = pd.Series(y_mk)\n",
        "X.columns = [f'col_{col}' for col in X.columns]\n",
        "\n",
        "class MyLineReg():\n",
        "    def __init__(self, n_iter=2, learning_rate=0.1, weights=None):\n",
        "        self.n_iter = n_iter\n",
        "        self.learning_rate = learning_rate\n",
        "        self.weights = weights\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"MyLineReg class: n_iter={self.n_iter}, learning_rate={self.learning_rate}\"\n",
        "\n",
        "    def fit(self, X, y, verbose=False):\n",
        "        X.to_numpy()\n",
        "        y.to_numpy()\n",
        "        X = np.c_[np.ones(X.shape[0]), X]\n",
        "        w = np.ones(X.shape[1])\n",
        "\n",
        "        y_tilda = np.dot(X, w)\n",
        "\n",
        "\n",
        "        if verbose:\n",
        "            print(f'start | loss: {np.mean((y_tilda - y)**2)}')\n",
        "\n",
        "        for i in range(self.n_iter):\n",
        "            y_tilda = np.dot(X, w)\n",
        "            # print(y_tilda)\n",
        "            nabla_mse = (2 / y.shape[0]) * ((y_tilda - y)).dot(X)\n",
        "            print(nabla_mse)\n",
        "            w -= self.learning_rate * nabla_mse\n",
        "\n",
        "            if verbose and i % verbose == 0:\n",
        "              err = np.mean((y_tilda - y)**2)\n",
        "              # err = 1 / y.shape[0] * sum((y_tilda - y) ** 2)\n",
        "              print(f'i = {i} | loss = {err}')\n",
        "\n",
        "            self.weights = w\n",
        "\n",
        "    def get_coef(self):\n",
        "      return self.weights[1:]\n",
        "\n",
        "\n",
        "reg = MyLineReg()\n",
        "reg.fit(X, y, verbose=1)\n",
        "c = reg.get_coef()\n",
        "c"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bE2MDl4DxSgi",
        "outputId": "7ca89e1e-5e31-490c-85f3-a32793d140d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "start | loss: 810.9197945296903\n",
            "[ 16.31891862 -20.68417949  -5.65483495  44.4806317 ]\n",
            "i = 0 | loss = 810.9197945296903\n",
            "[  4.71598742 -20.24244087  -3.18534441  29.45671377]\n",
            "i = 1 | loss = 584.491291098404\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 5.09266204,  1.88401794, -6.39373455])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Верное решение numpy."
      ],
      "metadata": {
        "id": "kYOVN1Hc-nRa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#### Верное решение numpy.\n",
        "X = pd.DataFrame(X_mk)\n",
        "y = pd.Series(y_mk)\n",
        "X.columns = [f'col_{col}' for col in X.columns]\n",
        "\n",
        "class MyLineReg():\n",
        "    def __init__(self, n_iter=50, learning_rate=0.1, weights=None) -> None:\n",
        "        self.n_iter = n_iter\n",
        "        self.learning_rate = learning_rate\n",
        "        self.weights = weights\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        return f\"MyLineReg class: n_iter={self.n_iter}, learning_rate={self.learning_rate}\"\n",
        "\n",
        "    def fit(self, X, y, verbose=False) -> None:\n",
        "        X.to_numpy()\n",
        "        y.to_numpy()\n",
        "        X = np.c_[np.ones(X.shape[0]), X]\n",
        "        w = np.ones(X.shape[1])\n",
        "\n",
        "        y_tilda = np.dot(X, w)\n",
        "\n",
        "        for i in range(self.n_iter):\n",
        "            y_tilda = np.dot(X, w)\n",
        "            nabla_mse = (2 / y.shape[0]) * ((y_tilda - y)).dot(X)\n",
        "            w -= self.learning_rate * nabla_mse\n",
        "\n",
        "            if verbose and i % verbose == 0:\n",
        "              err = np.mean((y_tilda - y)**2)\n",
        "              print(f'start | loss = {err}') if i == 0 else print(f'i = {i} | loss = {err}')\n",
        "\n",
        "            self.weights = w\n",
        "\n",
        "    def get_coef(self):\n",
        "      return self.weights[1:]\n",
        "\n",
        "reg = MyLineReg()\n",
        "reg.fit(X, y, verbose=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4OinoT4IfP7",
        "outputId": "340ada6e-32a6-420e-fe07-55feb2cfcbdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "start | loss = 810.9197945296903\n",
            "i = 10 | loss = 139.81959864186436\n",
            "i = 20 | loss = 32.585779251323856\n",
            "i = 30 | loss = 7.594408275896183\n",
            "i = 40 | loss = 1.7699450010116582\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2_1_7\n",
        "\n",
        "\n",
        "Предсказание\n",
        "Ну, и третьим (обязательным) шагом мы научим нашу модель выдавать предсказания...\n",
        "\n",
        "Добавьте в класс MyLineReg метод predict. Данный метод должен делать следующее:\n",
        "\n",
        "На вход принимать матрицу фичей в виде датафрейма пандаса.\n",
        "Дополнять матрицу фичей единичным вектором (первый столбец).\n",
        "Возвращать вектор предсказаний.\n",
        "Напомню, что предсказание выполняется следующим образом:\n",
        "�\n",
        "^\n",
        "=\n",
        "�\n",
        "�\n",
        "y\n",
        "^\n",
        "​\n",
        " =XW\n",
        "\n",
        "где:\n",
        "-\n",
        "X - матрица фичей\n",
        "-\n",
        "W - вектор весов\n",
        "\n",
        "Проверка\n",
        "\n",
        "Входные данные: три датасета с различными параметрами (сгенерированными посредством метода make_regression из scikit-learn)\n",
        "Выходные данные: возвращенные предсказания (их сумма)"
      ],
      "metadata": {
        "id": "xNdjv71LzHXT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## numpy"
      ],
      "metadata": {
        "id": "qIw7NGim-9tK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = pd.DataFrame(X_mk)\n",
        "y = pd.Series(y_mk)\n",
        "X.columns = [f'col_{col}' for col in X.columns]\n",
        "\n",
        "class MyLineReg():\n",
        "    def __init__(self, n_iter=50, learning_rate=0.1, weights=None) -> None:\n",
        "        self.n_iter = n_iter\n",
        "        self.learning_rate = learning_rate\n",
        "        self.weights = weights\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        return f\"MyLineReg class: n_iter={self.n_iter}, learning_rate={self.learning_rate}\"\n",
        "\n",
        "    def fit(self, X, y, verbose=False) -> None:\n",
        "        X.to_numpy()\n",
        "        y.to_numpy()\n",
        "        X = np.c_[np.ones(X.shape[0]), X]\n",
        "        w = np.ones(X.shape[1])\n",
        "\n",
        "        y_tilda = np.dot(X, w)\n",
        "\n",
        "        for i in range(self.n_iter):\n",
        "            y_tilda = np.dot(X, w)\n",
        "            nabla_mse = (2 / y.shape[0]) * ((y_tilda - y)).dot(X)\n",
        "            w -= self.learning_rate * nabla_mse\n",
        "\n",
        "            if verbose and i % verbose == 0:\n",
        "              err = np.mean((y_tilda - y)**2)\n",
        "              print(f'start | loss = {err}') if i == 0 else print(f'i = {i} | loss = {err}')\n",
        "\n",
        "            self.weights = w\n",
        "\n",
        "    def get_coef(self):\n",
        "      return self.weights[1:]\n",
        "\n",
        "    def predict(self, X):\n",
        "         X.to_numpy()\n",
        "         X = np.c_[np.ones(X.shape[0]), X]\n",
        "\n",
        "        #  y_pred = np.dot(X, self.weights)\n",
        "\n",
        "        #  return np.sum(y_pred)\n",
        "         return np.dot(X, self.weights)\n",
        "\n",
        "reg = MyLineReg()\n",
        "reg.fit(X, y, verbose=10)\n",
        "reg.predict(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZLUaK50zRur",
        "outputId": "dbe98383-925e-464d-82f5-61f08f533dca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "start | loss = 810.9197945296903\n",
            "i = 10 | loss = 139.81959864186436\n",
            "i = 20 | loss = 32.585779251323856\n",
            "i = 30 | loss = 7.594408275896183\n",
            "i = 40 | loss = 1.7699450010116582\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-32.91982746,  20.3506083 ])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## pandas"
      ],
      "metadata": {
        "id": "1egWkPP2-_5q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = pd.DataFrame(X_mk)\n",
        "y = pd.Series(y_mk)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "xYMj8ygyCG7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X = pd.DataFrame(X_mk)\n",
        "# y = pd.Series(y_mk)\n",
        "# X.columns = [f'col_{col}' for col in X.columns]\n",
        "\n",
        "class MyLineReg():\n",
        "    def __init__(self, n_iter=50, learning_rate=0.01, weights=None) -> None:\n",
        "        self.n_iter = n_iter\n",
        "        self.learning_rate = learning_rate\n",
        "        self.weights = weights\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"MyLineReg class: n_iter={self.n_iter}, learning_rate={self.learning_rate}\"\n",
        "\n",
        "    def fit(self, X, y, verbose=False):\n",
        "        X.insert(loc=0, column='x_0', value=1)\n",
        "        w = np.ones(X.shape[1])\n",
        "\n",
        "        for i in range(self.n_iter):\n",
        "            y_tilda = np.dot(X, w)\n",
        "            nabla_mse = (2 / y.shape[0]) * ((y_tilda - y)).dot(X)\n",
        "            w -= self.learning_rate * nabla_mse\n",
        "\n",
        "            if verbose != False and i % verbose == 0:\n",
        "              err = np.mean((y - y_tilda)**2)\n",
        "              print(f'i = {i} | loss = {err}')\n",
        "            self.weights = w.to_numpy()\n",
        "\n",
        "    def get_coef(self):\n",
        "      return self.weights[1:]\n",
        "\n",
        "    def predict(self, X):\n",
        "         X.insert(loc=0, column='x_x', value=1)\n",
        "\n",
        "         return np.dot(X, self.weights)\n",
        "\n",
        "\n",
        "reg = MyLineReg()\n",
        "reg.fit(X_train, y_train, verbose=10)\n",
        "reg.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dFk1BRZ_Kc2",
        "outputId": "b6d84831-c27e-402d-87b9-fa33647b663a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i = 0 | loss = 1256.1431476987827\n",
            "i = 10 | loss = 303.3195182707737\n",
            "i = 20 | loss = 73.24223384298229\n",
            "i = 30 | loss = 17.685722464853963\n",
            "i = 40 | loss = 4.2705521485648905\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-14.43018977])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2_1_9\n"
      ],
      "metadata": {
        "id": "_cOcCe16zLV6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Метрики (реализация)\n",
        "Теперь реализуем метрики на практике:\n",
        "\n",
        "Добавьте в класс MyLineReg параметр metric, который будет принимать одно из следующих значений:\n",
        "- mae\n",
        "- mse\n",
        "- rmse\n",
        "- mape\n",
        "- r2\n",
        "\n",
        "По умолчанию: None\n",
        "\n",
        "При обучении добавьте в вывод расчет метрики:\n",
        "\n",
        "start | loss: 42027.65 | <metric_name>: 234.65\n",
        "\n",
        "100 | loss: 1222.87 | <metric_name>: 114.35\n",
        "\n",
        "200 | loss: 232.17 | <metric_name>: 58.2\n",
        "\n",
        "300 | loss: 202.4 | <metric_name>: 46.01\n",
        "\n",
        "Если метрика не задана, то ничего дополнительно выводить не нужно.\n",
        "Добавьте метод get_best_score, который возвращает последнее значение метрики (т.е. уже полностью обученной модели).\n",
        "\n",
        "Примечания:\n",
        "\n",
        "Хотя мы теперь отслеживаем и другие метрики, градиентный спуск все равно выполняется по среднеквадратичной ошибке.\n",
        "Зачем мы добавили метрику MSE если у нас и так функция потерь это MSE? Во-первых, функцией потерь может быть не только MSE. Во-вторых, далее мы добавим к функции потерь регуляризацию, которая будет влиять на ее результат. А на метрику регуляризация влиять не должна.\n",
        "\n",
        "Проверка\n",
        "\n",
        "Входные данные: названия всех метрик\n",
        "Выходные данные: значение метрики полученное после обучения модели"
      ],
      "metadata": {
        "id": "vZaSOrMG7A5B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = pd.DataFrame(X_mk)\n",
        "y = pd.Series(y_mk)\n",
        "X.columns = [f'col_{col}' for col in X.columns]\n",
        "\n",
        "class MyLineReg():\n",
        "    def __init__(self, n_iter=50, learning_rate=0.1, weights=None, metric=None) -> None:\n",
        "        self.n_iter = n_iter\n",
        "        self.learning_rate = learning_rate\n",
        "        self.weights = weights\n",
        "        self.metric = metric\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        return f\"MyLineReg class: n_iter={self.n_iter}, learning_rate={self.learning_rate}\"\n",
        "\n",
        "    @staticmethod\n",
        "    def get_best_score(metric, y, y_tilda):\n",
        "        if metric == 'mae':\n",
        "            metr = np.sum(abs(y - y_tilda))\n",
        "        elif metric == 'mse':\n",
        "            metr = np.mean((y_tilda - y)**2)\n",
        "        elif metric == 'rmse':\n",
        "            metr = np.sqrt(np.mean((y_tilda - y)**2))\n",
        "        elif metric == 'mape':\n",
        "            metr = (100 / y.shape[0]) * np.sum(abs((y - y_tilda) / y_tilda))\n",
        "        elif metric == 'r2':\n",
        "            metr = 1 - ((np.sum((y - y_tilda)**2)) / (np.sum((y - np.mean(y))**2)))\n",
        "        return metr\n",
        "\n",
        "    def fit(self, X, y, verbose=False) -> None:\n",
        "        X.to_numpy()\n",
        "        y.to_numpy()\n",
        "        X = np.c_[np.ones(X.shape[0]), X]\n",
        "        w = np.ones(X.shape[1])\n",
        "\n",
        "        y_tilda = np.dot(X, w)\n",
        "\n",
        "        for i in range(self.n_iter):\n",
        "            y_tilda = np.dot(X, w)\n",
        "            nabla_mse = (2 / y.shape[0]) * ((y_tilda - y)).dot(X)\n",
        "            w -= self.learning_rate * nabla_mse\n",
        "\n",
        "            metr = self.get_best_score(self.metric, y, y_tilda) if self.metric else None\n",
        "\n",
        "            if verbose and i % verbose == 0:\n",
        "              err = np.mean((y_tilda - y)**2)\n",
        "              if metr != None:\n",
        "                  print(f'start | loss = {err}') if i == 0 else print(f'i = {i} | loss = {err} | {metr}')\n",
        "              else:\n",
        "                  print(f'start | loss = {err}') if i == 0 else print(f'i = {i} | loss = {err}')\n",
        "\n",
        "            self.weights = w\n",
        "\n",
        "    def get_coef(self):\n",
        "        return self.weights[1:]\n",
        "\n",
        "    def predict(self, X):\n",
        "        X.to_numpy()\n",
        "        X = np.c_[np.ones(X.shape[0]), X]\n",
        "\n",
        "        return np.dot(X, self.weights)\n",
        "\n",
        "reg = MyLineReg()\n",
        "reg.fit(X, y, verbose=10)\n",
        "# reg.predict(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVOR1WcQ3piJ",
        "outputId": "089a23b8-8cdc-4e71-bd10-9c9a89fb3fe8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "start | loss = 810.9197945296903\n",
            "i = 10 | loss = 139.81959864186436\n",
            "i = 20 | loss = 32.585779251323856\n",
            "i = 30 | loss = 7.594408275896183\n",
            "i = 40 | loss = 1.7699450010116582\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = pd.DataFrame(X_mk)\n",
        "y = pd.Series(y_mk)\n",
        "X.columns = [f'col_{col}' for col in X.columns]\n",
        "\n",
        "class MyLineReg():\n",
        "    def __init__(self, n_iter=50, learning_rate=0.1, weights=None, metric=None) -> None:\n",
        "        self.n_iter = n_iter\n",
        "        self.learning_rate = learning_rate\n",
        "        self.weights = weights\n",
        "        self.metric = metric\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        return f\"MyLineReg class: n_iter={self.n_iter}, learning_rate={self.learning_rate}\"\n",
        "\n",
        "\n",
        "    def get_best_score(self):\n",
        "        if self.metric == 'mae':\n",
        "            metr = np.sum(abs(self.y - self.y_tilda))\n",
        "        elif self.metric == 'mse':\n",
        "            metr = np.mean((self.y_tilda - self.y)**2)\n",
        "        elif self.metric == 'rmse':\n",
        "            metr = np.sqrt(np.mean((self.y_tilda - self.y)**2))\n",
        "        elif self.metric == 'mape':\n",
        "            metr = (100 / self.y.shape[0]) * np.sum(abs((self.y - self.y_tilda) / self.y_tilda))\n",
        "        elif self.metric == 'r2':\n",
        "            metr = 1 - ((np.sum((self.y - self.y_tilda)**2)) / (np.sum((self.y - np.mean(self.y))**2)))\n",
        "        return metr\n",
        "\n",
        "    def fit(self, X, y, verbose=False) -> None:\n",
        "        X.to_numpy()\n",
        "        y.to_numpy()\n",
        "        X = np.c_[np.ones(X.shape[0]), X]\n",
        "        w = np.ones(X.shape[1])\n",
        "\n",
        "        y_tilda = np.dot(X, w)\n",
        "        self.y = y\n",
        "        self.y_tilda = y_tilda\n",
        "\n",
        "        for i in range(self.n_iter):\n",
        "            y_tilda = np.dot(X, w)\n",
        "            nabla_mse = (2 / y.shape[0]) * ((y_tilda - y)).dot(X)\n",
        "            w -= self.learning_rate * nabla_mse\n",
        "\n",
        "            metr = self.get_best_score() if self.metric else None\n",
        "\n",
        "            if verbose and i % verbose == 0:\n",
        "              err = np.mean((y_tilda - y)**2)\n",
        "              if metr != None:\n",
        "                  print(f'start | loss = {err}') if i == 0 else print(f'i = {i} | loss = {err} | {metr}')\n",
        "              else:\n",
        "                  print(f'start | loss = {err}') if i == 0 else print(f'i = {i} | loss = {err}')\n",
        "\n",
        "            self.weights = w\n",
        "\n",
        "    def get_coef(self):\n",
        "        return self.weights[1:]\n",
        "\n",
        "    def predict(self, X):\n",
        "        X.to_numpy()\n",
        "        X = np.c_[np.ones(X.shape[0]), X]\n",
        "\n",
        "        return np.dot(X, self.weights)\n",
        "\n",
        "reg = MyLineReg()\n",
        "reg.get_best_score()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PN9qbWGsRnu2",
        "outputId": "8f036e30-52a5-47c0-da02-e5fd7db544d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Перепишем заново"
      ],
      "metadata": {
        "id": "HQDZZUaEYNmW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## numpy"
      ],
      "metadata": {
        "id": "CkwcG2pgxquv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# рабочая версия, но она на нампае, а нужно в пандас перевести.\n",
        "\n",
        "X = pd.DataFrame(X_mk)\n",
        "y = pd.Series(y_mk)\n",
        "X.columns = [f'col_{col}' for col in X.columns]\n",
        "\n",
        "class MyLineReg():\n",
        "    def __init__(self,\n",
        "                 n_iter=3,\n",
        "                 learning_rate= 0.1,\n",
        "                 weights = None,\n",
        "                 metric=None) -> None:\n",
        "\n",
        "        self.n_iter = n_iter\n",
        "        self.learning_rate = learning_rate\n",
        "        self.weights = weights\n",
        "        self.metric = metric\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        return f\"MyLineReg class: n_iter={self.n_iter}, learning_rate={self.learning_rate}\"\n",
        "\n",
        "    def get_best_score(self):\n",
        "        return self.score\n",
        "\n",
        "    @staticmethod\n",
        "    def get_metric_score(metric, y, y_tilda):\n",
        "        if metric == 'mae':\n",
        "            score = (y - y_tilda).abs().mean()\n",
        "        elif metric == 'mse':\n",
        "            score = np.mean((y_tilda - y)**2)\n",
        "        elif metric == 'rmse':\n",
        "            score = np.sqrt(np.mean((y_tilda - y)**2))\n",
        "        elif metric == 'mape':\n",
        "            score = (100 / y.shape[0]) * np.sum(abs((y - y_tilda) / y_tilda))\n",
        "        elif metric == 'r2':\n",
        "            score = 1 - ((np.sum((y - y_tilda)**2)) / (np.sum((y - np.mean(y))**2)))\n",
        "        return score\n",
        "\n",
        "    def fit(self, X, y, verbose=False) -> None:\n",
        "        X.to_numpy()\n",
        "        y.to_numpy()\n",
        "        X = np.c_[np.ones(X.shape[0]), X]\n",
        "        w = np.ones(X.shape[1])\n",
        "\n",
        "\n",
        "        for i in range(self.n_iter):\n",
        "            y_tilda = np.round(np.dot(X, w), 6)\n",
        "            err = np.mean((y_tilda - y)**2)\n",
        "            nabla_mse = (2 / y.shape[0]) * ((y_tilda - y)).dot(X)\n",
        "\n",
        "            w -= self.learning_rate * nabla_mse\n",
        "\n",
        "            if self.metric:\n",
        "               self.score = getattr(self, 'get_metric_score')(self.metric, y, np.dot(X, w))\n",
        "\n",
        "            if verbose and i % verbose == 0:\n",
        "              if self.metric:\n",
        "                  print(f'start | loss = {err} | {self.score}') if i == 0 else print(f'i = {i} | loss = {err} | {self.score}')\n",
        "              else:\n",
        "                  print(f'start | loss = {err}') if i == 0 else print(f'i = {i} | loss = {err}')\n",
        "\n",
        "            self.weights = w\n",
        "\n",
        "reg = MyLineReg(metric='mae')\n",
        "# reg.get_best_score()\n",
        "reg.fit(X, y, verbose=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qoY47HxKYQVT",
        "outputId": "1d52e6eb-1020-4112-a00d-ccdf4be74b08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "start | loss = 810.9198188309781 | 24.06098823146364\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## pandas"
      ],
      "metadata": {
        "id": "punRgqxqxtaQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = pd.DataFrame(X_mk)\n",
        "y = pd.Series(y_mk)\n",
        "\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "nkgQgsOPKUUT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = pd.DataFrame(X_mk)\n",
        "y = pd.Series(y_mk)\n",
        "\n",
        "class MyLineReg():\n",
        "    def __init__(self,\n",
        "                 n_iter=3,\n",
        "                 learning_rate= 0.1,\n",
        "                 weights = None,\n",
        "                 metric=None) -> None:\n",
        "\n",
        "        self.n_iter = n_iter\n",
        "        self.learning_rate = learning_rate\n",
        "        self.weights = weights\n",
        "        self.metric = metric\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"MyLineReg class: n_iter={self.n_iter}, learning_rate={self.learning_rate}\"\n",
        "\n",
        "    def get_best_score(self):\n",
        "        return self.score\n",
        "\n",
        "\n",
        "    def get_coef(self):\n",
        "      return self.weights[1:]\n",
        "\n",
        "    def predict(self, X):\n",
        "         X.insert(loc=0, column='x_x', value=1)\n",
        "\n",
        "         return np.dot(X, self.weights)\n",
        "\n",
        "    @staticmethod\n",
        "    def get_metric_score(metric, y, y_tilda):\n",
        "        if metric == 'mae':\n",
        "            score = (y - y_tilda).abs().mean()\n",
        "        elif metric == 'mse':\n",
        "            score = np.mean((y_tilda - y)**2)\n",
        "        elif metric == 'rmse':\n",
        "            score = np.sqrt(np.mean((y_tilda - y)**2))\n",
        "        elif metric == 'mape':\n",
        "            score = (100 / y.shape[0]) * np.sum(abs((y - y_tilda) / y))\n",
        "            # score = 100 * ((y - y_tilda) / y).abs().mean()\n",
        "        elif metric == 'r2':\n",
        "            score = 1 - ((np.sum((y - y_tilda)**2)) / (np.sum((y - np.mean(y))**2)))\n",
        "        return score\n",
        "\n",
        "    def fit(self, X, y, verbose=False):\n",
        "        X.insert(loc=0, column='x_0', value=1)\n",
        "        w = np.ones(X.shape[1])\n",
        "\n",
        "        for i in range(self.n_iter):\n",
        "            y_tilda = np.dot(X, w)\n",
        "            err = np.mean((y_tilda - y)**2)\n",
        "            nabla_mse = (2 / y.shape[0]) * ((y_tilda - y)).dot(X)\n",
        "            w -= self.learning_rate * nabla_mse\n",
        "\n",
        "            if self.metric:\n",
        "               self.score = getattr(self, 'get_metric_score')(self.metric, y, np.dot(X, w))\n",
        "\n",
        "            if verbose and i % verbose == 0:\n",
        "              if self.metric:\n",
        "                  print(f'start | loss = {err} | {self.score}') if i == 0 else print(f'i = {i} | loss = {err} | {self.score}')\n",
        "              else:\n",
        "                  print(f'start | loss = {err}') if i == 0 else print(f'i = {i} | loss = {err}')\n",
        "\n",
        "            self.weights = w.to_numpy()\n",
        "\n",
        "\n",
        "reg = MyLineReg(metric='mape')\n",
        "reg.fit(X, y, verbose=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FA7VJn7XEDr-",
        "outputId": "d7a7093f-88f3-4663-9a4c-3a1fe91676f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "start | loss = 810.9197945296903 | 90.92184361849664\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# верное решение\n",
        "\n",
        "class MyLineReg():\n",
        "    def __init__(self,\n",
        "                 n_iter=3,\n",
        "                 learning_rate= 0.1,\n",
        "                 weights = None,\n",
        "                 metric=None) -> None:\n",
        "\n",
        "        self.n_iter = n_iter\n",
        "        self.learning_rate = learning_rate\n",
        "        self.weights = weights\n",
        "        self.metric = metric\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"MyLineReg class: n_iter={self.n_iter}, learning_rate={self.learning_rate}\"\n",
        "\n",
        "    def get_best_score(self):\n",
        "        return self.score\n",
        "\n",
        "\n",
        "    def get_coef(self):\n",
        "      return self.weights[1:]\n",
        "\n",
        "    def predict(self, X):\n",
        "         X.insert(loc=0, column='x_x', value=1)\n",
        "\n",
        "         return np.dot(X, self.weights)\n",
        "\n",
        "    @staticmethod\n",
        "    def get_metric_score(metric, y, y_tilda):\n",
        "        if metric == 'mae':\n",
        "            score = (y - y_tilda).abs().mean()\n",
        "        elif metric == 'mse':\n",
        "            score = np.mean((y_tilda - y)**2)\n",
        "        elif metric == 'rmse':\n",
        "            score = np.sqrt(np.mean((y_tilda - y)**2))\n",
        "        elif metric == 'mape':\n",
        "            score = (100 / y.shape[0]) * np.sum(abs((y - y_tilda) / y))\n",
        "        elif metric == 'r2':\n",
        "            score = 1 - ((np.sum((y - y_tilda)**2)) / (np.sum((y - np.mean(y))**2)))\n",
        "        return score\n",
        "\n",
        "    def fit(self, X, y, verbose=False):\n",
        "        X.insert(loc=0, column='x_0', value=1)\n",
        "        w = np.ones(X.shape[1])\n",
        "\n",
        "        for i in range(self.n_iter):\n",
        "            y_tilda = np.dot(X, w)\n",
        "            err = np.mean((y_tilda - y)**2)\n",
        "            nabla_mse = (2 / y.shape[0]) * ((y_tilda - y)).dot(X)\n",
        "            w -= self.learning_rate * nabla_mse\n",
        "\n",
        "            if self.metric:\n",
        "               self.score = getattr(self, 'get_metric_score')(self.metric, y, np.dot(X, w))\n",
        "\n",
        "            if verbose and i % verbose == 0:\n",
        "              if self.metric:\n",
        "                  print(f'start | loss = {err} | {self.score}') if i == 0 else print(f'i = {i} | loss = {err} | {self.score}')\n",
        "              else:\n",
        "                  print(f'start | loss = {err}') if i == 0 else print(f'i = {i} | loss = {err}')\n",
        "\n",
        "            self.weights = w.to_numpy()"
      ],
      "metadata": {
        "id": "D7DeaBu7P9Gk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Another решение."
      ],
      "metadata": {
        "id": "FYksezuWxkK7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "h8VlMjN3eY-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = pd.DataFrame(X_mk)\n",
        "y = pd.Series(y_mk)\n",
        "X.columns = [f'col_{col}' for col in X.columns]\n",
        "\n",
        "\n",
        "class MyLineReg:\n",
        "    def __init__(self,\n",
        "                 n_iter: int = 3,\n",
        "                 learning_rate: float = 0.1,\n",
        "                 metric: str = None,\n",
        "                 reg: str = 'None',\n",
        "                 l1_coef: float = 0.,\n",
        "                 l2_coef: float = 0.,\n",
        "                 sgd_sample: float = None,\n",
        "                 random_state: int = 42) -> None:\n",
        "        self.n_iter = n_iter\n",
        "        self.learning_rate = learning_rate\n",
        "        self._weights = None\n",
        "        self.metric = metric\n",
        "        self.reg = reg  # 'l1', 'l2', 'elasticnet'\n",
        "        self.l1_coef = l1_coef\n",
        "        self.l2_coef = l2_coef\n",
        "        self.sgd_sample = sgd_sample\n",
        "        # random.seed(random_state)\n",
        "\n",
        "    def __str__(self) -> str:\n",
        "        params = [f'{key}={value}' for key, value in self.__dict__.items()]\n",
        "        return 'MyLineReg class: ' + ', '.join(params)\n",
        "\n",
        "    @staticmethod\n",
        "    def _mae(y_true: pd.Series, y_pred: pd.Series):\n",
        "        return (y_true - y_pred).abs().mean()\n",
        "\n",
        "    @staticmethod\n",
        "    def _mse(y_true: pd.Series, y_pred: pd.Series):\n",
        "        return (y_true - y_pred).pow(2).mean()\n",
        "\n",
        "    @staticmethod\n",
        "    def _rmse(y_true: pd.Series, y_pred: pd.Series):\n",
        "        return np.sqrt((y_true - y_pred).pow(2).mean())\n",
        "\n",
        "    @staticmethod\n",
        "    def _mape(y_true: pd.Series, y_pred: pd.Series):\n",
        "        return 100 * ((y_true - y_pred) / y_true).abs().mean()\n",
        "\n",
        "    @staticmethod\n",
        "    def _r2(y_true: pd.Series, y_pred: pd.Series):\n",
        "        return 1 - (y_true - y_pred).pow(2).sum() / ((y_true - y_true.mean()).pow(2).sum())\n",
        "\n",
        "    def get_best_score(self):\n",
        "        return self.score\n",
        "\n",
        "\n",
        "    def loss(self, y_true: pd.Series, y_pred: pd.Series) -> float:\n",
        "        if self.reg == 'None':\n",
        "            return (y_pred - y_true).pow(2).mean()\n",
        "        elif self.reg == 'l1':\n",
        "            return (y_pred - y_true).pow(2).mean() +\\\n",
        "                self.l1_coef * self._weights.abs().sum()\n",
        "        elif self.reg == 'l2':\n",
        "            return (y_pred - y_true).pow(2).mean() +\\\n",
        "                self.l2_coef * self._weights.pow(2).sum()\n",
        "        else:\n",
        "            return (y_pred - y_true).pow(2).mean() +\\\n",
        "                self.l1_coef * self._weights.abs().sum() +\\\n",
        "                self.l2_coef * (self._weights.pow(2).sum())\n",
        "\n",
        "    def grad(self, y_true: pd.Series, y_pred: pd.Series, x: pd.DataFrame, mini_batch_idx: pd.DataFrame.index):\n",
        "        y_true = y_true.iloc[mini_batch_idx]\n",
        "        y_pred = y_pred.iloc[mini_batch_idx]\n",
        "        x = x.iloc[mini_batch_idx, :]\n",
        "\n",
        "        if not self.reg:\n",
        "            return (2 / y_true.shape[0]) * (y_pred - y_true) @ x\n",
        "        elif self.reg == 'l1':\n",
        "            return (2 / y_true.shape[0]) * (y_pred - y_true) @ x +\\\n",
        "                self.l1_coef * np.sign(self._weights)\n",
        "        elif self.reg == 'l2':\n",
        "            return (2 / y_true.shape[0]) * (y_pred - y_true) @ x +\\\n",
        "                self.l2_coef * 2 * self._weights\n",
        "        else:\n",
        "            return (2 / y_true.shape[0]) * (y_pred - y_true) @ x +\\\n",
        "                self.l1_coef * np.sign(self._weights) +\\\n",
        "                self.l2_coef * 2 * self._weights\n",
        "\n",
        "    # def _get_minibatch_idx(self, x_length, sample) -> pd.DataFrame.index:\n",
        "    #     sample = int(sample * x_length) if isinstance(sample, float) else sample\n",
        "    #     return random.sample(range(x_length), sample)\n",
        "\n",
        "    def fit(self, x: pd.DataFrame, y: pd.Series, verbose: int) -> None:\n",
        "        x = pd.concat([pd.Series([1] * x.shape[0], index=x.index), x], axis=1)\n",
        "        self._weights = pd.Series([1.] * x.shape[1], index=x.columns)\n",
        "        for i in range(self.n_iter):\n",
        "            mini_batch_idx = self._get_minibatch_idx(x.shape[0], self.sgd_sample) if self.sgd_sample else x.index\n",
        "            y_hat = self._weights @ x.T\n",
        "            loss = self.loss(y, y_hat)\n",
        "            grad = self.grad(y, y_hat, x, mini_batch_idx)\n",
        "            if isinstance(self.learning_rate, (int, float)):\n",
        "                self._weights -= self.learning_rate * grad\n",
        "            else:\n",
        "                self._weights -= self.learning_rate(i + 1) * grad\n",
        "            if self.metric:\n",
        "                self.score = getattr(self, '_' + self.metric)(y, x @ self._weights)\n",
        "            if verbose and i % verbose == 0:\n",
        "                if self.metric:\n",
        "                    print(f'{i} | loss: {loss} | {self.metric}: {self.score}')\n",
        "                else:\n",
        "                    print(f'{i} | loss: {loss}')\n",
        "\n",
        "    def get_coef(self):\n",
        "        return self._weights[1:]\n",
        "\n",
        "    def predict(self, x: pd.DataFrame):\n",
        "        x = pd.concat([pd.Series([1] * x.shape[0], index=x.index), x], axis=1).values\n",
        "        return x @ self._weights\n",
        "\n",
        "\n",
        "# X, y = make_regression(n_samples=400, n_features=14, n_informative=5, noise=5, random_state=42)\n",
        "# X = pd.DataFrame(X)\n",
        "# y = pd.Series(y)\n",
        "# X.columns = [f'col_{col}' for col in X.columns]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "reg = MyLineReg(metric='mae')\n",
        "# reg.fit(X_train, y_train, 20)\n",
        "\n",
        "\n",
        "# print(reg.get_coef().sum())\n",
        "\n",
        "# reg.get_best_score()\n",
        "\n",
        "reg.fit(X, y, 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mqw3HpdKeH3V",
        "outputId": "0645aea8-e2a3-428d-c30b-d5ba53bb157f"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 | loss: 4690.118351259567 | mae: 46.51753895770776\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = np.array([-33.38737, 21.12933])\n",
        "# y_tilda = np.array([2.05474,  2.006138])\n",
        "y_tilda = np.array([2.054740, 2.006138])\n",
        "\n",
        "np.abs(y_tilda - y).mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GDo19AUEtlVD",
        "outputId": "2970efe6-9a15-4479-ed8d-185ee3769f49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "27.282651"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2_1_11"
      ],
      "metadata": {
        "id": "517IIRZmQZBH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = pd.DataFrame(X_mk)\n",
        "y = pd.Series(y_mk)\n",
        "\n",
        "class MyLineReg():\n",
        "    def __init__(self,\n",
        "                 n_iter=3,\n",
        "                 learning_rate= 0.1,\n",
        "                 weights = None,\n",
        "                 metric=None,\n",
        "                 reg=None,\n",
        "                 l1_coef: float = 0.,\n",
        "                 l2_coef: float = 0.,) -> None:\n",
        "\n",
        "        self.n_iter = n_iter\n",
        "        self.learning_rate = learning_rate\n",
        "        self.weights = weights\n",
        "        self.metric = metric\n",
        "        self.reg = reg\n",
        "        self.l1_coef = l1_coef\n",
        "        self.l2_coef = l2_coef\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"MyLineReg class: n_iter={self.n_iter}, learning_rate={self.learning_rate}\"\n",
        "\n",
        "    def get_best_score(self):\n",
        "        return self.score\n",
        "\n",
        "    def get_coef(self):\n",
        "      return self.weights[1:]\n",
        "\n",
        "    def predict(self, X):\n",
        "         X.insert(loc=0, column='x_x', value=1)\n",
        "\n",
        "         return np.dot(X, self.weights)\n",
        "\n",
        "    @staticmethod\n",
        "    def get_metric_score(metric, y, y_pred):\n",
        "        if metric == 'mae':\n",
        "            score = (y - y_pred).abs().mean()\n",
        "        elif metric == 'mse':\n",
        "            score = np.mean((y_pred - y)**2)\n",
        "        elif metric == 'rmse':\n",
        "            score = np.sqrt(np.mean((y_pred - y)**2))\n",
        "        elif metric == 'mape':\n",
        "            score = (100 / y.shape[0]) * np.sum(abs((y - y_pred) / y))\n",
        "        elif metric == 'r2':\n",
        "            score = 1 - ((np.sum((y - y_pred)**2)) / (np.sum((y - np.mean(y))**2)))\n",
        "        return score\n",
        "\n",
        "    def grad(self, y_true: pd.Series, y_pred: pd.Series, X: pd.DataFrame):\n",
        "\n",
        "        if not self.reg:\n",
        "           grad = (2 / y.shape[0]) * ((y_pred - y)).dot(X)\n",
        "        elif self.reg == 'l1':\n",
        "           grad = (2 / y.shape[0]) * ((y_pred - y)).dot(X) + self.l1_coef * np.sign(self.weights)\n",
        "        elif self.reg == 'l2':\n",
        "           grad = (2 / y.shape[0]) * ((y_pred - y)).dot(X) + self.l2_coef * 2 * (self.weights)\n",
        "        elif self.reg == 'elasticnet':\n",
        "           grad = (2 / y.shape[0]) * ((y_pred - y)).dot(X) + self.l1_coef * np.sign(self.weights) + self.l2_coef * 2 * (self.weights)\n",
        "\n",
        "        return grad\n",
        "\n",
        "    def fit(self, X, y, verbose=False):\n",
        "        X.insert(loc=0, column='x_0', value=1)\n",
        "        # w = np.ones(X.shape[1])\n",
        "\n",
        "        self.weights = np.ones(X.shape[1])\n",
        "\n",
        "        for i in range(self.n_iter):\n",
        "            y_pred = np.dot(X, self.weights)\n",
        "            err = np.mean((y_pred - y)**2)\n",
        "            # nabla_mse = (2 / y.shape[0]) * ((y_pred - y)).dot(X)\n",
        "            nabla = self.grad(y, y_pred, X)\n",
        "\n",
        "            self.weights -= self.learning_rate * nabla\n",
        "\n",
        "            if self.metric:\n",
        "               self.score = getattr(self, 'get_metric_score')(self.metric, y, np.dot(X, self.weights))\n",
        "\n",
        "            if verbose and i % verbose == 0:\n",
        "              if self.metric:\n",
        "                  print(f'start | loss = {err} | {self.score}') if i == 0 else print(f'i = {i} | loss = {err} | {self.score}')\n",
        "              else:\n",
        "                  print(f'start | loss = {err}') if i == 0 else print(f'i = {i} | loss = {err}')\n",
        "\n",
        "            # self.weights = w.to_numpy()\n",
        "\n",
        "\n",
        "reg = MyLineReg(metric='mape')\n",
        "reg.fit(X, y, verbose=10)"
      ],
      "metadata": {
        "id": "wJCw4OJuropk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f36a682-7f64-4e71-e18c-8bd2bad2b75f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "start | loss = 810.9197945296903 | 90.92184361849664\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# correct version\n",
        "\n",
        "class MyLineReg():\n",
        "    def __init__(self,\n",
        "                 n_iter=3,\n",
        "                 learning_rate= 0.1,\n",
        "                 weights = None,\n",
        "                 metric=None,\n",
        "                 reg=None,\n",
        "                 l1_coef: float = 0.,\n",
        "                 l2_coef: float = 0.,) -> None:\n",
        "\n",
        "        self.n_iter = n_iter\n",
        "        self.learning_rate = learning_rate\n",
        "        self.weights = weights\n",
        "        self.metric = metric\n",
        "        self.reg = reg\n",
        "        self.l1_coef = l1_coef\n",
        "        self.l2_coef = l2_coef\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"MyLineReg class: n_iter={self.n_iter}, learning_rate={self.learning_rate}\"\n",
        "\n",
        "    def get_best_score(self):\n",
        "        return self.score\n",
        "\n",
        "    def get_coef(self):\n",
        "        return self.weights[1:]\n",
        "\n",
        "    def predict(self, X):\n",
        "         X.insert(loc=0, column='x_x', value=1)\n",
        "\n",
        "         return np.dot(X, self.weights)\n",
        "\n",
        "    @staticmethod\n",
        "    def get_metric_score(metric, y, y_pred):\n",
        "        if metric == 'mae':\n",
        "            score = (y - y_pred).abs().mean()\n",
        "        elif metric == 'mse':\n",
        "            score = np.mean((y_pred - y)**2)\n",
        "        elif metric == 'rmse':\n",
        "            score = np.sqrt(np.mean((y_pred - y)**2))\n",
        "        elif metric == 'mape':\n",
        "            score = (100 / y.shape[0]) * np.sum(abs((y - y_pred) / y))\n",
        "        elif metric == 'r2':\n",
        "            score = 1 - ((np.sum((y - y_pred)**2)) / (np.sum((y - np.mean(y))**2)))\n",
        "        return score\n",
        "\n",
        "    def grad(self, y_true: pd.Series, y_pred: pd.Series, X: pd.DataFrame):\n",
        "\n",
        "        if not self.reg:\n",
        "           grad = (2 / y.shape[0]) * ((y_pred - y)).dot(X)\n",
        "        elif self.reg == 'l1':\n",
        "           grad = (2 / y.shape[0]) * ((y_pred - y)).dot(X) + self.l1_coef * np.sign(self.weights)\n",
        "        elif self.reg == 'l2':\n",
        "           grad = (2 / y.shape[0]) * ((y_pred - y)).dot(X) + self.l2_coef * 2 * (self.weights)\n",
        "        elif self.reg == 'elasticnet':\n",
        "           grad = (2 / y.shape[0]) * ((y_pred - y)).dot(X) + self.l1_coef * np.sign(self.weights) + self.l2_coef * 2 * (self.weights)\n",
        "\n",
        "        return grad\n",
        "\n",
        "    def fit(self, X, y, verbose=False):\n",
        "        X.insert(loc=0, column='x_0', value=1)\n",
        "\n",
        "        self.weights = np.ones(X.shape[1])\n",
        "\n",
        "        for i in range(self.n_iter):\n",
        "            y_pred = np.dot(X, self.weights)\n",
        "            err = np.mean((y_pred - y)**2)\n",
        "            nabla = self.grad(y, y_pred, X)\n",
        "\n",
        "            self.weights -= self.learning_rate * nabla\n",
        "\n",
        "            if self.metric:\n",
        "               self.score = getattr(self, 'get_metric_score')(self.metric, y, np.dot(X, self.weights))\n",
        "\n",
        "            if verbose and i % verbose == 0:\n",
        "               if self.metric:\n",
        "                   print(f'start | loss = {err} | {self.score}') if i == 0 else print(f'i = {i} | loss = {err} | {self.score}')\n",
        "               else:\n",
        "                   print(f'start | loss = {err}') if i == 0 else print(f'i = {i} | loss = {err}')"
      ],
      "metadata": {
        "id": "MOGJIT62OuT_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2_1_12\n",
        "\n",
        "Возьмите код из предыдущего шага и модифицируйте в нем параметр learning_rate следующим:\n",
        "\n",
        "Если на вход пришло число, то работаем как и раньше.\n",
        "Если на вход пришла lambda-функция, то вычисляем learning_rate на каждом шаге на основе переданной лямбда-функции.\n",
        "Можете дополнительно для контроля вывести значение learning_rate в лог тренировки.\n",
        "\n",
        "Примечания:\n",
        "\n",
        "Т.к. у нас теперь результат зависит от нумерации шагов, то формализуем их нумерацию: они должна считаться от 1 до n_iter (включительно).\n",
        "Проверка\n",
        "\n",
        "\n",
        "Входные данные: три различных значения для скорости обучения, два из которых — динамические\n",
        "\n",
        "Выходные данные: коэффициенты обученной линейной регрессии (их сумма)"
      ],
      "metadata": {
        "id": "Re8UEHBjREqr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def f():\n",
        "  pass\n",
        "\n",
        "isinstance(f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "xu33TMS3WoPR",
        "outputId": "f91a72c2-bd0c-4998-d5fc-c1a033f1368f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-d592c561d99c>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: isinstance expected 2 arguments, got 1"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MyLineReg():\n",
        "    def __init__(self,\n",
        "                 n_iter=3,\n",
        "                 learning_rate= 0.1,\n",
        "                 weights = None,\n",
        "                 metric=None,\n",
        "                 reg=None,\n",
        "                 l1_coef: float = 0.,\n",
        "                 l2_coef: float = 0.,) -> None:\n",
        "\n",
        "        self.n_iter = n_iter\n",
        "        self.learning_rate = learning_rate\n",
        "        self.weights = weights\n",
        "        self.metric = metric\n",
        "        self.reg = reg\n",
        "        self.l1_coef = l1_coef\n",
        "        self.l2_coef = l2_coef\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"MyLineReg class: n_iter={self.n_iter}, learning_rate={self.learning_rate}\"\n",
        "\n",
        "    def get_best_score(self):\n",
        "        return self.score\n",
        "\n",
        "    def get_coef(self):\n",
        "        return self.weights[1:]\n",
        "\n",
        "    def predict(self, X):\n",
        "         X.insert(loc=0, column='x_x', value=1)\n",
        "\n",
        "         return np.dot(X, self.weights)\n",
        "\n",
        "    @staticmethod\n",
        "    def get_metric_score(metric, y, y_pred):\n",
        "        if metric == 'mae':\n",
        "            score = (y - y_pred).abs().mean()\n",
        "        elif metric == 'mse':\n",
        "            score = np.mean((y_pred - y)**2)\n",
        "        elif metric == 'rmse':\n",
        "            score = np.sqrt(np.mean((y_pred - y)**2))\n",
        "        elif metric == 'mape':\n",
        "            score = (100 / y.shape[0]) * np.sum(abs((y - y_pred) / y))\n",
        "        elif metric == 'r2':\n",
        "            score = 1 - ((np.sum((y - y_pred)**2)) / (np.sum((y - np.mean(y))**2)))\n",
        "        return score\n",
        "\n",
        "    def grad(self, y_true: pd.Series, y_pred: pd.Series, X: pd.DataFrame):\n",
        "\n",
        "        if not self.reg:\n",
        "           grad = (2 / y.shape[0]) * ((y_pred - y)).dot(X)\n",
        "        elif self.reg == 'l1':\n",
        "           grad = (2 / y.shape[0]) * ((y_pred - y)).dot(X) + self.l1_coef * np.sign(self.weights)\n",
        "        elif self.reg == 'l2':\n",
        "           grad = (2 / y.shape[0]) * ((y_pred - y)).dot(X) + self.l2_coef * 2 * (self.weights)\n",
        "        elif self.reg == 'elasticnet':\n",
        "           grad = (2 / y.shape[0]) * ((y_pred - y)).dot(X) + self.l1_coef * np.sign(self.weights) + self.l2_coef * 2 * (self.weights)\n",
        "\n",
        "        return grad\n",
        "\n",
        "    def fit(self, X, y, verbose=False):\n",
        "        X.insert(loc=0, column='x_0', value=1)\n",
        "\n",
        "        self.weights = np.ones(X.shape[1])\n",
        "\n",
        "        for i in range(self.n_iter):\n",
        "            y_pred = np.dot(X, self.weights)\n",
        "            err = np.mean((y_pred - y)**2)\n",
        "            nabla = self.grad(y, y_pred, X)\n",
        "\n",
        "            if isinstance(self.learning_rate, (int, float)):\n",
        "                self.weights -= self.learning_rate * nabla\n",
        "            else:\n",
        "                self.weights -= self.learning_rate(i + 1) * nabla\n",
        "\n",
        "            # self.weights -= self.learning_rate * nabla if isinstance(self.learning_rate, (int, float)) else self.weights -= self.learning_rate(i + 1) * nabla\n",
        "\n",
        "            # if (self.learning_rate, numbers.Number):\n",
        "            #     self.weights -= self.learning_rate * nabla\n",
        "            # else:\n",
        "            #     self.weights -= self.learning_rate(i + 1) * nabla\n",
        "\n",
        "            if self.metric:\n",
        "               self.score = getattr(self, 'get_metric_score')(self.metric, y, np.dot(X, self.weights))\n",
        "\n",
        "            if verbose and i % verbose == 0:\n",
        "               if self.metric:\n",
        "                   print(f'start | loss = {err} | {self.score}') if i == 0 else print(f'i = {i} | loss = {err} | {self.score}')\n",
        "               else:\n",
        "                   print(f'start | loss = {err}') if i == 0 else print(f'i = {i} | loss = {err}')"
      ],
      "metadata": {
        "id": "LQfxsh4ERZ8r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# correct version\n",
        "\n",
        "class MyLineReg():\n",
        "    def __init__(self,\n",
        "                 n_iter=3,\n",
        "                 learning_rate= 0.1,\n",
        "                 weights = None,\n",
        "                 metric=None,\n",
        "                 reg=None,\n",
        "                 l1_coef: float = 0.,\n",
        "                 l2_coef: float = 0.,) -> None:\n",
        "\n",
        "        self.n_iter = n_iter\n",
        "        self.learning_rate = learning_rate\n",
        "        self.weights = weights\n",
        "        self.metric = metric\n",
        "        self.reg = reg\n",
        "        self.l1_coef = l1_coef\n",
        "        self.l2_coef = l2_coef\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"MyLineReg class: n_iter={self.n_iter}, learning_rate={self.learning_rate}\"\n",
        "\n",
        "    def get_best_score(self):\n",
        "        return self.score\n",
        "\n",
        "    def get_coef(self):\n",
        "        return self.weights[1:]\n",
        "\n",
        "    def predict(self, X):\n",
        "         X.insert(loc=0, column='x_x', value=1)\n",
        "\n",
        "         return np.dot(X, self.weights)\n",
        "\n",
        "    @staticmethod\n",
        "    def get_metric_score(metric, y, y_pred):\n",
        "        if metric == 'mae':\n",
        "            score = (y - y_pred).abs().mean()\n",
        "        elif metric == 'mse':\n",
        "            score = np.mean((y_pred - y)**2)\n",
        "        elif metric == 'rmse':\n",
        "            score = np.sqrt(np.mean((y_pred - y)**2))\n",
        "        elif metric == 'mape':\n",
        "            score = (100 / y.shape[0]) * np.sum(abs((y - y_pred) / y))\n",
        "        elif metric == 'r2':\n",
        "            score = 1 - ((np.sum((y - y_pred)**2)) / (np.sum((y - np.mean(y))**2)))\n",
        "        return score\n",
        "\n",
        "    def grad(self, y_true: pd.Series, y_pred: pd.Series, X: pd.DataFrame):\n",
        "\n",
        "        if not self.reg:\n",
        "           grad = (2 / y.shape[0]) * ((y_pred - y)).dot(X)\n",
        "        elif self.reg == 'l1':\n",
        "           grad = (2 / y.shape[0]) * ((y_pred - y)).dot(X) + self.l1_coef * np.sign(self.weights)\n",
        "        elif self.reg == 'l2':\n",
        "           grad = (2 / y.shape[0]) * ((y_pred - y)).dot(X) + self.l2_coef * 2 * (self.weights)\n",
        "        elif self.reg == 'elasticnet':\n",
        "           grad = (2 / y.shape[0]) * ((y_pred - y)).dot(X) + self.l1_coef * np.sign(self.weights) + self.l2_coef * 2 * (self.weights)\n",
        "\n",
        "        return grad\n",
        "\n",
        "    def fit(self, X, y, verbose=False):\n",
        "        X.insert(loc=0, column='x_0', value=1)\n",
        "\n",
        "        self.weights = np.ones(X.shape[1])\n",
        "\n",
        "        for i in range(self.n_iter):\n",
        "            y_pred = np.dot(X, self.weights)\n",
        "            err = np.mean((y_pred - y)**2)\n",
        "            nabla = self.grad(y, y_pred, X)\n",
        "\n",
        "            if isinstance(self.learning_rate, (int, float)):\n",
        "                self.weights -= self.learning_rate * nabla\n",
        "            else:\n",
        "                self.weights -= self.learning_rate(i + 1) * nabla\n",
        "\n",
        "            if self.metric:\n",
        "               self.score = getattr(self, 'get_metric_score')(self.metric, y, np.dot(X, self.weights))\n",
        "\n",
        "            if verbose and i % verbose == 0:\n",
        "               if self.metric:\n",
        "                   print(f'start | loss = {err} | {self.score} | learning_rate = {self.learning_rate}') if i == 0 else print(f'i = {i} | loss = {err} | {self.score} | learning_rate = {self.learning_rate}')\n",
        "               else:\n",
        "                   print(f'start | loss = {err} | learning_rate = {self.learning_rate}') if i == 0 else print(f'i = {i} | loss = {err} | learning_rate = {self.learning_rate}')"
      ],
      "metadata": {
        "id": "8sBxs4dsaOIs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2_1_14\n",
        "\n",
        "\n",
        "Стохастический градиентный спуск (реализация)\n",
        "Добавьте в класс MyLineReg два новых параметра:\n",
        "\n",
        "sgd_sample – кол-во образцов, которое будет использоваться на каждой итерации обучения. Может принимать либо целые числа, либо дробные от 0.0 до 1.0.\n",
        "По-умолчанию: None\n",
        "\n",
        "random_state – для воспроизводимости результата зафиксируем сид (об этом далее).\n",
        "По-умолчанию: 42\n",
        "Внесем изменение в алгоритм обучения:\n",
        "\n",
        "В начале обучения фиксируем сид (см. ниже).\n",
        "В начале каждого шага формируется новый мини-пакет, состоящий из случайно выбранных элементов обучающего набора. Кол-во отобранных элементов определяется параметром sgd_sample:\n",
        "Если задано целое число, то из исходного датасета берется ровно столько примеров сколько указано.\n",
        "Если задано дробное число, то рассматриваем его как долю от количества строк в исходном датасете (округленное до целого числа).\n",
        "Расчет градиента (и последующее изменение весов) делаем на основе мини-пакета.\n",
        "Все остальные параметры, если они заданы (например, регуляризация), также должны учитываться при обучении.\n",
        "Ошибку и метрику необходимо считать на всем датасете, а не на мини-пакете.\n",
        "Если sgd_sample = None, то обучение выполняется как раньше (на всех данных).\n",
        "Случайная генерация\n",
        "\n",
        "Т.к. у нас формальная проверка кода, то у всех должны получиться одинаковые случайные подвыборки. Поэтому и способ у всех будет одинаковый.\n",
        "\n",
        "В начале обучения посредством модуля random фиксирум сид:\n",
        "\n",
        "random.seed(<random_state>)\n",
        "В начале каждой итерации сформируем порядковые номера строк, которые стоит отобрать.\n",
        "\n",
        "sample_rows_idx = random.sample(range(X.shape[0]), <sgd_sample>)\n",
        "В этом случае при каждом запуске будут генерироваться одни и те же номера строк. Что позволит нам добиться воспроизводимости.\n",
        "\n",
        "З.Ы. Модуль random уже импортирован.\n",
        "\n",
        "Тестирование\n",
        "\n",
        "Входные данные: различные значения параметра sgd_sample\n",
        "Выходные данные: коэффициенты обученной линейной регрессии (их среднее)"
      ],
      "metadata": {
        "id": "IQMGn9GJaNzk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyLineReg():\n",
        "    def __init__(self,\n",
        "                 n_iter=50,\n",
        "                 learning_rate= 0.1,\n",
        "                 weights = None,\n",
        "                 metric=None,\n",
        "                 reg=None,\n",
        "                 l1_coef: float = 0.,\n",
        "                 l2_coef: float = 0.,\n",
        "                 sgd_sample: float = None,\n",
        "                 random_state: int = 42) -> None:\n",
        "\n",
        "        self.n_iter = n_iter\n",
        "        self.learning_rate = learning_rate\n",
        "        self.weights = weights\n",
        "        self.metric = metric\n",
        "        self.reg = reg\n",
        "        self.l1_coef = l1_coef\n",
        "        self.l2_coef = l2_coef\n",
        "        self.sgd_sample = sgd_sample\n",
        "        random.seed(random_state)\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"MyLineReg class: n_iter={self.n_iter}, learning_rate={self.learning_rate}\"\n",
        "\n",
        "    def get_best_score(self):\n",
        "        return self.score\n",
        "\n",
        "    def get_coef(self):\n",
        "        return self.weights[1:]\n",
        "\n",
        "    def predict(self, X):\n",
        "         X.insert(loc=0, column='x_x', value=1)\n",
        "         return np.dot(X, self.weights)\n",
        "\n",
        "    def get_batch(self, x_length):\n",
        "        # return random.sample(range(int(self.sgd_sample * x_length), self.sgd_sample)) if isinstance(self.sgd_sample, float) else random.sample(range(x_length), self.sgd_sample)\n",
        "        if isinstance(self.sgd_sample, float):\n",
        "            amount = int(self.sgd_sample * x_length)\n",
        "        else:\n",
        "            amount = self.sgd_sample\n",
        "        return random.sample(range(x_length), amount)\n",
        "\n",
        "    @staticmethod\n",
        "    def get_metric_score(metric, y, y_pred):\n",
        "        if metric == 'mae':\n",
        "            score = (y - y_pred).abs().mean()\n",
        "        elif metric == 'mse':\n",
        "            score = np.mean((y_pred - y)**2)\n",
        "        elif metric == 'rmse':\n",
        "            score = np.sqrt(np.mean((y_pred - y)**2))\n",
        "        elif metric == 'mape':\n",
        "            score = (100 / y.shape[0]) * np.sum(abs((y - y_pred) / y))\n",
        "        elif metric == 'r2':\n",
        "            score = 1 - ((np.sum((y - y_pred)**2)) / (np.sum((y - np.mean(y))**2)))\n",
        "        return score\n",
        "\n",
        "    def grad(self, y_true: pd.Series, y_pred: pd.Series, X: pd.DataFrame, batch_idxs):\n",
        "        y_true = y_true.iloc[batch_idxs]\n",
        "        y_pred = y_pred.iloc[batch_idxs]\n",
        "        X = X.iloc[batch_idxs, :]\n",
        "\n",
        "        if not self.reg:\n",
        "           grad = (2 / y.shape[0]) * ((y_pred - y)).dot(X)\n",
        "        elif self.reg == 'l1':\n",
        "           grad = (2 / y.shape[0]) * ((y_pred - y)).dot(X) + self.l1_coef * np.sign(self.weights)\n",
        "        elif self.reg == 'l2':\n",
        "           grad = (2 / y.shape[0]) * ((y_pred - y)).dot(X) + self.l2_coef * 2 * (self.weights)\n",
        "        elif self.reg == 'elasticnet':\n",
        "           grad = (2 / y.shape[0]) * ((y_pred - y)).dot(X) + self.l1_coef * np.sign(self.weights) + self.l2_coef * 2 * (self.weights)\n",
        "\n",
        "        return grad\n",
        "\n",
        "    def fit(self, X, y, verbose=False):\n",
        "\n",
        "        X.insert(loc=0, column='x_0', value=1)\n",
        "\n",
        "        self.weights = np.ones(X.shape[1])\n",
        "\n",
        "        for i in range(self.n_iter):\n",
        "            sample_rows_idx = self.get_batch(X.shape[0]) if self.sgd_sample else X.index\n",
        "            # X_batch = X.iloc[[sample_rows_idx]]\n",
        "            y_pred = np.dot(X, self.weights)\n",
        "            err = np.mean((y_pred - y)**2)\n",
        "            nabla = self.grad(y, y_pred, X, sample_rows_idx)\n",
        "\n",
        "            if isinstance(self.learning_rate, (int, float)):\n",
        "                self.weights -= self.learning_rate * nabla\n",
        "            else:\n",
        "                self.weights -= self.learning_rate(i + 1) * nabla\n",
        "\n",
        "            if self.metric:\n",
        "               self.score = getattr(self, 'get_metric_score')(self.metric, y, np.dot(X, self.weights))\n",
        "\n",
        "            if verbose and i % verbose == 0:\n",
        "               if self.metric:\n",
        "                   print(f'start | loss = {err} | {self.score} | learning_rate = {self.learning_rate}') if i == 0 else print(f'i = {i} | loss = {err} | {self.score} | learning_rate = {self.learning_rate}')\n",
        "               else:\n",
        "                   print(f'start | loss = {err} | learning_rate = {self.learning_rate}') if i == 0 else print(f'i = {i} | loss = {err} | learning_rate = {self.learning_rate}')"
      ],
      "metadata": {
        "id": "JTUaBuPqfO6s"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_regression\n",
        "\n",
        "X_mk, y_mk = make_regression(n_samples=10, n_features=3, n_informative=10, noise=15, random_state=42)"
      ],
      "metadata": {
        "id": "wbhH1Aa6sEJS"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = pd.DataFrame(X_mk)\n",
        "y = pd.Series(y_mk)"
      ],
      "metadata": {
        "id": "Wc84AjfKsau4"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "nflmIeNMwTAi",
        "outputId": "8d79b9d6-f1f8-48cc-b88b-0f6a661fa850"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          0         1         2\n",
              "0  0.767435  1.579213 -0.469474\n",
              "1 -0.234153  1.523030 -0.234137\n",
              "2  0.110923 -0.544383 -1.150994\n",
              "3 -0.600639  0.375698 -0.291694\n",
              "4 -1.913280  0.241962 -1.724918\n",
              "5 -1.012831 -0.562288  0.314247\n",
              "6 -0.138264  0.496714  0.647689\n",
              "7 -0.463418  0.542560 -0.465730\n",
              "8 -1.412304 -0.908024  1.465649\n",
              "9  0.067528 -0.225776 -1.424748"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-53eff9c2-1ee9-4395-97b7-c70a3a17a131\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.767435</td>\n",
              "      <td>1.579213</td>\n",
              "      <td>-0.469474</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.234153</td>\n",
              "      <td>1.523030</td>\n",
              "      <td>-0.234137</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.110923</td>\n",
              "      <td>-0.544383</td>\n",
              "      <td>-1.150994</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.600639</td>\n",
              "      <td>0.375698</td>\n",
              "      <td>-0.291694</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1.913280</td>\n",
              "      <td>0.241962</td>\n",
              "      <td>-1.724918</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>-1.012831</td>\n",
              "      <td>-0.562288</td>\n",
              "      <td>0.314247</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>-0.138264</td>\n",
              "      <td>0.496714</td>\n",
              "      <td>0.647689</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>-0.463418</td>\n",
              "      <td>0.542560</td>\n",
              "      <td>-0.465730</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>-1.412304</td>\n",
              "      <td>-0.908024</td>\n",
              "      <td>1.465649</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.067528</td>\n",
              "      <td>-0.225776</td>\n",
              "      <td>-1.424748</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-53eff9c2-1ee9-4395-97b7-c70a3a17a131')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-53eff9c2-1ee9-4395-97b7-c70a3a17a131 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-53eff9c2-1ee9-4395-97b7-c70a3a17a131');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.iloc[[0, 1, 3]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "CH9ipx1xslcl",
        "outputId": "8a6ce676-4099-4839-8bae-db696ea5f3f6"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          0         1         2\n",
              "0  0.767435  1.579213 -0.469474\n",
              "1 -0.234153  1.523030 -0.234137\n",
              "3 -0.600639  0.375698 -0.291694"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f28ba280-d89d-439e-90b0-d8e97cb87afc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.767435</td>\n",
              "      <td>1.579213</td>\n",
              "      <td>-0.469474</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.234153</td>\n",
              "      <td>1.523030</td>\n",
              "      <td>-0.234137</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.600639</td>\n",
              "      <td>0.375698</td>\n",
              "      <td>-0.291694</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f28ba280-d89d-439e-90b0-d8e97cb87afc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f28ba280-d89d-439e-90b0-d8e97cb87afc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f28ba280-d89d-439e-90b0-d8e97cb87afc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random"
      ],
      "metadata": {
        "id": "G614Q8SxtXJJ"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random.sample(range(10), 2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfa-MJ1ZtTcB",
        "outputId": "984faa30-bad0-4c5f-af6f-40616900c7a2"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "int(0.8 * 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gR9Toe0DwHtX",
        "outputId": "26af32c7-204d-41b7-964b-0457fa74161c"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = pd.DataFrame(X_mk)\n",
        "y = pd.Series(y_mk)\n",
        "\n",
        "class MyLineReg():\n",
        "    def __init__(self,\n",
        "                 n_iter=2,\n",
        "                 learning_rate= 0.1,\n",
        "                 weights = None,\n",
        "                 metric=None,\n",
        "                 reg=None,\n",
        "                 l1_coef: float = 0.,\n",
        "                 l2_coef: float = 0.,\n",
        "                 sgd_sample: float = None,\n",
        "                 random_state: int = 42) -> None:\n",
        "\n",
        "        self.n_iter = n_iter\n",
        "        self.learning_rate = learning_rate\n",
        "        self.weights = weights\n",
        "        self.metric = metric\n",
        "        self.reg = reg\n",
        "        self.l1_coef = l1_coef\n",
        "        self.l2_coef = l2_coef\n",
        "        self.sgd_sample = sgd_sample\n",
        "        random.seed(random_state)\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"MyLineReg class: n_iter={self.n_iter}, learning_rate={self.learning_rate}\"\n",
        "\n",
        "    def get_best_score(self):\n",
        "        return self.score\n",
        "\n",
        "    def get_coef(self):\n",
        "        return self.weights[1:]\n",
        "\n",
        "    def predict(self, X):\n",
        "         X.insert(loc=0, column='x_x', value=1)\n",
        "         return np.dot(X, self.weights)\n",
        "\n",
        "    def get_batch(self, x_length):\n",
        "        return random.sample(range(x_length), int(self.sgd_sample * x_length)) if isinstance(self.sgd_sample, float) else random.sample(range(x_length), self.sgd_sample)\n",
        "        # if isinstance(self.sgd_sample, float):\n",
        "        #     amount = int(self.sgd_sample * x_length)\n",
        "        # else:\n",
        "        #     amount = self.sgd_sample\n",
        "        # return random.sample(range(x_length), amount)\n",
        "\n",
        "    @staticmethod\n",
        "    def get_metric_score(metric, y, y_pred):\n",
        "        if metric == 'mae':\n",
        "            score = (y - y_pred).abs().mean()\n",
        "        elif metric == 'mse':\n",
        "            score = np.mean((y_pred - y)**2)\n",
        "        elif metric == 'rmse':\n",
        "            score = np.sqrt(np.mean((y_pred - y)**2))\n",
        "        elif metric == 'mape':\n",
        "            score = (100 / y.shape[0]) * np.sum(abs((y - y_pred) / y))\n",
        "        elif metric == 'r2':\n",
        "            score = 1 - ((np.sum((y - y_pred)**2)) / (np.sum((y - np.mean(y))**2)))\n",
        "        return score\n",
        "\n",
        "    def grad(self, y: pd.Series, y_pred: np.array, X: pd.DataFrame, batch_idxs):\n",
        "        print('y\\n', y)\n",
        "        y = y.iloc[batch_idxs]\n",
        "        print('y_new\\n', y)\n",
        "        y_pred = y_pred[batch_idxs]\n",
        "        X = X.iloc[batch_idxs]\n",
        "\n",
        "        if not self.reg:\n",
        "           grad = (2 / y.shape[0]) * ((y_pred - y)).dot(X)\n",
        "        elif self.reg == 'l1':\n",
        "           grad = (2 / y.shape[0]) * ((y_pred - y)).dot(X) + self.l1_coef * np.sign(self.weights)\n",
        "        elif self.reg == 'l2':\n",
        "           grad = (2 / y.shape[0]) * ((y_pred - y)).dot(X) + self.l2_coef * 2 * (self.weights)\n",
        "        elif self.reg == 'elasticnet':\n",
        "           grad = (2 / y.shape[0]) * ((y_pred - y)).dot(X) + self.l1_coef * np.sign(self.weights) + self.l2_coef * 2 * (self.weights)\n",
        "\n",
        "        return grad\n",
        "\n",
        "    def fit(self, X, y, verbose=False):\n",
        "\n",
        "\n",
        "        X.insert(loc=0, column='x_0', value=1)\n",
        "\n",
        "        self.weights = np.ones(X.shape[1])\n",
        "\n",
        "        for i in range(self.n_iter):\n",
        "            sample_rows_idx = self.get_batch(X.shape[0]) if self.sgd_sample else X.index\n",
        "            y_pred = np.dot(X, self.weights)\n",
        "            err = np.mean((y_pred - y)**2)\n",
        "            nabla = self.grad(y, y_pred, X, sample_rows_idx)\n",
        "\n",
        "            if isinstance(self.learning_rate, (int, float)):\n",
        "                # print(self.learning_rate)\n",
        "                # print(nabla)\n",
        "                self.weights -= self.learning_rate * nabla\n",
        "            else:\n",
        "                self.weights -= self.learning_rate(i + 1) * nabla\n",
        "\n",
        "            if self.metric:\n",
        "               self.score = getattr(self, 'get_metric_score')(self.metric, y, np.dot(X, self.weights))\n",
        "\n",
        "            if verbose and i % verbose == 0:\n",
        "               if self.metric:\n",
        "                   print(f'start | loss = {err} | {self.score} | learning_rate = {self.learning_rate}') if i == 0 else print(f'i = {i} | loss = {err} | {self.score} | learning_rate = {self.learning_rate}')\n",
        "               else:\n",
        "                   print(f'start | loss = {err} | learning_rate = {self.learning_rate}') if i == 0 else print(f'i = {i} | loss = {err} | learning_rate = {self.learning_rate}')\n",
        "\n",
        "\n",
        "reg = MyLineReg(metric='mape', sgd_sample=0.8)\n",
        "# reg = MyLineReg(metric='mape')\n",
        "reg.fit(X, y, verbose=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJzQ3d3E31Wc",
        "outputId": "abb02d02-2ad6-4378-c5f9-98dc4a3cf333"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y\n",
            " 0    132.662648\n",
            "1     90.964130\n",
            "2    -43.133126\n",
            "3      8.935874\n",
            "4   -107.685029\n",
            "5    -62.838681\n",
            "6     27.800630\n",
            "7     16.882855\n",
            "8    -64.731691\n",
            "9    -11.958869\n",
            "dtype: float64\n",
            "y_new\n",
            " 1     90.964130\n",
            "0    132.662648\n",
            "4   -107.685029\n",
            "9    -11.958869\n",
            "6     27.800630\n",
            "5    -62.838681\n",
            "8    -64.731691\n",
            "2    -43.133126\n",
            "dtype: float64\n",
            "start | loss = 4690.118351259567 | 82.23173814529274 | learning_rate = 0.1\n",
            "y\n",
            " 0    132.662648\n",
            "1     90.964130\n",
            "2    -43.133126\n",
            "3      8.935874\n",
            "4   -107.685029\n",
            "5    -62.838681\n",
            "6     27.800630\n",
            "7     16.882855\n",
            "8    -64.731691\n",
            "9    -11.958869\n",
            "dtype: float64\n",
            "y_new\n",
            " 8    -64.731691\n",
            "1     90.964130\n",
            "6     27.800630\n",
            "0    132.662648\n",
            "7     16.882855\n",
            "5    -62.838681\n",
            "9    -11.958869\n",
            "4   -107.685029\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNZUidzt-4h5",
        "outputId": "34986b26-4961-4fd9-cf2a-a70153d66776"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RangeIndex(start=0, stop=10, step=1)"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# correct version\n",
        "\n",
        "class MyLineReg():\n",
        "    def __init__(self,\n",
        "                 n_iter=2,\n",
        "                 learning_rate= 0.1,\n",
        "                 weights = None,\n",
        "                 metric=None,\n",
        "                 reg=None,\n",
        "                 l1_coef: float = 0.,\n",
        "                 l2_coef: float = 0.,\n",
        "                 sgd_sample: float = None,\n",
        "                 random_state: int = 42) -> None:\n",
        "\n",
        "        self.n_iter = n_iter\n",
        "        self.learning_rate = learning_rate\n",
        "        self.weights = weights\n",
        "        self.metric = metric\n",
        "        self.reg = reg\n",
        "        self.l1_coef = l1_coef\n",
        "        self.l2_coef = l2_coef\n",
        "        self.sgd_sample = sgd_sample\n",
        "        random.seed(random_state)\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"MyLineReg class: n_iter={self.n_iter}, learning_rate={self.learning_rate}\"\n",
        "\n",
        "    def get_best_score(self):\n",
        "        return self.score\n",
        "\n",
        "    def get_coef(self):\n",
        "        return self.weights[1:]\n",
        "\n",
        "    def predict(self, X):\n",
        "         X.insert(loc=0, column='x_x', value=1)\n",
        "         return np.dot(X, self.weights)\n",
        "\n",
        "    def get_batch(self, x_length):\n",
        "        return random.sample(range(x_length), int(self.sgd_sample * x_length)) if isinstance(self.sgd_sample, float) else random.sample(range(x_length), self.sgd_sample)\n",
        "\n",
        "    @staticmethod\n",
        "    def get_metric_score(metric, y, y_pred):\n",
        "        if metric == 'mae':\n",
        "            score = (y - y_pred).abs().mean()\n",
        "        elif metric == 'mse':\n",
        "            score = np.mean((y_pred - y)**2)\n",
        "        elif metric == 'rmse':\n",
        "            score = np.sqrt(np.mean((y_pred - y)**2))\n",
        "        elif metric == 'mape':\n",
        "            score = (100 / y.shape[0]) * np.sum(abs((y - y_pred) / y))\n",
        "        elif metric == 'r2':\n",
        "            score = 1 - ((np.sum((y - y_pred)**2)) / (np.sum((y - np.mean(y))**2)))\n",
        "        return score\n",
        "\n",
        "    def grad(self, y: pd.Series, y_pred: np.array, X: pd.DataFrame, batch_idxs):\n",
        "        y = y.iloc[batch_idxs]\n",
        "        y_pred = y_pred[batch_idxs]\n",
        "        X = X.iloc[batch_idxs]\n",
        "\n",
        "        if not self.reg:\n",
        "           grad = (2 / y.shape[0]) * ((y_pred - y)).dot(X)\n",
        "        elif self.reg == 'l1':\n",
        "           grad = (2 / y.shape[0]) * ((y_pred - y)).dot(X) + self.l1_coef * np.sign(self.weights)\n",
        "        elif self.reg == 'l2':\n",
        "           grad = (2 / y.shape[0]) * ((y_pred - y)).dot(X) + self.l2_coef * 2 * (self.weights)\n",
        "        elif self.reg == 'elasticnet':\n",
        "           grad = (2 / y.shape[0]) * ((y_pred - y)).dot(X) + self.l1_coef * np.sign(self.weights) + self.l2_coef * 2 * (self.weights)\n",
        "\n",
        "        return grad\n",
        "\n",
        "    def fit(self, X, y, verbose=False):\n",
        "        X.insert(loc=0, column='x_0', value=1)\n",
        "        self.weights = np.ones(X.shape[1])\n",
        "\n",
        "        for i in range(self.n_iter):\n",
        "            sample_rows_idx = self.get_batch(X.shape[0]) if self.sgd_sample else range(X.shape[0])\n",
        "            y_pred = np.dot(X, self.weights)\n",
        "            err = np.mean((y_pred - y)**2)\n",
        "            nabla = self.grad(y, y_pred, X, sample_rows_idx)\n",
        "\n",
        "            if isinstance(self.learning_rate, (int, float)):\n",
        "                self.weights -= self.learning_rate * nabla\n",
        "            else:\n",
        "                self.weights -= self.learning_rate(i + 1) * nabla\n",
        "\n",
        "            if self.metric:\n",
        "               self.score = getattr(self, 'get_metric_score')(self.metric, y, np.dot(X, self.weights))\n",
        "\n",
        "            if verbose and i % verbose == 0:\n",
        "               if self.metric:\n",
        "                   print(f'start | loss = {err} | {self.score} | learning_rate = {self.learning_rate}') if i == 0 else print(f'i = {i} | loss = {err} | {self.score} | learning_rate = {self.learning_rate}')\n",
        "               else:\n",
        "                   print(f'start | loss = {err} | learning_rate = {self.learning_rate}') if i == 0 else print(f'i = {i} | loss = {err} | learning_rate = {self.learning_rate}')"
      ],
      "metadata": {
        "id": "jp91yJVBEfzS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}